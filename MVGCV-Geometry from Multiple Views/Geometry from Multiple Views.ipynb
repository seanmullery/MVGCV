{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b44e51-837a-418a-9138-9d8d61eb9ff0",
   "metadata": {},
   "source": [
    "![\"HCI Banner Logos for ATU Sligo, the HCI Human capital initiative and Higher Education 4.0\"](images/HCIBanner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae5c58",
   "metadata": {},
   "source": [
    "# Geometry from Multiple Views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b9290",
   "metadata": {},
   "source": [
    "## Opening Assumptions\n",
    "\n",
    "As with the two-view case,  to solve this problem one step at a time we need to make some assumptions.\n",
    "\n",
    "- We have to assume that we are viewing a static scene and that we have multiple different views of this scene.\n",
    "- We will assume that we already have a set of point correspondences in our multiple views. How we did this is not our concern in this section.\n",
    "- We assume that we know the intrinsic parameters of the camera. And we will assume that they are the same for all views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55bac6",
   "metadata": {},
   "source": [
    "## What does more views bring us?\n",
    "More views allows us to have more measurements for the same number of 3D points.\n",
    "\n",
    "This constrains our result even more than the two-view case.\n",
    "\n",
    "In general we start by looking at the three-view case and then generalise that to the n-view case.\n",
    "\n",
    "This three-view case can be tackled with matrices (which is how we will do it) or with the trifocal tensor.\n",
    "\n",
    "The trifocal tensor is a generalisation of the fundamental matrix.\n",
    "\n",
    "As with the fundamental matrix, the trifocal tensor doesn't depend on the 3D points, but only on the inter-frame camera motion.\n",
    "\n",
    "The relationship between points and lines encoded by the trifocal tensor is called a trilinear relationship.\n",
    "\n",
    "## The matrix view\n",
    "We will not use the trifocal tensor but instead use a matrix notation which once again will make use of rank constraints which are imposed by the constraints from the multiple views.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e7069-512e-48ce-ba3a-6af7ee6f104b",
   "metadata": {},
   "source": [
    "# Modify the basic epipolar program to demonstrate pre-image and co-image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee4946-85a2-4309-b23a-949db9de2f54",
   "metadata": {},
   "source": [
    "## Pre-image and Co-image\n",
    "Definition of Pre-image:_The pre-image of a point or a line in 3D is defined by the subspace (in the camera coordinate frame)  spanned by the homogeneous coordinates of the image point or points of the line in the plane._\n",
    "\n",
    "Definition of Co-image: _The co-image of a point or a line in 3D is defined to be the maximum orthogonal supplementary subspace orthogonal to its pre-image (in the camera coordinate frame)._\n",
    "\n",
    "\n",
    "\n",
    "## Pre-image of a point\n",
    "\n",
    "\n",
    "For a point, the pre-image is a 1D subspace, i.e. a line defined by a vector.\n",
    "In the figure the pre-image of the point $p$ in camera\\textsubscript{1}  is $\\vec{x_1}$\n",
    "\n",
    "![](images/precoimage.png)\n",
    "\n",
    "\n",
    "## Pre-image of a line\n",
    "\n",
    "\n",
    "For a line, the pre-image is a 2D subspace, i.e. a plane which can be defined by any two linearly independent vectors in that plane.\n",
    "\n",
    "The plane uniquely determines the image of the line in the image plane as the intersection of the plane with image plane.\n",
    "In the figure the pre-image of the line $L$ in camera\\textsubscript{1} is the dark blue line. \n",
    "\t\n",
    "\n",
    "## Co-image of a point}\n",
    "\n",
    "As the pre-image of a point is a 1D subspace then its co-image is a plane with the pre-image vector being the normal to that plane.\n",
    "\n",
    "\n",
    "\n",
    "## Co-image of a line\n",
    "\n",
    "\n",
    "As the pre-image of a line is a 2D subspace, i.e. a plane, then its co-image is a vector that is normal to this plane.\n",
    "Shown in the diagram as $\\vec{l_1}$ and $\\vec{l_2}$.\n",
    "\n",
    "\n",
    "\t\n",
    "\t\n",
    "## Pre-image from multiple views\n",
    "\n",
    "\n",
    "A pre-image of multiple images of a point is the largest set of 3D points that give rise to the same set of multiple images of the point.\n",
    "\n",
    "In the figure for the two images, $p$ is the pre-image as it is the intersection of the two vectors $\\vec{x_1}$ and $\\vec{x_2}$.\n",
    "\n",
    "\n",
    "\t\n",
    " \n",
    "## Pre-image from multiple views\n",
    "\n",
    "\n",
    "A pre-image of multiple images of a line is the largest set of 3D points that give rise to the same set of multiple images of the line.\n",
    "In the figure for the two images, $L$ is the pre-image as it is the intersection of the two planes $l_{1\\times}$ and $l_{2\\times}$.\n",
    "\n",
    " \n",
    "## Pre-image intersection\n",
    "\n",
    "The pre-image in multiple images of points and lines can be defined by the intersection.\n",
    "pre-image $(\\vec{x_1},\\dots, \\vec{x_m})$ = pre-image$(\\vec{x_1}) \\cap \\cdots \\cap$ pre-image$(\\vec{x_m})$\n",
    "\n",
    "pre-image $(l_1,\\dots, l_m)$ = pre-image$(l_1) \\cap \\cdots \\cap$ pre-image$(l_m)$  \n",
    "\n",
    "The pre-image of multiple image lines can either be nothing (empty set), a point, a line or a plane, depending on whether or not they come from the same line in space.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Assume we have a moving camera, at time $t$, let $x(t)$ denote the coordinates of a 3D point $\\mathbf{X}$ in homogeneous coordinates.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\lambda(t)x(t) = K(t)\\Pi_0g(t)\\mathbf{X}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\lambda(t)$ denotes the depth of the point, $K(t)$ denotes the intrinsic paramters and $\\Pi_0$ denotes the generic projection.\n",
    "\n",
    "\\begin{equation}\n",
    "\tg(t) = \\begin{bmatrix}\n",
    "R(t) & T(t)\\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} \\in SE(3)\n",
    "\\end{equation}\n",
    "\n",
    "Which you recall denotes the rigid body motion, at time t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cad71-36fd-4d23-8858-7fb08d0ec340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf494341",
   "metadata": {},
   "source": [
    "## 3D line $L$\n",
    "\n",
    "\n",
    "A 3D line $L$ in homogeneous coordinates can be written as,\n",
    "\\begin{equation}\n",
    "\tL = \\{\\mathbf{X}|\\mathbf{X}=\\mathbf{X}_0 + \\mu\\mathbf{V}, \\mu \\in \\mathbb{R}\\} \\subset \\mathbb{R}^4\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\mathbf{X}_0 = [X_0,Y_0,Z_0,1]^{\\top} \\in \\mathbb{R}^4$ are the coordinates of the base point $p_0$ and \n",
    "\n",
    "$\\mathbf{V} = [V_1,V_2,V_3,0]^{\\top} \\in \\mathbb{R}^4$ is a nonzero \n",
    "\n",
    "vector indicating the line direction.\n",
    "\n",
    "![](images/precoimage.png)\n",
    "\n",
    "The pre-image of $L$ w.r.t. the image at time $t$ is a plane with normal $l(t)$. The vector $l(t)$ is orthogonal to all points $x(t)$ of the line\n",
    "\n",
    "\\begin{equation}\n",
    "\tl(t)^{\\top}x(t) = l(t)^{\\top}K(t)\\Pi_0g(t)\\mathbf{X} = 0\n",
    "\\end{equation}\n",
    "\n",
    "Assume we have a set of $m$ images at times $t_1,\\dots,t_m$ where\n",
    "$\\lambda_i=\\lambda(t_i)$\n",
    "\n",
    "$x_i = x(t_i)$,\n",
    "\n",
    "$l_i = l(t_i)$,\n",
    "\n",
    "$\\Pi_i=K(t_i)\\Pi_0g(t_i)$\n",
    "\n",
    "\n",
    "We can now relate the $i^{th}$ image of a point $p$ to its world coordinates $\\mathbf{X}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\lambda_ix_i=\\Pi_i\\mathbf{X}\n",
    "\\end{equation}\n",
    "\n",
    "and the $i^{th}$ co-image of a line $L$ to its world coordinates \n",
    "$(\\mathbf{X}_0, \\mathbf{V})$:\n",
    "\\begin{equation}\n",
    "\tl^{\\top}_i\\Pi_i\\mathbf{X}_0=l_i^{\\top}\\Pi_i\\mathbf{V}=0\t\n",
    "\\end{equation}\n",
    "    \n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "## Pre-images and Rank Constraints\n",
    "\n",
    "As we did in the two-view case, we need to remove the 3D coordinates of points (and lines) from the equations on the previous slides if we are to solve the system.\n",
    "\n",
    "We want equations that are in only the 2D coordinates, which we know.\n",
    "\n",
    "Take the images of a 3D point $\\mathbf{X}$ which we capture in multiple views;\n",
    "\\begin{equation}\n",
    "\t\\mathcal{I}\\vec{\\lambda} \\equiv \n",
    "\t\\begin{bmatrix}\n",
    "\tx_1 & 0 & \\cdots & 0 \\\\\n",
    "    0 & x_2 &  0 & 0\\\\\n",
    "\t\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\t0 & 0 & \\cdots & x_m\\\\\n",
    "\t\\end{bmatrix}\\begin{bmatrix}\n",
    "\t\\lambda_1  \\\\\n",
    "    \\lambda_2 \\\\\n",
    "\t\\vdots \\\\\n",
    "\t\\lambda_m\\\\\n",
    "\t\\end{bmatrix}=\\begin{bmatrix}\n",
    "\t\\Pi_1  \\\\\n",
    "    \\Pi_2 \\\\\n",
    "\t\\vdots \\\\\n",
    "\t\\Pi_m\\\\\n",
    "\t\\end{bmatrix}\\mathbf{X}\\equiv \\Pi\\mathbf{X}\n",
    "\\end{equation}\n",
    "or compactly:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathcal{I}\\vec{\\lambda} =\\Pi\\mathbf{X}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Pre-images and Rank Constraints\n",
    "\n",
    "$$\\mathcal{I}\\vec{\\lambda} =\\Pi\\mathbf{X}$$\n",
    "where $\\vec{\\lambda} \\in \\mathbb{R}^m$ is the depth scale vector, and $\\Pi \\in \\mathbb{R}^{3m\\times4}$ is the multiple-view projection matrix associated with the image matrix $\\mathcal{I} \\in \\mathbb{R}^{3m\\times m}$\n",
    "\n",
    "Just as with the two-view case, this equation is not of use yet as everything in it is unknown apart from the 2D coordinates.\n",
    "\n",
    "So our goal is to decouple the above equations into constraints which allow us to separately recover the camera displacements $\\Pi_i$ first and then the scene structure $\\lambda_i$ and $\\mathbf{X}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0343645f-05a7-4a9e-8e3a-93dd39a28db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644617959f7c4f5bac1da4ccc5ef2223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='Elevation', max=180, min=-180), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "camera_coords = np.array(np.zeros([3,2,2]))\n",
    "epipole_coords = np.array(np.zeros([2,2]))\n",
    "lambda1 = 0\n",
    "lambda2 = 0\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "num_points = 3\n",
    "\n",
    "\n",
    "\n",
    "def update_2d_plots(fig,gs, camera_coords, epipole_coords, ep):\n",
    "    \n",
    "    #fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    #axs = [fig.add_subplot(1, 3, 2), fig.add_subplot(1, 3, 3)]\n",
    "    axs = [fig.add_subplot(gs[0,3]),fig.add_subplot(gs[1,3])]\n",
    "    # Clear existing plots\n",
    "    axs[0].cla()\n",
    "    axs[1].cla()\n",
    "    \n",
    "    # Update and configure the first plot (Camera 1 View)\n",
    "    axs[0].set_title('Camera 1 View')\n",
    "    axs[0].set_xlim(-1, 1)\n",
    "    axs[0].set_ylim(-0.5, 0.5)\n",
    "    rect1 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(0, 1, 1, 0.5))  # Cyan color\n",
    "    axs[0].add_patch(rect1)\n",
    "    axs[0].plot([camera_coords[0][0][0], camera_coords[2][0][0]], [camera_coords[0][0][1], camera_coords[2][0][1]], color='blue')\n",
    "    for i in range(0,num_points):\n",
    "        axs[0].scatter(camera_coords[i][0][0], camera_coords[i][0][1], color='magenta')\n",
    "        axs[0].text(camera_coords[i][0][0], camera_coords[i][0][1], f\"x{i}\", color='black')\n",
    "        \n",
    "        if ep:\n",
    "            axs[0].scatter(epipole_coords[0][0], epipole_coords[0][1], color='black', marker='x')\n",
    "            axs[0].plot([camera_coords[i][0][0], epipole_coords[0][0]], [camera_coords[i][0][1], epipole_coords[0][1]], color='green')\n",
    "            \n",
    "\n",
    "\n",
    "        # Update and configure the second plot (Camera 2 View)\n",
    "    axs[1].set_title('Camera 2 View')\n",
    "    axs[1].set_xlim(-1, 1)\n",
    "    axs[1].set_ylim(-0.5, 0.5)\n",
    "    rect2 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(1, 1, 0, 0.2))  # Yellow color\n",
    "    axs[1].add_patch(rect2)\n",
    "    axs[1].plot([camera_coords[0][1][0], camera_coords[2][1][0]], [camera_coords[0][1][1], camera_coords[2][1][1]], color='red')\n",
    "    for i in range(0,num_points):\n",
    "        axs[1].scatter(camera_coords[i][1][0], camera_coords[i][1][1], color='green')\n",
    "        axs[1].text(camera_coords[i][1][0], camera_coords[i][1][1], f\"x{i}\\'\", color='black')\n",
    "        \n",
    "        if ep:\n",
    "            axs[1].plot([camera_coords[i][1][0], epipole_coords[1][0]], [camera_coords[i][1][1], epipole_coords[1][1]], color='magenta')\n",
    "            axs[1].scatter(epipole_coords[1][0], epipole_coords[1][1], color='black', marker='x')\n",
    "    # Redraw the plots\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "# Define a function to update the plot with both elevation and azimuth angles\n",
    "def update_plot(elev_angle, azim_angle, roll_angle, FL2, Alpha, Beta, Gamma, tx, ty, tz, ep):\n",
    "    # Create a new matplotlib figure and axis\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    gs = GridSpec(2, 4, figure=fig)\n",
    "    #fig = plt.figure(figsize=(30, 10))\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = fig.add_subplot(gs[0:4,:], projection='3d')\n",
    "    # Set axes labels and limits\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_xlim([-2, 2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_zlim([0, 4])\n",
    "    global E_mat\n",
    "    global rot\n",
    "    global T\n",
    "    global world_coord\n",
    "\n",
    "\n",
    "    # Second camera array\n",
    "    K=np.array([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0,1,0],\n",
    "               [0,0,0,1]])\n",
    "    \n",
    "    T = np.array([[1,0,0,tx],\n",
    "                   [0,1,0,ty],\n",
    "                   [0,0,1,tz],\n",
    "                   [0,0,0,1]])\n",
    "    \n",
    "    # Individual Euler angle matrices\n",
    "    alphaRot = np.array([[1,0,0,0],\n",
    "       [0,math.cos(math.pi*Alpha/180),-math.sin(math.pi*Alpha/180),0],\n",
    "       [0,math.sin(math.pi*Alpha/180),math.cos(math.pi*Alpha/180),0],\n",
    "       [0,0,0,1]])\n",
    "    betaRot = np.array([[math.cos(math.pi*Beta/180),0,math.sin(math.pi*Beta/180),0],\n",
    "       [0,1,0,0],\n",
    "       [-math.sin(math.pi*Beta/180),0,math.cos(math.pi*Beta/180),0],\n",
    "       [0,0,0,1]])\n",
    "    gammaRot = np.array([\n",
    "       [math.cos(math.pi*Gamma/180),-math.sin(math.pi*Gamma/180),0,0],\n",
    "       [math.sin(math.pi*Gamma/180),math.cos(math.pi*Gamma/180),0,0],\n",
    "        [0,0,1,0],\n",
    "       [0,0,0,1]]\n",
    "    # Full rotation matrix but keep in mind that changing the order will change the rotation.\n",
    "    rot = alphaRot @ betaRot @ gammaRot\n",
    "    \n",
    "    # Camera two focal length only.\n",
    "    K_FL = ([[FL2,0,0,0],\n",
    "       [0,FL2,0,0],\n",
    "       [0,0,FL2,0],\n",
    "       [0,0,0,1]])\n",
    "    \n",
    "    '''Special matrix for the applying the focal length to the z-axis only \n",
    "    This is used to move the image sensor with the focal length but not resize the sensor\n",
    "    '''\n",
    "    K_plane = ([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0 ,FL2,0],\n",
    "               [0,0 ,0,1]])\n",
    "    \n",
    "    '''K_NF is the camera two matrix but without the focal length\n",
    "    This is to all the red, green and blue axes for camera two \n",
    "    to be the same size as for camera one. So this matrix is to help \n",
    "    with the visualisation only'''\n",
    "    K_NF = K @ T @ rot \n",
    "    \n",
    "    '''K_z is for the visualisation only. It allows the camera two frame to be shown in the correct\n",
    "    position without re-sizing the frame. Note, as we are only affecting the z-axis, ordering matters here.\n",
    "    You must do the rotation and translation first and only then extend the z-axis or otherwise you will rotate\n",
    "    and translate what you did to the z-axis and point it in another direction'''\n",
    "   \n",
    "    K_z = K @ T  @ rot @ K_plane \n",
    "   \n",
    "    '''This is the full camera two matrix (relative to camera one). The focal length is in multiples \n",
    "    of the first camera focal length. Hence the first camera focal lenght is fixed at 1 and therefore all \n",
    "    coordinates are in units of the focal length of camera one'''\n",
    "    \n",
    "    K = K  @ T  @  rot @  K_FL  \n",
    "    \n",
    "       \n",
    "    # Plotting the axes for the two cameras\n",
    "    axes = np.array([[[-.1, 0, 0],[.1, 0, 0]],\n",
    "            [[0, -.1, 0], [0, .1, 0]],\n",
    "            [[0, 0, 0], [0, 0, 0.5]]])\n",
    "               \n",
    "       \n",
    "    axes_cam_2 = axes.reshape(6,3)\n",
    "    axes_cam_2 = np.hstack([axes_cam_2, np.ones((6, 1))])\n",
    "    axes_cam_2 = K_NF @ axes_cam_2.transpose()\n",
    "    axes_cam_2 = axes_cam_2.transpose() \n",
    "    # Remove the last column\n",
    "    axes_cam_2 = axes_cam_2[:, :-1]\n",
    "    axes_cam_2 = axes_cam_2.reshape(3,2,3)\n",
    "    colors = ['r', 'g', 'b']  # Colors for each axis\n",
    "    for i in range(0, 3):\n",
    "        ax.plot([axes_cam_2[i][0][0], axes_cam_2[i][1][0]],  # X coordinates\n",
    "            [axes_cam_2[i][0][1], axes_cam_2[i][1][1]],  # Y coordinates\n",
    "            [axes_cam_2[i][0][2], axes_cam_2[i][1][2]],  # Z coordinates\n",
    "            color=colors[i]) \n",
    "        \n",
    "        ax.plot([axes[i][0][0], axes[i][1][0]],  # X coordinates\n",
    "            [axes[i][0][1], axes[i][1][1]],  # Y coordinates\n",
    "            [axes[i][0][2], axes[i][1][2]],  # Z coordinates\n",
    "            color=colors[i])   \n",
    "    \n",
    "    intersection_point = np.zeros([3,3])\n",
    "    cam_1_coord = np.zeros([3,2])\n",
    "    cam_2_coord = np.zeros([3,2])\n",
    "    intersection_point_imageP2 = np.zeros([3,4])\n",
    "    points = np.zeros([3,3,3])\n",
    "    pre_im_points1 = np.zeros([3,3,3])\n",
    "    pre_im_points2 = np.zeros([3,3,3])\n",
    "    world_coord = np.array([[-1.0,  0.0,2.5],\n",
    "                            [-0.5, 0.4, 2.5],\n",
    "                            [0.0, 0.8, 2.5],\n",
    "                            ]) \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,num_points):\n",
    "        # adding the world coordinate point\n",
    "        \n",
    "        ax.scatter(*world_coord[i], color='black')\n",
    "        ax.text(world_coord[i][0], world_coord[i][1], world_coord[i][2], f\"X{i}\", color='black')\n",
    "\n",
    "        # Drawing a line from the origin to the  World coordinate point\n",
    "        ax.plot([0, world_coord[i][0]], [0, world_coord[i][1]], [0, world_coord[i][2]], color='magenta')\n",
    "\n",
    "        # Creating a plane normal to the y-axis centered at (0, 1, 0)\n",
    "        x = np.linspace(-.6, .6, 10)\n",
    "        y = np.linspace(-.4, .4, 10)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.ones_like(X)  # Plane centered at Z=focal length\n",
    "        image_plane1 = np.array([X,Y,Z, np.ones_like(X)])\n",
    "\n",
    "\n",
    "\n",
    "        camera_2_center = K_NF @ np.array([0,0,0,1])\n",
    "        # Drawing a line from the camera 2 center to the point\n",
    "        ax.plot([camera_2_center[0], world_coord[i][0]], [camera_2_center[1], world_coord[i][1]], [camera_2_center[2], world_coord[i][2]], color='green')\n",
    "\n",
    "        # Adding the plane with transparency\n",
    "        if i == 0:\n",
    "            ax.plot_surface(image_plane1[0], image_plane1[1], image_plane1[2], color='cyan', alpha=0.5)\n",
    "\n",
    "            # This reshapes image_plane1 for matrix multiplication by our camera 2 matrix\n",
    "            image_plane2 = K_z @ image_plane1.reshape(4,-1) \n",
    "\n",
    "            # Reshaping back to original shape\n",
    "            image_plane2 = image_plane2.reshape(image_plane1.shape) \n",
    "            ax.plot_surface(image_plane2[0], image_plane2[1], image_plane2[2], color='yellow', alpha=0.5)\n",
    "\n",
    "        # The intersection point where the magenta line intersects the image_plane1 Z = 1\n",
    "        intersection_point[i] = (world_coord[i][0]/world_coord[i][2], world_coord[i][1]/world_coord[i][2], world_coord[i][2]/world_coord[i][2])\n",
    "        cam_1_coord[i] = np.array(intersection_point[i][:2])\n",
    "\n",
    "\n",
    "        \n",
    "        ax.scatter(*intersection_point[i], color='magenta')\n",
    "        \n",
    "        world_hom = np.array([world_coord[i][0],world_coord[i][1],world_coord[i][2],1])\n",
    "        try:\n",
    "            K_inv = np.linalg.inv(K)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"The matrix is not invertible.\")\n",
    "\n",
    "        temp_world = K_inv @ world_hom\n",
    "        if i == 0:\n",
    "            temp_world0=temp_world\n",
    "        intersection_point_imageP2[i] = np.array([FL2*temp_world[0]/temp_world[2], \n",
    "                                      FL2*temp_world[1]/temp_world[2], \n",
    "                                      FL2*temp_world[2]/temp_world[2],1])\n",
    "\n",
    "        x2 = intersection_point_imageP2[i][:3]\n",
    "        cam_2_coord[i] = intersection_point_imageP2[i][:2]\n",
    "\n",
    "        intersection_point_imageP2[i] = K_NF @ intersection_point_imageP2[i]\n",
    "        pt = (intersection_point_imageP2[i][0],intersection_point_imageP2[i][1],intersection_point_imageP2[i][2])\n",
    "        ax.scatter(*pt, color='green')\n",
    "\n",
    "        # draw line between camera centers\n",
    "        ax.plot([0, camera_2_center[0]], [0, camera_2_center[1]], [0, camera_2_center[2]], color='cyan')\n",
    "\n",
    "        points[i] = np.array([[0, 0, 0],  # Origin - camera 1 center\n",
    "                           [world_coord[i][0], world_coord[i][1], world_coord[i][2]],  # World coordinate\n",
    "                           [camera_2_center[0], camera_2_center[1], camera_2_center[2]]])  # Camera 2 center\n",
    "\n",
    "        # Shade in the Epipolar plane\n",
    "        epipoloar_plane = Poly3DCollection([points[i]])\n",
    "        epipoloar_plane.set_color('grey')\n",
    "        epipoloar_plane.set_alpha(0.2)  # Adjust transparency here\n",
    "        ax.add_collection3d(epipoloar_plane)\n",
    "\n",
    "        pre_im_points1[i] = np.array([[0, 0, 0],  # Origin - camera 1 center\n",
    "                           [world_coord[0][0], world_coord[0][1], world_coord[0][2]],  # World coordinate 0\n",
    "                           [world_coord[2][0], world_coord[2][1], world_coord[2][2]]])  # World coordinate 2\n",
    "\n",
    "        # Shade in the co-image plane 1\n",
    "        pre_image_plane1 = Poly3DCollection([pre_im_points1[i]])\n",
    "        pre_image_plane1.set_color('blue')\n",
    "        pre_image_plane1.set_alpha(0.1)  # Adjust transparency here\n",
    "        ax.add_collection3d(pre_image_plane1)\n",
    "\n",
    "        pre_im_points2[i] = np.array([[camera_2_center[0], camera_2_center[1], camera_2_center[2]],  # Origin - camera 1 center\n",
    "                           [world_coord[0][0], world_coord[0][1], world_coord[0][2]],  # World coordinate 0\n",
    "                           [world_coord[2][0], world_coord[2][1], world_coord[2][2]]])  # World coordinate 2\n",
    "\n",
    "         # Shade in the co-image plane 2\n",
    "        pre_image_plane2 = Poly3DCollection([pre_im_points2[i]])\n",
    "        pre_image_plane2.set_color('red')\n",
    "        pre_image_plane2.set_alpha(0.1)  # Adjust transparency here\n",
    "        ax.add_collection3d(pre_image_plane2)\n",
    "        \n",
    "        \n",
    "        if i == 0:\n",
    "            # Show the epipole for camera 1\n",
    "            cam_1_epipole = (camera_2_center[0]/camera_2_center[2], \n",
    "                             camera_2_center[1]/camera_2_center[2], \n",
    "                             camera_2_center[2]/camera_2_center[2])\n",
    "            ax.scatter(*cam_1_epipole, color='black', marker='x')\n",
    "            epipole_coords[0] = np.array([cam_1_epipole[0], cam_1_epipole[1]])\n",
    "\n",
    "            # Show the epipole for camera 2\n",
    "            cam_2_view_origin = K_inv @ np.array([0,0,0,1])\n",
    "            cam_2_epipole = (cam_2_view_origin[0]/cam_2_view_origin[2], \n",
    "                             cam_2_view_origin[1]/cam_2_view_origin[2],\n",
    "                             cam_2_view_origin[2]/cam_2_view_origin[2], 1)\n",
    "            epipole_coords[1] = np.array([cam_2_epipole[0], cam_2_epipole[1]])\n",
    "            cam_2_epipole = K @ cam_2_epipole\n",
    "            ax.scatter(*cam_2_epipole[:3], color='black', marker='x')\n",
    "\n",
    "            # Adjust view\n",
    "            ax.view_init(elev=elev_angle, azim=azim_angle, roll=roll_angle)\n",
    "\n",
    "        #show view in camera 1    \n",
    "        cam_1_coord[i] = np.array([world_coord[i][0]/world_coord[i][2], world_coord[i][1]/world_coord[i][2]])\n",
    "\n",
    "\n",
    "        camera_coords[i][0] = cam_1_coord[i]\n",
    "        camera_coords[i][1] = cam_2_coord[i]\n",
    "\n",
    "    \n",
    "    \n",
    "    update_2d_plots(fig,gs, camera_coords, epipole_coords, ep)\n",
    "    \n",
    "    lambda1 = world_coord[0][2]#math.sqrt((world_coord[0]**2)+(world_coord[1]**2)+(world_coord[2]**2))\n",
    "    lambda2 = FL2*temp_world0[2]# math.sqrt((world_coord[0]-camera_2_center[0])**2+(world_coord[1]-camera_2_center[1])**2+(world_coord[2]-camera_2_center[2])**2)\n",
    "    print(f'lambda1:{lambda1}')\n",
    "    print(f'lambda2:{lambda2}')\n",
    "    \n",
    "    x0 = np.append(camera_coords[0][0], 1)\n",
    "    \n",
    "    x0p = np.append(camera_coords[0][1], 1)\n",
    "    print(f'x0:{x0}')\n",
    "    #np.append(cam_2_coord, 1)\n",
    "    print(f'x0\\':{x0p}')\n",
    "    Tx = np.array([[0, -tz, ty],\n",
    "                   [tz, 0, -tx],\n",
    "                   [-ty, tx, 0]])\n",
    "    \n",
    "    R = np.array(rot[:3,:3])\n",
    "    print(f'x0TxRx0\\':{ x0 @ Tx @ R @ x0p}')\n",
    "    print(f'lambda1*x1:{lambda1*x0}')\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    print(f'R(lambda1*x0)+T:{R_inv @ (lambda1*x0 -np.array([tx, ty,tz])) }' )\n",
    "    print(f'lambda2*x0\\':{lambda2*x0p}')\n",
    "    \n",
    "    E_mat= Tx @ R\n",
    "    \n",
    "    \n",
    "    print(f'Determinant of E=TxR: {np.linalg.det(E_mat)}')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "elev_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Elevation')\n",
    "azim_slider = widgets.IntSlider(min=-180, max=180, step=1, value=90, description='Azimuth')\n",
    "roll_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-90, description='Roll')\n",
    "\n",
    "\n",
    "\n",
    "FL_slider2 = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1.0, description='Cam 2 Focal')\n",
    "\n",
    "alpha_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Cam2 Alpha')\n",
    "beta_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-150, description='Cam2 Beta')\n",
    "gamma_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-70, description='Cam2 Gamma')\n",
    "\n",
    "\n",
    "tx_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Tx')\n",
    "ty_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Ty')\n",
    "tz_slider = widgets.FloatSlider(min=0.0, max=5.0, step=0.1, value=4, description='Tz')\n",
    "\n",
    "# Group sliders into two columns\n",
    "left_box = widgets.VBox([elev_slider, azim_slider, roll_slider, Xw_slider, Yw_slider, Zw_slider ])\n",
    "right_box = widgets.VBox([ FL_slider2, alpha_slider, beta_slider, gamma_slider, tx_slider, ty_slider, tz_slider])\n",
    "\n",
    "epipoles_checkbox = widgets.Checkbox(value=False, description='Show Epipoles in 2D',disabled=False)\n",
    "\n",
    "# Combine the two columns into a single horizontal layout\n",
    "ui = widgets.HBox([left_box,  right_box])\n",
    "\n",
    "\n",
    "# Interactive widget\n",
    "out = widgets.interactive_output(update_plot, {'elev_angle': elev_slider, 'azim_angle': azim_slider, \n",
    "                                               'roll_angle': roll_slider, \n",
    "                                                'FL2': FL_slider2, \n",
    "                                               'Alpha': alpha_slider, 'Beta': beta_slider, 'Gamma': gamma_slider,\n",
    "                                              'tx': tx_slider, 'ty': ty_slider, 'tz': tz_slider, 'ep': epipoles_checkbox})\n",
    "\n",
    "sliders_box = widgets.VBox([elev_slider, azim_slider, roll_slider, \n",
    "                            FL_slider2, alpha_slider, beta_slider, \n",
    "                            gamma_slider, tx_slider, ty_slider, tz_slider, epipoles_checkbox])\n",
    "ui = widgets.HBox([sliders_box, out])\n",
    "\n",
    "\n",
    "# Display the UI and the output widget\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8c6de-28e7-4b72-bbe5-f95b2173cdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3bcf32a",
   "metadata": {},
   "source": [
    "## Point Features\n",
    "\n",
    "Every column of $\\mathcal{I}$ lies in a 4D space spanned by the columns of the matrix $\\Pi$. \n",
    "\n",
    "In order to have a solution to the above equation, the columns of $\\mathcal{I}$ and $\\Pi$ must therefore be linearly **dependent**,\n",
    "i.e. \n",
    "\\begin{equation}\n",
    "\tN_p \\equiv (\\Pi,\\mathcal{I}) = \\begin{bmatrix}\n",
    "\t\\Pi_1 & x_1 & 0 & \\cdots & 0 \\\\\n",
    "    \\Pi_2 & 0 & x_2 &  0 & 0\\\\\n",
    "\t\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\t\\Pi_m & 0 & 0 & \\cdots & x_m\\\\\n",
    "\t\\end{bmatrix} \\in \\mathbb{R}^{3m\\times(m+4)}\n",
    "\\end{equation}\n",
    "\n",
    "must have a non-trivial right null space. For $m \\geq 2$ (i.e. $3m \\geq m+4)$, full rank would be $m+4$. Linear dependence of columns therefore implies the rank constraint.\n",
    "\n",
    "\\begin{equation}\n",
    "\trank(N_p) \\leq m+3\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We can make a more compact formulation as follows.\n",
    "\n",
    "First introduce the following matrix.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathcal{I}^{\\perp} \\equiv \\begin{bmatrix}\n",
    "\tx_{1\\times} & 0 & \\cdots & 0 \\\\\n",
    "    0 & x_{2\\times} &  0 & 0\\\\\n",
    "\t\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\t0 & 0 & \\cdots & x_{m\\times}\\\\\n",
    "\t\\end{bmatrix} \\in \\mathbb{R}^{3m\\times3m}\n",
    "\\end{equation}\n",
    "\n",
    "which has the property of removing $\\mathcal{I}$\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathcal{I}^{\\perp}\\mathcal{I} = 0\n",
    "\\end{equation}\n",
    "\n",
    "So we can pre-muliply $\\mathcal{I}\\vec{\\lambda} =\\Pi\\mathbf{X}$ by $\\mathcal{I}^{\\perp}$ to get\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathcal{I}^{\\perp}\\Pi\\mathbf{X} = 0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Once again we see a solution defined by a null space.\n",
    "i.e. $X$ is in the null space of the matrix\n",
    "\n",
    "\\begin{equation}\n",
    "\tW_p \\equiv \\mathcal{I}^{\\perp}\\Pi = \n",
    "\t\\begin{bmatrix}\n",
    "\tx_{1\\times}\\Pi_1  \\\\\n",
    "   x_{2\\times}\\Pi_2 \\\\\n",
    "\t\\vdots \\\\\n",
    "    x_{m\\times}\\Pi_m\n",
    "\t\\end{bmatrix}  \\in \\mathbb{R}^{3m\\times4}\n",
    "\\end{equation}\n",
    "\n",
    "To have a non-trivial solution, we must have \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\text{rank}(W_p) \\leq 3\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee552d",
   "metadata": {},
   "source": [
    "## Multi-view Matrix of a point\n",
    "\n",
    "Beware! These matrices will begin to look very scary.\n",
    "\n",
    "DON'T PANIC!\n",
    "\n",
    "First, we want to rewrite the rank constraints in a more compact way so that it is more transparent what we are solving for.\n",
    "If we have $m$ images of a point we will show the first as a projection of the world coordinates and then show each of the others as a rotation and translation from the first.\n",
    "\n",
    "We are assuming that these are calibrated cameras and so $(K_i=I)$\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\Pi_1=[I, 0], \\Pi_2=[R_2, T_2],\\dots, \\Pi_m=[R_m,T_m] \\in \\mathbb{R}^{3\\times4}\n",
    "\\end{equation}\n",
    "\n",
    "As before we define the matrix $W_p$ as:\n",
    "\n",
    "\\begin{equation}\n",
    "\tW_p \\equiv \\mathcal{I}^{\\perp}\\Pi = \n",
    "\t\\begin{bmatrix}\n",
    "\tx_{1\\times}\\Pi_1  \\\\\n",
    "   x_{2\\times}\\Pi_2 \\\\\n",
    "\t\\vdots \\\\\n",
    "    x_{m\\times}\\Pi_m\n",
    "\t\\end{bmatrix}  \\in \\mathbb{R}^{3m\\times4}\n",
    "\\end{equation}\n",
    "\n",
    "The rank of the matrix $W_p$ is not affected if we multiply by a full-rank matrix $D_p \\in \\mathbb{R}^{4\\times5}$ as follows:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\tW_pD_p=\\begin{bmatrix}\n",
    "\tx_{1\\times}\\Pi_1  \\\\\n",
    "   x_{2\\times}\\Pi_2 \\\\\n",
    "\t\\vdots \\\\\n",
    "    x_{m\\times}\\Pi_m\n",
    "\t\\end{bmatrix} \n",
    "\t\\begin{bmatrix}\n",
    "    x_{1\\times} & x_1 & 0 \\\\\n",
    "    0 & 0 & 1\n",
    " \\end{bmatrix}= \n",
    " \\begin{bmatrix}\n",
    "    x_{1\\times}x_{1\\times} & 0 & 0\\\\\n",
    "    x_{2\\times}R_2x_{1\\times} & x_{2\\times}R_2x_1 & x_{2\\times}T_2\\\\\n",
    "    x_{3\\times}R_3x_{1\\times} & x_{3\\times}R_3x_1 & x_{3\\times}T_3\\\\\n",
    "    \\vdots & \\vdots & \\vdots\\\\\n",
    "    x_{m\\times}R_mx_{1\\times} & x_{m\\times}R_mx_1 & x_{m\\times}T_m\\\\\n",
    " \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So the rank$(W_p)\\leq3$ if and only if the submatrix\n",
    "\\begin{equation}\n",
    "\tM_p \\equiv \\begin{bmatrix}\n",
    " x_{2\\times}R_2x_1 & x_{2\\times}T_2\\\\\n",
    "     x_{3\\times}R_3x_1 & x_{3\\times}T_3\\\\\n",
    "     \\vdots & \\vdots\\\\\n",
    "    x_{m\\times}R_mx_1 & x_{m\\times}T_m\\\\\n",
    " \\end{bmatrix} \\in \\mathbb{R}^{3(m-1)\\times2}\n",
    "\\end{equation}\n",
    "\n",
    "has rank$(M_p)\\leq 1$.\n",
    "\n",
    "$M_p$ is called the multiple-view matrix of a point $p$.\n",
    "\n",
    "It relates the \n",
    "\n",
    "$x_1$ in the first view and the co-images $x_{i\\times}$ in the remaining views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af384fe1",
   "metadata": {},
   "source": [
    "## Analysis: Multi-View Constraint\n",
    "\n",
    "For any non-zero vectors $a_i, b_i \\in \\mathbb{R}^3, i=1,2,\\dots, n$, the matrix\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    " a_1 & b_1\\\\\n",
    "     a_2 & b_2\\\\\n",
    "     \\vdots & \\vdots\\\\\n",
    "    a_n & b_n \\\\\n",
    " \\end{bmatrix} \\in \\mathbb{R}^{3n\\times2}\t\n",
    "\\end{equation}\n",
    "\n",
    "is rank-deficient if and only if $a_ib^{\\top}_j - b_ia^{\\top}_j = 0$ for all $i,j=1,\\dots,n$. \n",
    "Applied to the rank constraint on $M_p$ we get:\n",
    "\n",
    "\\begin{equation}\n",
    "\tx_{i\\times}R_ix_1(x_{j\\times}T_j)^{\\top} - x_{i\\times}T_i(x_{j\\times}R_jx_1)^{\\top} = 0 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe3635",
   "metadata": {},
   "source": [
    "## The Tri-linear Constraint\n",
    "\n",
    "This gives us the tri-linear constraint\n",
    "\\begin{equation}\n",
    "\tx_{i\\times}(T_ix_1^{\\top}R_j^{\\top} - R_ix_1T^{\\top}_j)x_{j\\times} = 0 \n",
    "\\end{equation}\n",
    "\n",
    "This is a matrix equation giving $3\\times3 = 9$ scalar tri-linear equations, only four of which are linearly independent.\n",
    "From the equations \n",
    "\n",
    "$$x_{i\\times}R_ix_1(x_{j\\times}T_j)^{\\top} - x_{i\\times}T_i(x_{j\\times}R_jx_1)^{\\top} = 0 \\quad  \\forall i,j$$\n",
    "\n",
    "We see that as long as the entries in $x_{j\\times}T_j$ and $x_{j\\times}R_jx_1$ are non-zero, it follows from the above, that the two vectors $x_{i\\times}R_ix_1$ and $x_{i\\times}T_i$ are linearly dependent.  \n",
    "\n",
    "In other words: Except for degeneracies, the bi-linear (epipolar) constraints relating two views are already contained in the tri-linear constraints obtained for the multi-view scenario.\n",
    "\n",
    "Note that the equivalence between the bi-linear and tri-linear constraints on the one hand and the condition that rank($M_p\\leq 1$) on the other only holds if the vectors in $M_p$ are non-zero.\n",
    "\n",
    "In certain degenerate cases this is not fulfilled.\n",
    "\n",
    "An example of a rare degenerate case is that the point $p$ lies on the line through the optical centers $o_1$ and $o_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8401a63",
   "metadata": {},
   "source": [
    "## AV Degenerate Cases\n",
    "\n",
    "\n",
    "![](images/degenerateFOE.png)\n",
    "Vechicle Degenerate Case\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66d692",
   "metadata": {},
   "source": [
    "## Uniqueness of Pre-image\n",
    "\n",
    "Using the multiple-view matrix we obtain a more general and simpler characterization regarding the uniqueness of the pre-image.\n",
    "\n",
    "Given $m$ vectors representing the $m$ images of a point in $m$ views, they correspond to the same point in the 3D space if the rank of the $M_p$ matrix relative to any of the camera frames is one.\n",
    "\n",
    "If the rank is zero, the point is determined up to the line on which all the camera centers must lie.\n",
    "In summary we get the following\n",
    "\n",
    "\n",
    "- rank$(M_p)=2 \\rightarrow{}$ no point correspondence and empty pre-image.\n",
    "- rank$(M_p)=1 \\rightarrow{}$ point correspondence and unique pre-image. \n",
    "- rank$(M_p)=0 \\rightarrow{}$ point correspondence and pre-image not unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba40cd6",
   "metadata": {},
   "source": [
    "## Let's take stock\n",
    "\n",
    "What we have shown for points and lines is that we can construct a matrix, with a rank deficiency.\n",
    "\n",
    "Our solution lives in the null space of the matrix.\n",
    "\n",
    "If we construct a matrix with just the right rank then the null space will be the same dimensions as our solution. \n",
    "\n",
    "And that would mean a unique solution. \n",
    "\n",
    "At least up to scale.\n",
    "\n",
    "So our next move is to actually find the null space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d743df7",
   "metadata": {},
   "source": [
    "## Multi-view Factorisation\n",
    "\n",
    "With the two view case what we did here is to try to separate the structure (3D points) from the motion (Rotation and Translation).\n",
    "\n",
    "We will try the same here but beware that once again noise can cause these algorithms to be sub-optimal.\n",
    "\n",
    "So if we have $m$ images of $n$ points $p^j$ and we want to estimate the unknown projection matrix $\\Pi$, the condition rank$(M_p) \\leq 1$) states that the two columns of $M_p$ are linearly dependent. \n",
    "\n",
    "\n",
    "For the $j^{\\text{th}}$ point $p^j$ this implies\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{bmatrix}\n",
    "x_{2\\times}^jR_2x_1^j \\\\\n",
    "x_{3\\times}^jR_3x_1^j \\\\\n",
    "\\vdots\\\\\n",
    "x_{m\\times}^jR_mx_1^j \\\\\n",
    " \\end{bmatrix} + \\alpha^j\\begin{bmatrix}\n",
    "x_{2\\times}^jT_2 \\\\\n",
    "x_{3\\times}^jT_3 \\\\\n",
    "\\vdots\\\\\n",
    "x_{m\\times}^jT_m \\\\\n",
    " \\end{bmatrix} = 0 \\in \\mathbb{R}^{3(m-1)\\times1}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$\\alpha \\in \\mathbb{R}, j=1,\\dots,n$.\n",
    "\n",
    "Each row in the above equation can be obtained from $\\lambda^j_ix^j_i=\\lambda^j_1R_ix^j_1+T_i$ and multiplying by \n",
    "$x^j_{i\\times}$.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\tx^j_{i\\times}R_ix^j_1 + x^j_{i\\times}T_i/\\lambda^j_1=0\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, $\\alpha^j=1/\\lambda^j_1$ is nothing but the inverse of the depth of point $p^j$ w.r.t. the first frame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## If we know the structure\n",
    "If we know the depth of points i.e. their inverse $\\alpha^j$ then the equation above is linear in the camera motion parameters $R_i$ and $T_i$. \n",
    "\n",
    "We can use the stack operation $R^s_i=[r_{11},r_{21},r_{31},r_{12},r_{21},r_{32},r_{13},r_{23},r_{33}]^{\\top}\\in \\mathbb{R}^9$ and $T_i\\in \\mathbb{R}^3$, we have the linear equation system.\n",
    "\n",
    "\\begin{equation}\n",
    "\tP_i \\begin{bmatrix}\n",
    "R^s_i\\\\\n",
    "T_i\n",
    " \\end{bmatrix} = \\begin{bmatrix}\n",
    "{x^1_1}^{\\top} \\otimes x^1_{j\\times} & \\alpha^1x^1_{j\\times}\\\\\n",
    "{x^2_1}^{\\top} \\otimes x^2_{j\\times} & \\alpha^2x^2_{j\\times}\\\\\n",
    "\\vdots & \\vdots\\\\\n",
    "{x^n_1}^{\\top} \\otimes x^n_{j\\times} & \\alpha^nx^n_{j\\times}\\\\\n",
    " \\end{bmatrix}\\begin{bmatrix}\n",
    "R^s_i\\\\\n",
    "T_i\n",
    " \\end{bmatrix}=0 \\in \\mathbb{R}^{3n}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "The $P_i\\in \\mathbb{R}^{3n\\times12}$ is of rank=11 if more than 6 points in general position are used. \n",
    "\n",
    "If that is the case the null space of $P_i$ is 1-Dimensional and the projection matrix $\\Pi_i=(R_i,T_i)$ is given up to a scale factor.\n",
    "\n",
    "In practice you should use more than 6 points, obtain a full rank matrix and compute the solution by SVD using the smallest singular value.\n",
    "\n",
    "\n",
    "## If we know the motion\n",
    "If we know $\\Pi_i = (R_i, T_i), i=1,\\dots,m$, then we can estimate the structure i.e. $\\alpha^j, j=1,\\dots,m)$.\n",
    "\n",
    "The least squares solution to equation\n",
    "\n",
    "\\begin{equation}\n",
    "\tx^j_{i\\times}R_ix^j_1 + x^j_{i\\times}T_i/\\lambda^j_1=0\n",
    "\\end{equation} \n",
    "\n",
    "is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\alpha^j=-\\frac{\\sum^m_{i=2}(x^j_{i\\times}T_i)^{\\top}x_{i\\times}^jR_ix^j_1}{\\sum^m_{i=2}||x_{i\\times}^jT_i||^2}, j=1,\\dots,n.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc3939d",
   "metadata": {},
   "source": [
    "## But we don't know....\n",
    "Ok, so unfortunately we don't know the the structure or the motion and unlike the two view case we can't easily separate them.\n",
    "\n",
    "However if we can estimate either or both we can iteratively estimate each in turn while keeping the other fixed.\n",
    "\n",
    "These estimates could come from other sensors as part of a sensor fusion setup.\n",
    "\n",
    "Or we could apply the 8-point algorithm to the first two images to obtain an estimate of the structure parameters $\\alpha^j$.\n",
    "\n",
    "While the equation for $\\Pi_i$ makes use of the two frames 1 and $i$ only, the structure parameter estimation takes into account all frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95429c6",
   "metadata": {},
   "source": [
    "## Line Features\n",
    "\n",
    "Just as with the point features, we can use a rank constraint for lines. \n",
    "\n",
    "The co-images $l_i$ of a line $L$ spanned by a base $\\mathbf{X}_0$ and a direction $\\mathbf{V}$ we have:\n",
    "\n",
    "\\begin{equation}\n",
    "\tl_i^{\\top}\\Pi_i\\mathbf{X}_0=l_i^{\\top}\\Pi_i\\mathbf{V} = 0\n",
    "\\end{equation}\n",
    "\n",
    "Don't let the subtlety of the above equation fool you.\\\\ $\\mathbf{X}_0 \\neq \\mathbf{V}$\n",
    "Instead, it is saying that both $\\mathbf{X}_0$ and $\\mathbf{V}$ are in the null space of $l_i^{\\top}\\Pi_i$.\n",
    "\n",
    "\n",
    "Let us construct the following matrix\n",
    "\\begin{equation}\n",
    "\tW_l \\equiv \\begin{bmatrix}\n",
    "l_1^{\\top}\\Pi_1\\\\\n",
    "l_2^{\\top}\\Pi_2\\\\\n",
    "\\vdots\\\\\n",
    "l_m^{\\top}\\Pi_m\n",
    " \\end{bmatrix} \\in \\mathbb{R}^{m\\times4}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "An $m\\times4$ matrix can have rank of at most $4$.\n",
    "We know that there are at least two vectors living in the null space, i.e. $\\mathbf{X}_0 \\neq \\mathbf{V}$.\n",
    "\n",
    "Therefore $W_l$ can have rank of at most $2$\n",
    "So the question is, how many lines do we need?\n",
    "\n",
    "Well, if we had only two lines then that would give $rank=2$ right there, because $M_l \\in \\mathbb{R}^{m\\times4}$.\n",
    "\n",
    "But, this wouldn't be a solution.\n",
    "\n",
    "\n",
    "\n",
    "This would simply be stating that any two planes in a space must meet eachother in a line....somewhere.\n",
    "\n",
    "It wouldn't uniquely identify our line.\n",
    "\n",
    "Instead, if we have three or more planes and they all meet in the same line, then we have a unique identification.\n",
    "\n",
    "This is why lines don't appear in the two-view case but become useful in the multi-view case.\n",
    "\n",
    "\n",
    "\n",
    "## Only two views of a line\n",
    "\n",
    "\n",
    "![](images/LinesInTwoViews.png)\n",
    "Ambiguous reconstruction with only two views of a line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2d9e4",
   "metadata": {},
   "source": [
    "## Degenerate three-view of a line}\n",
    "\n",
    "\n",
    "![](images/Line3ViewDegenerate.png)\n",
    "\t\n",
    " \n",
    "\n",
    "\n",
    "## Consistent three-view of a line}\n",
    "\n",
    "\n",
    "![](images/Line3ViewGood.png)\n",
    "\t\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc89b01-cb58-47e6-8667-50fb0bad5f58",
   "metadata": {},
   "source": [
    "![\"HigherEd 4.0 is funded by the Human Capital Initiative Pillar 3. HCI Pillar 3 supports projects to enhance the innovation and agility in response to future skills needs\"](images/HCIFunding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b001b85-8150-4f6a-a5d3-3beb6a2fe0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
