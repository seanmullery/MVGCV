{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286254e6",
   "metadata": {},
   "source": [
    "# Epipolar Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546eb01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7acb8",
   "metadata": {},
   "source": [
    "## Opening Assumptions\n",
    "\n",
    "To solve this problem one step at a time we need to make some assumptions.\n",
    "\n",
    "- We have to assume that we are viewing a static scene and that we have two different views of this scene.\n",
    "- We will assume that we already have a set of point correspondences in our two views. \\\\How we did this is not our concern in this section.\n",
    "- We assume that we know the intrinsic parameters of the camera. And we will assume that they are the same for both views.\n",
    "\n",
    "\n",
    "## What we don't know\n",
    "Even with these assumptions we still have a problem on our hands. \n",
    "\n",
    "We know a set of 2D points but we don't know the extrinsic parameters and we don't know the 3D coordinates that correspond to the points in the images.\n",
    "\n",
    "This leads to a bit of a catch-22.\n",
    "To find the extrinsic parameters (rotation and translation) we need the 3D points.\n",
    "To find the 3D points we need to know the extrinsic camera parameters.\n",
    "\n",
    "## Route to solution\n",
    "\n",
    "- Disentangle the 3D coordinates from the camera motion (rotation/translation) algebraically.\n",
    "- Remove the 3D coordinates from the algebra so that we have equations in 2D image coordinates only.\n",
    "- Use these to solve for camera motion (using the 8-point algorithm).\n",
    "- Now we have the extrinsic parameters we can determine the 3D coordinates. \n",
    "- The 3D coordinates are the reconstruction.\n",
    "\t\n",
    "\n",
    "**Note: that this is solving a neat mathematics problem. So a gentle reminder: the real world is not a neat mathematics problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04705d",
   "metadata": {},
   "source": [
    "## Epipolar Geometry\n",
    "We will continue to call a point in the 3D world $X$.\n",
    "\n",
    "The projection of this into the first view results in 2D coordinate $x_1$ and its projection into the second view results in 2D coordinate $x_2$.\n",
    "\n",
    "We refer to the center of projection of the two cameras as $O_1$ and $O_2$.\n",
    "\n",
    "If we draw a line beteen the two centers of projection this line will intersect the two image planes, the points of intersection are called the epipoles $e_1$ for the intersection with the first view plane and $e_2$ for the intersection with image plane of the second view.\n",
    "\n",
    "Note: these intersections do not have to occur inside the small rectangle of the image. The image planes are assumed to continue forever in all directions.\n",
    " \n",
    "\n",
    "![](images/epipolarMuSh.png)\n",
    "[Image Credit: Mubarak Shah UCF](https://youtu.be/1X93H_0_W5k?t=1890)\n",
    " \n",
    "\n",
    "A triangle is formed between the 3D point $X$ and the two camera centers. This triangle is said to lie on the epipolar plane.\n",
    "The intersection of the epipolar plane with each image plane is called the epipolar lines $l_1$ and $l_2$.\n",
    "There is a single epipolar plane for each 3D point $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0938b9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab7cc897f1e4ff2bc4633e2d121fc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='Elevation', max=180, min=-180), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "camera_coords = np.array(np.zeros([2,2]))\n",
    "epipole_coords = np.array(np.zeros([2,2]))\n",
    "lambda1 = 0\n",
    "lambda2 = 0\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "\n",
    "\n",
    "\n",
    "def update_2d_plots(fig,gs, camera_coords, epipole_coords, ep):\n",
    "    \n",
    "    #fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    #axs = [fig.add_subplot(1, 3, 2), fig.add_subplot(1, 3, 3)]\n",
    "    axs = [fig.add_subplot(gs[0,3]),fig.add_subplot(gs[1,3])]\n",
    "    # Clear existing plots\n",
    "    axs[0].cla()\n",
    "    axs[1].cla()\n",
    "\n",
    "    # Update and configure the first plot (Camera 1 View)\n",
    "    axs[0].set_title('Camera 1 View')\n",
    "    axs[0].set_xlim(-1, 1)\n",
    "    axs[0].set_ylim(-0.5, 0.5)\n",
    "    rect1 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(0, 1, 1, 0.2))  # Cyan color\n",
    "    axs[0].add_patch(rect1)\n",
    "    axs[0].scatter(camera_coords[0][0], camera_coords[0][1], color='magenta')\n",
    "    axs[0].text(camera_coords[0][0], camera_coords[0][1], \"x1\", color='black')\n",
    "    if ep:\n",
    "        axs[0].scatter(epipole_coords[0][0], epipole_coords[0][1], color='black', marker='x')\n",
    "        axs[0].plot([camera_coords[0][0], epipole_coords[0][0]], [camera_coords[0][1], epipole_coords[0][1]], color='magenta')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update and configure the second plot (Camera 2 View)\n",
    "    axs[1].set_title('Camera 2 View')\n",
    "    axs[1].set_xlim(-1, 1)\n",
    "    axs[1].set_ylim(-0.5, 0.5)\n",
    "    rect2 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(1, 1, 0, 0.2))  # Yellow color\n",
    "    axs[1].add_patch(rect2)\n",
    "    axs[1].scatter(camera_coords[1][0], camera_coords[1][1], color='green')\n",
    "    axs[1].text(camera_coords[1][0], camera_coords[1][1], \"x2\", color='black')\n",
    "    if ep:\n",
    "        axs[1].scatter(epipole_coords[1][0], epipole_coords[1][1], color='black', marker='x')\n",
    "        axs[1].plot([camera_coords[1][0], epipole_coords[1][0]], [camera_coords[1][1], epipole_coords[1][1]], color='green')\n",
    "    # Redraw the plots\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "# Define a function to update the plot with both elevation and azimuth angles\n",
    "def update_plot(elev_angle, azim_angle, roll_angle,Xw, Yw, Zw, FL2, Alpha, Beta, Gamma, tx, ty, tz, ep):\n",
    "    # Create a new matplotlib figure and axis\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    gs = GridSpec(2, 4, figure=fig)\n",
    "    #fig = plt.figure(figsize=(30, 10))\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = fig.add_subplot(gs[0:4,:], projection='3d')\n",
    "    # Set axes labels and limits\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_xlim([-2, 2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_zlim([0, 4])\n",
    "    global E_mat\n",
    "    global rot\n",
    "\n",
    "\n",
    "    # Second camera array\n",
    "    K=np.array([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0,1,0],\n",
    "               [0,0,0,1]])\n",
    "    \n",
    "    T = np.array([[1,0,0,tx],\n",
    "                   [0,1,0,ty],\n",
    "                   [0,0,1,tz],\n",
    "                   [0,0,0,1]])\n",
    "    \n",
    "    # Individual Euler angle matrices\n",
    "    alphaRot = np.array([[1,0,0,0],\n",
    "       [0,math.cos(math.pi*Alpha/180),-math.sin(math.pi*Alpha/180),0],\n",
    "       [0,math.sin(math.pi*Alpha/180),math.cos(math.pi*Alpha/180),0],\n",
    "       [0,0,0,1]])\n",
    "    betaRot = np.array([[math.cos(math.pi*Beta/180),0,math.sin(math.pi*Beta/180),0],\n",
    "       [0,1,0,0],\n",
    "       [-math.sin(math.pi*Beta/180),0,math.cos(math.pi*Beta/180),0],\n",
    "       [0,0,0,1]])\n",
    "    gammaRot = np.array([\n",
    "       [math.cos(math.pi*Gamma/180),-math.sin(math.pi*Gamma/180),0,0],\n",
    "       [math.sin(math.pi*Gamma/180),math.cos(math.pi*Gamma/180),0,0],\n",
    "        [0,0,1,0],\n",
    "       [0,0,0,1]])\n",
    "    # Full rotation matrix but keep in mind that changing the order will change the rotation.\n",
    "    rot = alphaRot @ betaRot @ gammaRot\n",
    "    \n",
    "    # Camera two focal length only.\n",
    "    K_FL = ([[FL2,0,0,0],\n",
    "       [0,FL2,0,0],\n",
    "       [0,0,FL2,0],\n",
    "       [0,0,0,1]])\n",
    "    \n",
    "    '''Special matrix for the applying the focal length to the z-axis only \n",
    "    This is used to move the image sensor with the focal length but not resize the sensor\n",
    "    '''\n",
    "    K_plane = ([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0 ,FL2,0],\n",
    "               [0,0 ,0,1]])\n",
    "    \n",
    "    '''K_NF is the camera two matrix but without the focal length\n",
    "    This is to all the red, green and blue axes for camera two \n",
    "    to be the same size as for camera one. So this matrix is to help \n",
    "    with the visualisation only'''\n",
    "    K_NF = K @ T @ rot \n",
    "    \n",
    "    '''K_z is for the visualisation only. It allows the camera two frame to be shown in the correct\n",
    "    position without re-sizing the frame. Note, as we are only affecting the z-axis, ordering matters here.\n",
    "    You must do the rotation and translation first and only then extend the z-axis or otherwise you will rotate\n",
    "    and translate what you did to the z-axis and point it in another direction'''\n",
    "   \n",
    "    K_z = K @ T  @ rot @ K_plane \n",
    "   \n",
    "    '''This is the full camera two matrix (relative to camera one). The focal length is in multiples \n",
    "    of the first camera focal length. Hence the first camera focal lenght is fixed at 1 and therefore all \n",
    "    coordinates are in units of the focal length of camera one'''\n",
    "    \n",
    "    K = K  @ T  @  rot @  K_FL  \n",
    "    \n",
    "       \n",
    "    # Plotting the axes for the two cameras\n",
    "    axes = np.array([[[-.1, 0, 0],[.1, 0, 0]],\n",
    "            [[0, -.1, 0], [0, .1, 0]],\n",
    "            [[0, 0, 0], [0, 0, 0.5]]])\n",
    "               \n",
    "       \n",
    "    axes_cam_2 = axes.reshape(6,3)\n",
    "    axes_cam_2 = np.hstack([axes_cam_2, np.ones((6, 1))])\n",
    "    axes_cam_2 = K_NF @ axes_cam_2.transpose()\n",
    "    axes_cam_2 = axes_cam_2.transpose() \n",
    "    # Remove the last column\n",
    "    axes_cam_2 = axes_cam_2[:, :-1]\n",
    "    axes_cam_2 = axes_cam_2.reshape(3,2,3)\n",
    "    colors = ['r', 'g', 'b']  # Colors for each axis\n",
    "    for i in range(0, 3):\n",
    "        ax.plot([axes_cam_2[i][0][0], axes_cam_2[i][1][0]],  # X coordinates\n",
    "            [axes_cam_2[i][0][1], axes_cam_2[i][1][1]],  # Y coordinates\n",
    "            [axes_cam_2[i][0][2], axes_cam_2[i][1][2]],  # Z coordinates\n",
    "            color=colors[i]) \n",
    "        \n",
    "        ax.plot([axes[i][0][0], axes[i][1][0]],  # X coordinates\n",
    "            [axes[i][0][1], axes[i][1][1]],  # Y coordinates\n",
    "            [axes[i][0][2], axes[i][1][2]],  # Z coordinates\n",
    "            color=colors[i])   \n",
    "     \n",
    "    \n",
    "    \n",
    "    # adding the world coordinate point\n",
    "    world_coord = np.array([Xw, Yw, Zw])\n",
    "    ax.scatter(*world_coord, color='black')\n",
    "    ax.text(Xw, Yw, Zw, \"X\", color='black')\n",
    "\n",
    "    # Drawing a line from the origin to the  World coordinate point\n",
    "    ax.plot([0, world_coord[0]], [0, world_coord[1]], [0, world_coord[2]], color='magenta')\n",
    "    \n",
    "    # Creating a plane normal to the y-axis centered at (0, 1, 0)\n",
    "    x = np.linspace(-.6, .6, 10)\n",
    "    y = np.linspace(-.4, .4, 10)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.ones_like(X)  # Plane centered at Z=focal length\n",
    "    image_plane1 = np.array([X,Y,Z, np.ones_like(X)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    camera_2_center = K_NF @ np.array([0,0,0,1])\n",
    "    # Drawing a line from the camera 2 center to the point\n",
    "    ax.plot([camera_2_center[0], world_coord[0]], [camera_2_center[1], world_coord[1]], [camera_2_center[2], world_coord[2]], color='green')\n",
    "    \n",
    "    # Adding the plane with transparency\n",
    "    ax.plot_surface(image_plane1[0], image_plane1[1], image_plane1[2], color='cyan', alpha=0.2)\n",
    "    \n",
    "    # This reshapes image_plane1 for matrix multiplication by our camera 2 matrix\n",
    "    image_plane2 = K_z @ image_plane1.reshape(4,-1) \n",
    "    \n",
    "    # Reshaping back to original shape\n",
    "    image_plane2 = image_plane2.reshape(image_plane1.shape) \n",
    "    ax.plot_surface(image_plane2[0], image_plane2[1], image_plane2[2], color='yellow', alpha=0.2)\n",
    "    \n",
    "    # The intersection point where the magenta line intersects the image_plane1 Z = 1\n",
    "    intersection_point = (Xw/Zw, Yw/Zw, Zw/Zw)\n",
    "    cam_1_coord = np.array(intersection_point[:2])\n",
    "    \n",
    "    \n",
    "    ax.scatter(*intersection_point, color='magenta')\n",
    "    world_hom = np.array([Xw,Yw,Zw,1])\n",
    "    try:\n",
    "        K_inv = np.linalg.inv(K)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"The matrix is not invertible.\")\n",
    "        \n",
    "    temp_world = K_inv @ world_hom\n",
    "    \n",
    "    intersection_point_imageP2 = np.array([FL2*temp_world[0]/temp_world[2], \n",
    "                                  FL2*temp_world[1]/temp_world[2], \n",
    "                                  FL2*temp_world[2]/temp_world[2],1])\n",
    "    \n",
    "    x2 = intersection_point_imageP2[:3]\n",
    "    cam_2_coord = intersection_point_imageP2[:2]\n",
    "    \n",
    "    intersection_point_imageP2 = K_NF @ intersection_point_imageP2\n",
    "    pt = (intersection_point_imageP2[0],intersection_point_imageP2[1],intersection_point_imageP2[2])\n",
    "    ax.scatter(*pt, color='green')\n",
    "    \n",
    "    # draw line between camera centers\n",
    "    ax.plot([0, camera_2_center[0]], [0, camera_2_center[1]], [0, camera_2_center[2]], color='cyan')\n",
    "    \n",
    "    points = np.array([[0, 0, 0],  # Origin - camera 1 center\n",
    "                       [world_coord[0], world_coord[1], world_coord[2]],  # World coordinate\n",
    "                       [camera_2_center[0], camera_2_center[1], camera_2_center[2]]])  # Camera 2 center\n",
    "\n",
    "    # Shade in the Epipolar plane\n",
    "    epipoloar_plane = Poly3DCollection([points])\n",
    "    epipoloar_plane.set_color('grey')\n",
    "    epipoloar_plane.set_alpha(0.2)  # Adjust transparency here\n",
    "    ax.add_collection3d(epipoloar_plane)\n",
    "    \n",
    "    # Show the epipole for camera 1\n",
    "    cam_1_epipole = (camera_2_center[0]/camera_2_center[2], \n",
    "                     camera_2_center[1]/camera_2_center[2], \n",
    "                     camera_2_center[2]/camera_2_center[2])\n",
    "    ax.scatter(*cam_1_epipole, color='black', marker='x')\n",
    "    epipole_coords[0] = np.array([cam_1_epipole[0], cam_1_epipole[1]])\n",
    "    \n",
    "    # Show the epipole for camera 2\n",
    "    cam_2_view_origin = K_inv @ np.array([0,0,0,1])\n",
    "    cam_2_epipole = (cam_2_view_origin[0]/cam_2_view_origin[2], \n",
    "                     cam_2_view_origin[1]/cam_2_view_origin[2],\n",
    "                     cam_2_view_origin[2]/cam_2_view_origin[2], 1)\n",
    "    epipole_coords[1] = np.array([cam_2_epipole[0], cam_2_epipole[1]])\n",
    "    cam_2_epipole = K @ cam_2_epipole\n",
    "    ax.scatter(*cam_2_epipole[:3], color='black', marker='x')\n",
    "    \n",
    "    # Adjust view\n",
    "    ax.view_init(elev=elev_angle, azim=azim_angle, roll=roll_angle)\n",
    "    \n",
    "    #show view in camera 1    \n",
    "    cam_1_coord = np.array([world_coord[0]/world_coord[2], world_coord[1]/world_coord[2]])\n",
    "    \n",
    "    \n",
    "    camera_coords[0] = cam_1_coord\n",
    "    camera_coords[1] = cam_2_coord\n",
    "    \n",
    "    \n",
    "    \n",
    "    update_2d_plots(fig,gs, camera_coords, epipole_coords, ep)\n",
    "    \n",
    "    lambda1 = world_coord[2]#math.sqrt((world_coord[0]**2)+(world_coord[1]**2)+(world_coord[2]**2))\n",
    "    lambda2 = FL2*temp_world[2]# math.sqrt((world_coord[0]-camera_2_center[0])**2+(world_coord[1]-camera_2_center[1])**2+(world_coord[2]-camera_2_center[2])**2)\n",
    "    print(f'lambda1:{lambda1}')\n",
    "    print(f'lambda2:{lambda2}')\n",
    "    \n",
    "    x1 = np.append(cam_1_coord, 1)\n",
    "    print(f'x1:{x1}')\n",
    "    #np.append(cam_2_coord, 1)\n",
    "    print(f'x2:{x2}')\n",
    "    Tx = np.array([[0, -tz, ty],\n",
    "                   [tz, 0, -tx],\n",
    "                   [-ty, tx, 0]])\n",
    "    \n",
    "    R = np.array(rot[:3,:3])\n",
    "    print(f'x1TxRx2:{ x1 @ Tx @ R @ x2}')\n",
    "    print(f'lambda1*x1:{lambda1*x1}')\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    print(f'R(lambda1*x1)+T:{R_inv @ (lambda1*x1 -np.array([tx, ty,tz])) }' )\n",
    "    print(f'lambda2*x2:{lambda2*x2}')\n",
    "    \n",
    "    E_mat= Tx @ R\n",
    "    \n",
    "    \n",
    "    print(f'Determinant of E=TxR: {np.linalg.det(E_mat)}')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "elev_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Elevation')\n",
    "azim_slider = widgets.IntSlider(min=-180, max=180, step=1, value=90, description='Azimuth')\n",
    "roll_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-90, description='Roll')\n",
    "\n",
    "# Sliders for world coordinates\n",
    "Xw_slider = widgets.FloatSlider(min=-2, max=2, step=0.1, value=0, description='Xw')\n",
    "Yw_slider = widgets.FloatSlider(min=-2, max=2, step=0.1, value=0.5, description='Yw')\n",
    "Zw_slider = widgets.FloatSlider(min=0, max=5, step=0.1, value=3, description='Zw')\n",
    "\n",
    "FL_slider2 = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1.0, description='Cam 2 Focal')\n",
    "\n",
    "alpha_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Cam2 Alpha')\n",
    "beta_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-150, description='Cam2 Beta')\n",
    "gamma_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-70, description='Cam2 Gamma')\n",
    "\n",
    "\n",
    "tx_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Tx')\n",
    "ty_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Ty')\n",
    "tz_slider = widgets.FloatSlider(min=0.0, max=5.0, step=0.1, value=4, description='Tz')\n",
    "\n",
    "# Group sliders into two columns\n",
    "left_box = widgets.VBox([elev_slider, azim_slider, roll_slider, Xw_slider, Yw_slider, Zw_slider ])\n",
    "right_box = widgets.VBox([ FL_slider2, alpha_slider, beta_slider, gamma_slider, tx_slider, ty_slider, tz_slider])\n",
    "\n",
    "epipoles_checkbox = widgets.Checkbox(value=False, description='Show Epipoles in 2D',disabled=False)\n",
    "\n",
    "# Combine the two columns into a single horizontal layout\n",
    "ui = widgets.HBox([left_box,  right_box])\n",
    "\n",
    "\n",
    "# Interactive widget\n",
    "out = widgets.interactive_output(update_plot, {'elev_angle': elev_slider, 'azim_angle': azim_slider, \n",
    "                                               'roll_angle': roll_slider, 'Xw': Xw_slider, \n",
    "                                               'Yw': Yw_slider, 'Zw': Zw_slider, 'FL2': FL_slider2, \n",
    "                                               'Alpha': alpha_slider, 'Beta': beta_slider, 'Gamma': gamma_slider,\n",
    "                                              'tx': tx_slider, 'ty': ty_slider, 'tz': tz_slider, 'ep': epipoles_checkbox})\n",
    "\n",
    "sliders_box = widgets.VBox([elev_slider, azim_slider, roll_slider, \n",
    "                            Xw_slider, Yw_slider, Zw_slider,\n",
    "                            FL_slider2, alpha_slider, beta_slider, \n",
    "                            gamma_slider, tx_slider, ty_slider, tz_slider, epipoles_checkbox])\n",
    "ui = widgets.HBox([sliders_box, out])\n",
    "\n",
    "\n",
    "# Display the UI and the output widget\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b026790-9697-46dc-bd87-4534b41791d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb093d9",
   "metadata": {},
   "source": [
    "## Null Spaces\n",
    "\n",
    "A quick linear algebra reminder. A 2D plane in a 3D space is called a subspace (as long as it passes through the origin).\n",
    "\n",
    "We can define the plane with vectors that lie in the plane. Two independent vectors in the plane will be enough.\n",
    "\n",
    "However we can also define the plane by a single vector that is orthogonal to it, i.e. a vector that is in its null space.\n",
    "\n",
    "Keep this in mind as we proceed.\n",
    "\n",
    "**Ideas like null space, singular matrices, rank deficiency, zero determinant, SVD (Singular Value Decomposition) are all relevant here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63f019",
   "metadata": {},
   "source": [
    "## Simplifying the Intrinsic Parameters\n",
    "Firstly let's deal with the intrinsic parameters. \n",
    "\n",
    "We will assume no skew in the pixels and assume they are 1:1 aspect ratio. We will assume the focal length is 1. \n",
    "\n",
    "This idea of setting the focal length to one is just a way of saying that all other measures will be in units of the focal length. \n",
    "\n",
    "So rather than giving sizes in mm, cm or meters we instead give everything in units of the focal length. We can then convert everything easily if we know the focal length. \n",
    "\n",
    "We will assume that the origin in the center of the frame.\n",
    "\n",
    "So the Camera Intrinsic parameter matrix will be \n",
    "$$K= \\begin{bmatrix}\n",
    "                fs_x    & 0 & O_x  \\\\\n",
    "                0     & fs_y & O_y  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix} = \\begin{bmatrix}\n",
    "                1    & 0 & 0  \\\\\n",
    "                0     & 1 & 0  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}$$\n",
    "\n",
    "Which is the identity matrix, and this allows us to leave it out entirely in our mathematical manipulation.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222b012",
   "metadata": {},
   "source": [
    "## Epipolar Constraints\n",
    "So $x_1$ is the projection of the world 3D coordinate point onto the first camera image plane.\n",
    "$x_1$ will be in homogeneous coordinates.\n",
    "\n",
    "We will work with everything being relative to the first camera view. Therefore there will be zero rotation and translation for the mathematical description of the first camera view.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\lambda_1x_1 = X\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For the second camera view, we must describe this in terms of camera one. \n",
    "\n",
    "This means a Rotation and translation of the 3D point followed by the projection.\n",
    "\\begin{equation}\n",
    "\t\\lambda_2x_2=RX+T\n",
    "\\end{equation}\n",
    "Subsititute equation for the first view into the equation for the second view.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\lambda_2x_2=R(\\lambda_1x_1)+T\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da315e",
   "metadata": {},
   "source": [
    "## $T_{\\times}$\n",
    "\n",
    "Now it's convenient to remove the $+T$ out of this equation. So what we will do is multiply across by $T_{\\times}$.\n",
    "\n",
    "Remember how we defined this. Take a  vector $T$ and make it into a skew symmetric matrix that performs the cross product with $T$\n",
    "\\begin{equation}\n",
    "\t\\lambda_2T_{\\times}x_2=T_{\\times}R(\\lambda_1x_1)+T_{\\times}T\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\tT_{\\times}T = 0\n",
    "\\end{equation}\n",
    "\n",
    "So we can rewite equation for the second view as follows\n",
    "\\begin{equation}\n",
    "\t\\lambda_2T_{\\times}x_2=\\lambda_1T_{\\times}Rx_1\n",
    "\\end{equation}\n",
    "Remember that  $\\lambda_1$ and $\\lambda_2$ are simply scalar values and can be moved about more freely than vectors or matrices.\\\\\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd8666",
   "metadata": {},
   "source": [
    "## Getting rid of the $\\lambda$s\n",
    "Now this next step takes a bit of explaining.\n",
    "\n",
    "Firstly be aware that $T_{\\times}x_2$ will result in vector that is orthogonal to $x_2$. So if we get the dot product of $x_2$ with this vector we will get zero.\n",
    "So multiply across by $x_2$\n",
    "\\begin{equation}\n",
    "\t\\lambda_2x_2^{\\top}T_{\\times}x_2=\\lambda_1x_2^{\\top}T_{\\times}Rx_1\n",
    "\\end{equation}\n",
    "\n",
    "Which is \n",
    "\\begin{equation}\n",
    "\t0=\\lambda_1x_2^{\\top}T_{\\times}Rx_1\t\n",
    "\\end{equation}\n",
    "\n",
    "That's $\\lambda_2$ gone. Now divide both sides by $\\lambda_1$\n",
    "\\begin{equation}\n",
    "    0=\tx_2^{\\top}T_{\\times}Rx_1\t\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b47e9e",
   "metadata": {},
   "source": [
    "## The Epipolar Constraint\n",
    "\n",
    "\\begin{equation}\n",
    "    x_2^{\\top}T_{\\times}Rx_1=0\n",
    "\\end{equation}\n",
    "\n",
    "Is called the Epipolar Constraint.\n",
    "\n",
    "It is an important result as it relates 2D coordinates without mention of 3D coordinates.\n",
    "\n",
    "Remember our issue from earlier, the catch-22.\n",
    "In order to determine camera motion we needed the 3D coordinates and in order to determine the 3D coordinates we needed the camera motion.\n",
    "\n",
    "The epipolar constraint allows us to determine camera motion without 3D coordinates.\n",
    "\n",
    "So from there we can work towards getting the 3D coordinates.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096deac6",
   "metadata": {},
   "source": [
    "## The Essential matrix\n",
    "\n",
    "If we take the central part of the epipolar constraint, the part that doesn't include the two 2D coordinates we have what is called the essential matrix.\n",
    "\\begin{equation}\n",
    "\tE = T_{\\times}R \\quad \\in \\mathbb{R}^{3\\times3}\n",
    "\\end{equation}\n",
    "\n",
    "Due to this name the epipolar constraint may be variously called the the essential constraint or the bilinear constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d17a2",
   "metadata": {},
   "source": [
    "  \n",
    "## The Epipolar Plane\n",
    "$E$ is a $3\\times3$ matrix of rank 2 which means it has a left and right null space of 1. \n",
    "The epipolar constraint stipulates that the  triangle ($\\vec{O_1X},\\vec{O_2O_1},\\vec{O_2X})$ lies on a plane. \n",
    "\n",
    "Or we can say that those points alone can define the plane.\n",
    "\n",
    "Now, as these three are vectors, we can define a triple product with them.\n",
    "\n",
    "Remember that the triple product defines a volume. And a plane should have a volume of zero.\n",
    "So we can say\n",
    "\\begin{equation}\n",
    "\tx^{\\top}_2(T_{\\times} Rx_1) = 0 \n",
    "\\end{equation}\n",
    "   \n",
    "\n",
    "The plane is shown in grey in the interactive demonstration.\n",
    "\n",
    "**However, this all depends on perfect mathematics. Once you move it into a computer, \n",
    "the small amounts of round-off error cause this relationship to be a very small number rather than zero**\n",
    "**Take a look at the values for this and the determinant of $T_{\\times} R$ in the interactive demo. They are rarely perfectly zero**\n",
    "**More on this later**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee379c1",
   "metadata": {},
   "source": [
    "## A comment on invertability\n",
    "\n",
    "So we mentioned that $E$ has rank 2.\n",
    "\n",
    "Therefore it is singular and not invertible.\n",
    "\n",
    "Imagine you are given the epipolar constraint and asked to work back to get the $\\lambda$s.\n",
    "\n",
    "Can you do so?\n",
    "\n",
    "No, because you now have zero on the other side of the equation.\n",
    "\n",
    "This tells you that you have lost some things along the way.\n",
    "You may remember that rotation and translation (in 3D) has 6-DoF. \n",
    "\n",
    "The fact that we have lost information along the way means we cannot get away with just six equations to solve for these.\n",
    "\n",
    "We will need eight sets of corresponding points and hence this is called the 8-point algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645ad8d",
   "metadata": {},
   "source": [
    "## Some properties of $E$\n",
    "\n",
    "This is all great, but the truth is that the epipolar constraint is not really a nice identity.\n",
    "$E$ is a $3\\times3$ matrix. \n",
    "If we find enough point correspondences we should be able to recover $E$, but then what?\n",
    "\n",
    "We don't really want $E$, we want $R$ and $T$ so that we can tell how the camera moved between frames. \n",
    "How do we separate out $R$ and $T$?\n",
    "\n",
    "The space of all essential matrices is called the essential space defined as follows\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathcal{E} \\equiv \\left\\{ T_{\\times}R | R \\in SO(3), T \\in \\mathbb{R}^3 \\right\\} \\subset \\mathbb{R}^{3\\times3}\n",
    "\\end{equation}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19722fd2",
   "metadata": {},
   "source": [
    "## Some properties of $E$\n",
    "\n",
    "A nonzero matrix $E \\in \\mathbb{R}^{3\\times3}$ is an essential matrix (if and only if) $iff \\quad E$ has a singular value decomposition (SVD) $E=U\\Sigma V^{\\top}$ with \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\Sigma = \\begin{bmatrix}\n",
    "\\sigma & 0 & 0\\\\\n",
    "0 &\\sigma & 0\\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "for some $\\sigma>0$ and $U,V \\in SO(3)$.\n",
    "\n",
    "This is from the 1989 theorem _Characterization of a the essential Matrix_ by Huang & Faugeras.\n",
    "\n",
    "And it poses quite a problem because the space of essential matrices is not a linear one, so solving it by the normal linear algebra will find us a $3\\times3$ matrix, but it is unlikely to have these required properties.\n",
    "\n",
    "To add insult to injury here, even if we find the essential matrix, there are two possible decompositions of $R$ and $T$.\n",
    "\n",
    "The one bit of good news is that in general only one of the decompositions makes sense, i.e. gives positive depth values. Negative depth values would be behind the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa882910",
   "metadata": {},
   "source": [
    "## Two decompositions\n",
    "\n",
    "From the theorem _Pose recovery from the Essential Matrix_ - page 84 An invitation to 3D Vision by Ma, Kosecka, Soatto, Sastry.\n",
    "\n",
    "There are two relative poses $(R,T)$ with $R\\in SO(3)$ and $T\\in\\mathbb{R}^3$ corresponding to an essential matrix $E\\in\\mathcal{E}$\n",
    "\n",
    "\n",
    "For $E=U\\Sigma V^{\\top}$ we have:\n",
    "\\begin{equation}\n",
    "\t(T_{1\\times},R_1) = (UR_{Z(+\\frac{\\pi}{2})}\\Sigma U^{\\top}, UR^{\\top}_{Z(+\\frac{\\pi}{2})}V^{\\top})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t(T_{2\\times},R_2) = (UR_{Z(-\\frac{\\pi}{2})}\\Sigma U^{\\top}, UR^{\\top}_{Z(-\\frac{\\pi}{2})}V^{\\top})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "207d2db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: [-1. -1. -4.]\n",
      "T2: [1. 1. 4.]\n",
      "R1:[[ 0.235  0.97   0.06 ]\n",
      " [ 0.878 -0.186 -0.44 ]\n",
      " [-0.416  0.156 -0.896]]\n",
      "R2:[[-0.296 -0.814 -0.5  ]\n",
      " [-0.94   0.342  0.   ]\n",
      " [ 0.171  0.47  -0.866]]\n",
      "Actual Rotation: [[-0.296 -0.814 -0.5    0.   ]\n",
      " [-0.94   0.342  0.     0.   ]\n",
      " [ 0.171  0.47  -0.866  0.   ]\n",
      " [ 0.     0.     0.     1.   ]]\n"
     ]
    }
   ],
   "source": [
    "#In this code I am using the E matrix that I created from a known rotation and translation matrix\n",
    "# For the eight point algorithm we must determine the E matrix\n",
    "U, S, Vh = np.linalg.svd(E_mat)\n",
    "theta = np.pi / 2  # 90 degrees in radians\n",
    "S[2] = 0\n",
    "\n",
    "Rz = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                [np.sin(theta), np.cos(theta), 0],\n",
    "                [0, 0, 1]])\n",
    "Rzneg = np.array([[np.cos(-theta), -np.sin(-theta), 0],\n",
    "                [np.sin(-theta), np.cos(-theta), 0],\n",
    "                [0, 0, 1]])\n",
    "Tx1 = U @ Rz @ np.diag(S) @ U.T\n",
    "Tx2 = U @ Rzneg @ np.diag(S) @ U.T\n",
    "T1 = np.array([Tx1[2, 1], Tx1[0, 2], Tx1[1, 0]])\n",
    "T2 = np.array([Tx2[2, 1], Tx2[0, 2], Tx2[1, 0]])\n",
    "print(f'T1: {T1}')\n",
    "print(f'T2: {T2}')\n",
    "\n",
    "R1 = U @ Rz.T @ Vh\n",
    "R2 = U @ Rzneg.T @ Vh\n",
    "print(f'R1:{R1}')\n",
    "print(f'R2:{R2}')\n",
    "print(f'Actual Rotation: {rot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39faaf3",
   "metadata": {},
   "source": [
    "## Getting an essential matrix\n",
    "As mentioned earlier our standard linear Algebra methods will recover a $3\\times3$ matrix but this is unlikely to meet the stringent criteria of an Essential matrix.\n",
    "\n",
    "We have two options:\n",
    "\n",
    "- Recover whatever $3\\times3$ matrix we can from our linear methods and then project that on to the space of essential matrices. In other words use the closest essential matrix to the one we recover (whatever closest means) - Easy but lacking accuracy. \n",
    "- Optimise the epipolar constraints in the essential space $\\mathcal{E}$, accurate but requires non-linear constrained optimisation which is difficult and would require a whole new toolset of skills.\n",
    "\n",
    "\n",
    "We will use the first approach.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62ff027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d0a033e2f049159c7c99ea05c776c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='Elevation', max=180, min=-180), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "camera_coords = np.array(np.zeros([2,2,2]))\n",
    "epipole_coords = np.array(np.zeros([2,2]))\n",
    "lambda1 = 0\n",
    "lambda2 = 0\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "\n",
    "\n",
    "\n",
    "def update_2d_plots(fig,gs, camera_coords, epipole_coords, ep):\n",
    "    \n",
    "    #fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    #axs = [fig.add_subplot(1, 3, 2), fig.add_subplot(1, 3, 3)]\n",
    "    axs = [fig.add_subplot(gs[0,3]),fig.add_subplot(gs[1,3])]\n",
    "    # Clear existing plots\n",
    "    axs[0].cla()\n",
    "    axs[1].cla()\n",
    "    \n",
    "    # Update and configure the first plot (Camera 1 View)\n",
    "    axs[0].set_title('Camera 1 View')\n",
    "    axs[0].set_xlim(-1, 1)\n",
    "    axs[0].set_ylim(-0.5, 0.5)\n",
    "    rect1 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(0, 1, 1, 0.2))  # Cyan color\n",
    "    axs[0].add_patch(rect1)\n",
    "    for i in range(0,1):\n",
    "        axs[0].scatter(camera_coords[i][0][0], camera_coords[i][0][1], color='magenta')\n",
    "        axs[0].text(camera_coords[i][0][0], camera_coords[i][0][1], f\"x{i}\", color='black')\n",
    "        if ep:\n",
    "            axs[0].scatter(epipole_coords[0][0], epipole_coords[0][1], color='black', marker='x')\n",
    "            axs[0].plot([camera_coords[i][0][0], epipole_coords[0][0]], [camera_coords[i][0][1], epipole_coords[0][1]], color='green')\n",
    "\n",
    "\n",
    "        # Update and configure the second plot (Camera 2 View)\n",
    "    axs[1].set_title('Camera 2 View')\n",
    "    axs[1].set_xlim(-1, 1)\n",
    "    axs[1].set_ylim(-0.5, 0.5)\n",
    "    rect2 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(1, 1, 0, 0.2))  # Yellow color\n",
    "    axs[1].add_patch(rect2)\n",
    "    for i in range(0,1):\n",
    "        axs[1].scatter(camera_coords[i][1][0], camera_coords[i][1][1], color='green')\n",
    "        axs[1].text(camera_coords[i][1][0], camera_coords[i][1][1], f\"x{i}\\'\", color='black')\n",
    "        \n",
    "        if ep:\n",
    "            axs[1].plot([camera_coords[i][1][0], epipole_coords[1][0]], [camera_coords[i][1][1], epipole_coords[1][1]], color='magenta')\n",
    "            axs[1].scatter(epipole_coords[1][0], epipole_coords[1][1], color='black', marker='x')\n",
    "    # Redraw the plots\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "# Define a function to update the plot with both elevation and azimuth angles\n",
    "def update_plot(elev_angle, azim_angle, roll_angle, FL2, Alpha, Beta, Gamma, tx, ty, tz, ep):\n",
    "    # Create a new matplotlib figure and axis\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    gs = GridSpec(2, 4, figure=fig)\n",
    "    #fig = plt.figure(figsize=(30, 10))\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = fig.add_subplot(gs[0:4,:], projection='3d')\n",
    "    # Set axes labels and limits\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_xlim([-2, 2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_zlim([0, 4])\n",
    "    global E_mat\n",
    "    global rot\n",
    "\n",
    "\n",
    "    # Second camera array\n",
    "    K=np.array([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0,1,0],\n",
    "               [0,0,0,1]])\n",
    "    \n",
    "    T = np.array([[1,0,0,tx],\n",
    "                   [0,1,0,ty],\n",
    "                   [0,0,1,tz],\n",
    "                   [0,0,0,1]])\n",
    "    \n",
    "    # Individual Euler angle matrices\n",
    "    alphaRot = np.array([[1,0,0,0],\n",
    "       [0,math.cos(math.pi*Alpha/180),-math.sin(math.pi*Alpha/180),0],\n",
    "       [0,math.sin(math.pi*Alpha/180),math.cos(math.pi*Alpha/180),0],\n",
    "       [0,0,0,1]])\n",
    "    betaRot = np.array([[math.cos(math.pi*Beta/180),0,math.sin(math.pi*Beta/180),0],\n",
    "       [0,1,0,0],\n",
    "       [-math.sin(math.pi*Beta/180),0,math.cos(math.pi*Beta/180),0],\n",
    "       [0,0,0,1]])\n",
    "    gammaRot = np.array([\n",
    "       [math.cos(math.pi*Gamma/180),-math.sin(math.pi*Gamma/180),0,0],\n",
    "       [math.sin(math.pi*Gamma/180),math.cos(math.pi*Gamma/180),0,0],\n",
    "        [0,0,1,0],\n",
    "       [0,0,0,1]])\n",
    "    # Full rotation matrix but keep in mind that changing the order will change the rotation.\n",
    "    rot = alphaRot @ betaRot @ gammaRot\n",
    "    \n",
    "    # Camera two focal length only.\n",
    "    K_FL = ([[FL2,0,0,0],\n",
    "       [0,FL2,0,0],\n",
    "       [0,0,FL2,0],\n",
    "       [0,0,0,1]])\n",
    "    \n",
    "    '''Special matrix for the applying the focal length to the z-axis only \n",
    "    This is used to move the image sensor with the focal length but not resize the sensor\n",
    "    '''\n",
    "    K_plane = ([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0 ,FL2,0],\n",
    "               [0,0 ,0,1]])\n",
    "    \n",
    "    '''K_NF is the camera two matrix but without the focal length\n",
    "    This is to all the red, green and blue axes for camera two \n",
    "    to be the same size as for camera one. So this matrix is to help \n",
    "    with the visualisation only'''\n",
    "    K_NF = K @ T @ rot \n",
    "    \n",
    "    '''K_z is for the visualisation only. It allows the camera two frame to be shown in the correct\n",
    "    position without re-sizing the frame. Note, as we are only affecting the z-axis, ordering matters here.\n",
    "    You must do the rotation and translation first and only then extend the z-axis or otherwise you will rotate\n",
    "    and translate what you did to the z-axis and point it in another direction'''\n",
    "   \n",
    "    K_z = K @ T  @ rot @ K_plane \n",
    "   \n",
    "    '''This is the full camera two matrix (relative to camera one). The focal length is in multiples \n",
    "    of the first camera focal length. Hence the first camera focal lenght is fixed at 1 and therefore all \n",
    "    coordinates are in units of the focal length of camera one'''\n",
    "    \n",
    "    K = K  @ T  @  rot @  K_FL  \n",
    "    \n",
    "       \n",
    "    # Plotting the axes for the two cameras\n",
    "    axes = np.array([[[-.1, 0, 0],[.1, 0, 0]],\n",
    "            [[0, -.1, 0], [0, .1, 0]],\n",
    "            [[0, 0, 0], [0, 0, 0.5]]])\n",
    "               \n",
    "       \n",
    "    axes_cam_2 = axes.reshape(6,3)\n",
    "    axes_cam_2 = np.hstack([axes_cam_2, np.ones((6, 1))])\n",
    "    axes_cam_2 = K_NF @ axes_cam_2.transpose()\n",
    "    axes_cam_2 = axes_cam_2.transpose() \n",
    "    # Remove the last column\n",
    "    axes_cam_2 = axes_cam_2[:, :-1]\n",
    "    axes_cam_2 = axes_cam_2.reshape(3,2,3)\n",
    "    colors = ['r', 'g', 'b']  # Colors for each axis\n",
    "    for i in range(0, 3):\n",
    "        ax.plot([axes_cam_2[i][0][0], axes_cam_2[i][1][0]],  # X coordinates\n",
    "            [axes_cam_2[i][0][1], axes_cam_2[i][1][1]],  # Y coordinates\n",
    "            [axes_cam_2[i][0][2], axes_cam_2[i][1][2]],  # Z coordinates\n",
    "            color=colors[i]) \n",
    "        \n",
    "        ax.plot([axes[i][0][0], axes[i][1][0]],  # X coordinates\n",
    "            [axes[i][0][1], axes[i][1][1]],  # Y coordinates\n",
    "            [axes[i][0][2], axes[i][1][2]],  # Z coordinates\n",
    "            color=colors[i])   \n",
    "    \n",
    "    intersection_point = np.zeros([2,3])\n",
    "    cam_1_coord = np.zeros([2,2])\n",
    "    cam_2_coord = np.zeros([2,2])\n",
    "    intersection_point_imageP2 = np.zeros([2,4])\n",
    "    points = np.zeros([2,3,3])\n",
    "    world_coord = np.array([[0, 0.5, 3],\n",
    "                              [-0.5, 0, 3]])\n",
    "    for i in range(0,1):\n",
    "        # adding the world coordinate point\n",
    "        \n",
    "        ax.scatter(*world_coord[i], color='black')\n",
    "        ax.text(world_coord[i][0], world_coord[i][1], world_coord[i][2], f\"X{i}\", color='black')\n",
    "\n",
    "        # Drawing a line from the origin to the  World coordinate point\n",
    "        ax.plot([0, world_coord[i][0]], [0, world_coord[i][1]], [0, world_coord[i][2]], color='magenta')\n",
    "\n",
    "        # Creating a plane normal to the y-axis centered at (0, 1, 0)\n",
    "        x = np.linspace(-.6, .6, 10)\n",
    "        y = np.linspace(-.4, .4, 10)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.ones_like(X)  # Plane centered at Z=focal length\n",
    "        image_plane1 = np.array([X,Y,Z, np.ones_like(X)])\n",
    "\n",
    "\n",
    "\n",
    "        camera_2_center = K_NF @ np.array([0,0,0,1])\n",
    "        # Drawing a line from the camera 2 center to the point\n",
    "        ax.plot([camera_2_center[0], world_coord[i][0]], [camera_2_center[1], world_coord[i][1]], [camera_2_center[2], world_coord[i][2]], color='green')\n",
    "\n",
    "        # Adding the plane with transparency\n",
    "        if i == 0:\n",
    "            ax.plot_surface(image_plane1[0], image_plane1[1], image_plane1[2], color='cyan', alpha=0.2)\n",
    "\n",
    "            # This reshapes image_plane1 for matrix multiplication by our camera 2 matrix\n",
    "            image_plane2 = K_z @ image_plane1.reshape(4,-1) \n",
    "\n",
    "            # Reshaping back to original shape\n",
    "            image_plane2 = image_plane2.reshape(image_plane1.shape) \n",
    "            ax.plot_surface(image_plane2[0], image_plane2[1], image_plane2[2], color='yellow', alpha=0.2)\n",
    "\n",
    "        # The intersection point where the magenta line intersects the image_plane1 Z = 1\n",
    "        intersection_point[i] = (world_coord[i][0]/world_coord[i][2], world_coord[i][1]/world_coord[i][2], world_coord[i][2]/world_coord[i][2])\n",
    "        cam_1_coord[i] = np.array(intersection_point[i][:2])\n",
    "\n",
    "\n",
    "        \n",
    "        ax.scatter(*intersection_point[i], color='magenta')\n",
    "        \n",
    "        world_hom = np.array([world_coord[i][0],world_coord[i][1],world_coord[i][2],1])\n",
    "        try:\n",
    "            K_inv = np.linalg.inv(K)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"The matrix is not invertible.\")\n",
    "\n",
    "        temp_world = K_inv @ world_hom\n",
    "\n",
    "        intersection_point_imageP2[i] = np.array([FL2*temp_world[0]/temp_world[2], \n",
    "                                      FL2*temp_world[1]/temp_world[2], \n",
    "                                      FL2*temp_world[2]/temp_world[2],1])\n",
    "\n",
    "        x2 = intersection_point_imageP2[i][:3]\n",
    "        cam_2_coord[i] = intersection_point_imageP2[i][:2]\n",
    "\n",
    "        intersection_point_imageP2[i] = K_NF @ intersection_point_imageP2[i]\n",
    "        pt = (intersection_point_imageP2[i][0],intersection_point_imageP2[i][1],intersection_point_imageP2[i][2])\n",
    "        ax.scatter(*pt, color='green')\n",
    "\n",
    "        # draw line between camera centers\n",
    "        ax.plot([0, camera_2_center[0]], [0, camera_2_center[1]], [0, camera_2_center[2]], color='cyan')\n",
    "\n",
    "        points[i] = np.array([[0, 0, 0],  # Origin - camera 1 center\n",
    "                           [world_coord[i][0], world_coord[i][1], world_coord[i][2]],  # World coordinate\n",
    "                           [camera_2_center[0], camera_2_center[1], camera_2_center[2]]])  # Camera 2 center\n",
    "\n",
    "        # Shade in the Epipolar plane\n",
    "        epipoloar_plane = Poly3DCollection([points[i]])\n",
    "        epipoloar_plane.set_color('grey')\n",
    "        epipoloar_plane.set_alpha(0.2)  # Adjust transparency here\n",
    "        ax.add_collection3d(epipoloar_plane)\n",
    "        \n",
    "        if i == 0:\n",
    "            # Show the epipole for camera 1\n",
    "            cam_1_epipole = (camera_2_center[0]/camera_2_center[2], \n",
    "                             camera_2_center[1]/camera_2_center[2], \n",
    "                             camera_2_center[2]/camera_2_center[2])\n",
    "            ax.scatter(*cam_1_epipole, color='black', marker='x')\n",
    "            epipole_coords[0] = np.array([cam_1_epipole[0], cam_1_epipole[1]])\n",
    "\n",
    "            # Show the epipole for camera 2\n",
    "            cam_2_view_origin = K_inv @ np.array([0,0,0,1])\n",
    "            cam_2_epipole = (cam_2_view_origin[0]/cam_2_view_origin[2], \n",
    "                             cam_2_view_origin[1]/cam_2_view_origin[2],\n",
    "                             cam_2_view_origin[2]/cam_2_view_origin[2], 1)\n",
    "            epipole_coords[1] = np.array([cam_2_epipole[0], cam_2_epipole[1]])\n",
    "            cam_2_epipole = K @ cam_2_epipole\n",
    "            ax.scatter(*cam_2_epipole[:3], color='black', marker='x')\n",
    "\n",
    "            # Adjust view\n",
    "            ax.view_init(elev=elev_angle, azim=azim_angle, roll=roll_angle)\n",
    "\n",
    "        #show view in camera 1    \n",
    "        cam_1_coord[i] = np.array([world_coord[i][0]/world_coord[i][2], world_coord[i][1]/world_coord[i][2]])\n",
    "\n",
    "\n",
    "        camera_coords[i][0] = cam_1_coord[i]\n",
    "        camera_coords[i][1] = cam_2_coord[i]\n",
    "\n",
    "    \n",
    "    \n",
    "    update_2d_plots(fig,gs, camera_coords, epipole_coords, ep)\n",
    "    \n",
    "    lambda1 = world_coord[0][2]#math.sqrt((world_coord[0]**2)+(world_coord[1]**2)+(world_coord[2]**2))\n",
    "    lambda2 = FL2*temp_world[2]# math.sqrt((world_coord[0]-camera_2_center[0])**2+(world_coord[1]-camera_2_center[1])**2+(world_coord[2]-camera_2_center[2])**2)\n",
    "    print(f'lambda1:{lambda1}')\n",
    "    print(f'lambda2:{lambda2}')\n",
    "    \n",
    "    x1 = np.append(cam_1_coord[0], 1)\n",
    "    x2 = np.append(camera_coords[0][1], 1)\n",
    "    print(f'x1:{x1}')\n",
    "    #np.append(cam_2_coord, 1)\n",
    "    print(f'x2:{x2}')\n",
    "    Tx = np.array([[0, -tz, ty],\n",
    "                   [tz, 0, -tx],\n",
    "                   [-ty, tx, 0]])\n",
    "    \n",
    "    R = np.array(rot[:3,:3])\n",
    "    print(f'x1TxRx2:{ x1 @ Tx @ R @ x2}')\n",
    "    print(f'lambda1*x1:{lambda1*x1}')\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    print(f'R(lambda1*x1)+T:{R_inv @ (lambda1*x1 -np.array([tx, ty,tz])) }' )\n",
    "    print(f'lambda2*x2:{lambda2*x2}')\n",
    "    \n",
    "    E_mat= Tx @ R\n",
    "    \n",
    "    \n",
    "    print(f'Determinant of E=TxR: {np.linalg.det(E_mat)}')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "elev_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Elevation')\n",
    "azim_slider = widgets.IntSlider(min=-180, max=180, step=1, value=90, description='Azimuth')\n",
    "roll_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-90, description='Roll')\n",
    "\n",
    "\n",
    "\n",
    "FL_slider2 = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1.0, description='Cam 2 Focal')\n",
    "\n",
    "alpha_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Cam2 Alpha')\n",
    "beta_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-150, description='Cam2 Beta')\n",
    "gamma_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-70, description='Cam2 Gamma')\n",
    "\n",
    "\n",
    "tx_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Tx')\n",
    "ty_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Ty')\n",
    "tz_slider = widgets.FloatSlider(min=0.0, max=5.0, step=0.1, value=4, description='Tz')\n",
    "\n",
    "# Group sliders into two columns\n",
    "left_box = widgets.VBox([elev_slider, azim_slider, roll_slider, Xw_slider, Yw_slider, Zw_slider ])\n",
    "right_box = widgets.VBox([ FL_slider2, alpha_slider, beta_slider, gamma_slider, tx_slider, ty_slider, tz_slider])\n",
    "\n",
    "epipoles_checkbox = widgets.Checkbox(value=False, description='Show Epipoles in 2D',disabled=False)\n",
    "\n",
    "# Combine the two columns into a single horizontal layout\n",
    "ui = widgets.HBox([left_box,  right_box])\n",
    "\n",
    "\n",
    "# Interactive widget\n",
    "out = widgets.interactive_output(update_plot, {'elev_angle': elev_slider, 'azim_angle': azim_slider, \n",
    "                                               'roll_angle': roll_slider, \n",
    "                                                'FL2': FL_slider2, \n",
    "                                               'Alpha': alpha_slider, 'Beta': beta_slider, 'Gamma': gamma_slider,\n",
    "                                              'tx': tx_slider, 'ty': ty_slider, 'tz': tz_slider, 'ep': epipoles_checkbox})\n",
    "\n",
    "sliders_box = widgets.VBox([elev_slider, azim_slider, roll_slider, \n",
    "                            FL_slider2, alpha_slider, beta_slider, \n",
    "                            gamma_slider, tx_slider, ty_slider, tz_slider, epipoles_checkbox])\n",
    "ui = widgets.HBox([sliders_box, out])\n",
    "\n",
    "\n",
    "# Display the UI and the output widget\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "3b872abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b070d6a5f147ad916b6052955a24dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='Elevation', max=180, min=-180), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "camera_coords = np.array(np.zeros([8,2,2]))\n",
    "epipole_coords = np.array(np.zeros([2,2]))\n",
    "lambda1 = 0\n",
    "lambda2 = 0\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "num_points = 8\n",
    "\n",
    "\n",
    "\n",
    "def update_2d_plots(fig,gs, camera_coords, epipole_coords, ep):\n",
    "    \n",
    "    #fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    #axs = [fig.add_subplot(1, 3, 2), fig.add_subplot(1, 3, 3)]\n",
    "    axs = [fig.add_subplot(gs[0,3]),fig.add_subplot(gs[1,3])]\n",
    "    # Clear existing plots\n",
    "    axs[0].cla()\n",
    "    axs[1].cla()\n",
    "    \n",
    "    # Update and configure the first plot (Camera 1 View)\n",
    "    axs[0].set_title('Camera 1 View')\n",
    "    axs[0].set_xlim(-1, 1)\n",
    "    axs[0].set_ylim(-0.5, 0.5)\n",
    "    rect1 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(0, 1, 1, 0.2))  # Cyan color\n",
    "    axs[0].add_patch(rect1)\n",
    "    for i in range(0,num_points):\n",
    "        axs[0].scatter(camera_coords[i][0][0], camera_coords[i][0][1], color='magenta')\n",
    "        axs[0].text(camera_coords[i][0][0], camera_coords[i][0][1], f\"x{i}\", color='black')\n",
    "        if ep:\n",
    "            axs[0].scatter(epipole_coords[0][0], epipole_coords[0][1], color='black', marker='x')\n",
    "            axs[0].plot([camera_coords[i][0][0], epipole_coords[0][0]], [camera_coords[i][0][1], epipole_coords[0][1]], color='green')\n",
    "\n",
    "\n",
    "        # Update and configure the second plot (Camera 2 View)\n",
    "    axs[1].set_title('Camera 2 View')\n",
    "    axs[1].set_xlim(-1, 1)\n",
    "    axs[1].set_ylim(-0.5, 0.5)\n",
    "    rect2 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(1, 1, 0, 0.2))  # Yellow color\n",
    "    axs[1].add_patch(rect2)\n",
    "    for i in range(0,num_points):\n",
    "        axs[1].scatter(camera_coords[i][1][0], camera_coords[i][1][1], color='green')\n",
    "        axs[1].text(camera_coords[i][1][0], camera_coords[i][1][1], f\"x{i}\\'\", color='black')\n",
    "        \n",
    "        if ep:\n",
    "            axs[1].plot([camera_coords[i][1][0], epipole_coords[1][0]], [camera_coords[i][1][1], epipole_coords[1][1]], color='magenta')\n",
    "            axs[1].scatter(epipole_coords[1][0], epipole_coords[1][1], color='black', marker='x')\n",
    "    # Redraw the plots\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "# Define a function to update the plot with both elevation and azimuth angles\n",
    "def update_plot(elev_angle, azim_angle, roll_angle, FL2, Alpha, Beta, Gamma, tx, ty, tz, ep):\n",
    "    # Create a new matplotlib figure and axis\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    gs = GridSpec(2, 4, figure=fig)\n",
    "    #fig = plt.figure(figsize=(30, 10))\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = fig.add_subplot(gs[0:4,:], projection='3d')\n",
    "    # Set axes labels and limits\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_xlim([-2, 2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_zlim([0, 4])\n",
    "    global E_mat\n",
    "    global rot\n",
    "    global T\n",
    "    global world_coord\n",
    "\n",
    "\n",
    "    # Second camera array\n",
    "    K=np.array([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0,1,0],\n",
    "               [0,0,0,1]])\n",
    "    \n",
    "    T = np.array([[1,0,0,tx],\n",
    "                   [0,1,0,ty],\n",
    "                   [0,0,1,tz],\n",
    "                   [0,0,0,1]])\n",
    "    \n",
    "    # Individual Euler angle matrices\n",
    "    alphaRot = np.array([[1,0,0,0],\n",
    "       [0,math.cos(math.pi*Alpha/180),-math.sin(math.pi*Alpha/180),0],\n",
    "       [0,math.sin(math.pi*Alpha/180),math.cos(math.pi*Alpha/180),0],\n",
    "       [0,0,0,1]])\n",
    "    betaRot = np.array([[math.cos(math.pi*Beta/180),0,math.sin(math.pi*Beta/180),0],\n",
    "       [0,1,0,0],\n",
    "       [-math.sin(math.pi*Beta/180),0,math.cos(math.pi*Beta/180),0],\n",
    "       [0,0,0,1]])\n",
    "    gammaRot = np.array([\n",
    "       [math.cos(math.pi*Gamma/180),-math.sin(math.pi*Gamma/180),0,0],\n",
    "       [math.sin(math.pi*Gamma/180),math.cos(math.pi*Gamma/180),0,0],\n",
    "        [0,0,1,0],\n",
    "       [0,0,0,1]])\n",
    "    # Full rotation matrix but keep in mind that changing the order will change the rotation.\n",
    "    rot = alphaRot @ betaRot @ gammaRot\n",
    "    \n",
    "    # Camera two focal length only.\n",
    "    K_FL = ([[FL2,0,0,0],\n",
    "       [0,FL2,0,0],\n",
    "       [0,0,FL2,0],\n",
    "       [0,0,0,1]])\n",
    "    \n",
    "    '''Special matrix for the applying the focal length to the z-axis only \n",
    "    This is used to move the image sensor with the focal length but not resize the sensor\n",
    "    '''\n",
    "    K_plane = ([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0 ,FL2,0],\n",
    "               [0,0 ,0,1]])\n",
    "    \n",
    "    '''K_NF is the camera two matrix but without the focal length\n",
    "    This is to all the red, green and blue axes for camera two \n",
    "    to be the same size as for camera one. So this matrix is to help \n",
    "    with the visualisation only'''\n",
    "    K_NF = K @ T @ rot \n",
    "    \n",
    "    '''K_z is for the visualisation only. It allows the camera two frame to be shown in the correct\n",
    "    position without re-sizing the frame. Note, as we are only affecting the z-axis, ordering matters here.\n",
    "    You must do the rotation and translation first and only then extend the z-axis or otherwise you will rotate\n",
    "    and translate what you did to the z-axis and point it in another direction'''\n",
    "   \n",
    "    K_z = K @ T  @ rot @ K_plane \n",
    "   \n",
    "    '''This is the full camera two matrix (relative to camera one). The focal length is in multiples \n",
    "    of the first camera focal length. Hence the first camera focal lenght is fixed at 1 and therefore all \n",
    "    coordinates are in units of the focal length of camera one'''\n",
    "    \n",
    "    K = K  @ T  @  rot @  K_FL  \n",
    "    \n",
    "       \n",
    "    # Plotting the axes for the two cameras\n",
    "    axes = np.array([[[-.1, 0, 0],[.1, 0, 0]],\n",
    "            [[0, -.1, 0], [0, .1, 0]],\n",
    "            [[0, 0, 0], [0, 0, 0.5]]])\n",
    "               \n",
    "       \n",
    "    axes_cam_2 = axes.reshape(6,3)\n",
    "    axes_cam_2 = np.hstack([axes_cam_2, np.ones((6, 1))])\n",
    "    axes_cam_2 = K_NF @ axes_cam_2.transpose()\n",
    "    axes_cam_2 = axes_cam_2.transpose() \n",
    "    # Remove the last column\n",
    "    axes_cam_2 = axes_cam_2[:, :-1]\n",
    "    axes_cam_2 = axes_cam_2.reshape(3,2,3)\n",
    "    colors = ['r', 'g', 'b']  # Colors for each axis\n",
    "    for i in range(0, 3):\n",
    "        ax.plot([axes_cam_2[i][0][0], axes_cam_2[i][1][0]],  # X coordinates\n",
    "            [axes_cam_2[i][0][1], axes_cam_2[i][1][1]],  # Y coordinates\n",
    "            [axes_cam_2[i][0][2], axes_cam_2[i][1][2]],  # Z coordinates\n",
    "            color=colors[i]) \n",
    "        \n",
    "        ax.plot([axes[i][0][0], axes[i][1][0]],  # X coordinates\n",
    "            [axes[i][0][1], axes[i][1][1]],  # Y coordinates\n",
    "            [axes[i][0][2], axes[i][1][2]],  # Z coordinates\n",
    "            color=colors[i])   \n",
    "    \n",
    "    intersection_point = np.zeros([8,3])\n",
    "    cam_1_coord = np.zeros([8,2])\n",
    "    cam_2_coord = np.zeros([8,2])\n",
    "    intersection_point_imageP2 = np.zeros([8,4])\n",
    "    points = np.zeros([8,3,3])\n",
    "    world_coord = np.array([[-0.5, 0.5, 1.3],\n",
    "                            [-0.5, 0.2, 2.5],\n",
    "                            [-0.5, 0.3, 1.5],\n",
    "                            [-0.2,0.4,2.4],\n",
    "                            [-0.5,0.5,2.7],\n",
    "                             [0.2,0.7,1.9],\n",
    "                             [-0.3,0.7,2.7],\n",
    "                             [-0.2,0.8,2.3]],) \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,num_points):\n",
    "        # adding the world coordinate point\n",
    "        \n",
    "        ax.scatter(*world_coord[i], color='black')\n",
    "        ax.text(world_coord[i][0], world_coord[i][1], world_coord[i][2], f\"X{i}\", color='black')\n",
    "\n",
    "        # Drawing a line from the origin to the  World coordinate point\n",
    "        ax.plot([0, world_coord[i][0]], [0, world_coord[i][1]], [0, world_coord[i][2]], color='magenta')\n",
    "\n",
    "        # Creating a plane normal to the y-axis centered at (0, 1, 0)\n",
    "        x = np.linspace(-.6, .6, 10)\n",
    "        y = np.linspace(-.4, .4, 10)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.ones_like(X)  # Plane centered at Z=focal length\n",
    "        image_plane1 = np.array([X,Y,Z, np.ones_like(X)])\n",
    "\n",
    "\n",
    "\n",
    "        camera_2_center = K_NF @ np.array([0,0,0,1])\n",
    "        # Drawing a line from the camera 2 center to the point\n",
    "        ax.plot([camera_2_center[0], world_coord[i][0]], [camera_2_center[1], world_coord[i][1]], [camera_2_center[2], world_coord[i][2]], color='green')\n",
    "\n",
    "        # Adding the plane with transparency\n",
    "        if i == 0:\n",
    "            ax.plot_surface(image_plane1[0], image_plane1[1], image_plane1[2], color='cyan', alpha=0.2)\n",
    "\n",
    "            # This reshapes image_plane1 for matrix multiplication by our camera 2 matrix\n",
    "            image_plane2 = K_z @ image_plane1.reshape(4,-1) \n",
    "\n",
    "            # Reshaping back to original shape\n",
    "            image_plane2 = image_plane2.reshape(image_plane1.shape) \n",
    "            ax.plot_surface(image_plane2[0], image_plane2[1], image_plane2[2], color='yellow', alpha=0.2)\n",
    "\n",
    "        # The intersection point where the magenta line intersects the image_plane1 Z = 1\n",
    "        intersection_point[i] = (world_coord[i][0]/world_coord[i][2], world_coord[i][1]/world_coord[i][2], world_coord[i][2]/world_coord[i][2])\n",
    "        cam_1_coord[i] = np.array(intersection_point[i][:2])\n",
    "\n",
    "\n",
    "        \n",
    "        ax.scatter(*intersection_point[i], color='magenta')\n",
    "        \n",
    "        world_hom = np.array([world_coord[i][0],world_coord[i][1],world_coord[i][2],1])\n",
    "        try:\n",
    "            K_inv = np.linalg.inv(K)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"The matrix is not invertible.\")\n",
    "\n",
    "        temp_world = K_inv @ world_hom\n",
    "        if i == 0:\n",
    "            temp_world0=temp_world\n",
    "        intersection_point_imageP2[i] = np.array([FL2*temp_world[0]/temp_world[2], \n",
    "                                      FL2*temp_world[1]/temp_world[2], \n",
    "                                      FL2*temp_world[2]/temp_world[2],1])\n",
    "\n",
    "        x2 = intersection_point_imageP2[i][:3]\n",
    "        cam_2_coord[i] = intersection_point_imageP2[i][:2]\n",
    "\n",
    "        intersection_point_imageP2[i] = K_NF @ intersection_point_imageP2[i]\n",
    "        pt = (intersection_point_imageP2[i][0],intersection_point_imageP2[i][1],intersection_point_imageP2[i][2])\n",
    "        ax.scatter(*pt, color='green')\n",
    "\n",
    "        # draw line between camera centers\n",
    "        ax.plot([0, camera_2_center[0]], [0, camera_2_center[1]], [0, camera_2_center[2]], color='cyan')\n",
    "\n",
    "        points[i] = np.array([[0, 0, 0],  # Origin - camera 1 center\n",
    "                           [world_coord[i][0], world_coord[i][1], world_coord[i][2]],  # World coordinate\n",
    "                           [camera_2_center[0], camera_2_center[1], camera_2_center[2]]])  # Camera 2 center\n",
    "\n",
    "        # Shade in the Epipolar plane\n",
    "        epipoloar_plane = Poly3DCollection([points[i]])\n",
    "        epipoloar_plane.set_color('grey')\n",
    "        epipoloar_plane.set_alpha(0.2)  # Adjust transparency here\n",
    "        ax.add_collection3d(epipoloar_plane)\n",
    "        \n",
    "        if i == 0:\n",
    "            # Show the epipole for camera 1\n",
    "            cam_1_epipole = (camera_2_center[0]/camera_2_center[2], \n",
    "                             camera_2_center[1]/camera_2_center[2], \n",
    "                             camera_2_center[2]/camera_2_center[2])\n",
    "            ax.scatter(*cam_1_epipole, color='black', marker='x')\n",
    "            epipole_coords[0] = np.array([cam_1_epipole[0], cam_1_epipole[1]])\n",
    "\n",
    "            # Show the epipole for camera 2\n",
    "            cam_2_view_origin = K_inv @ np.array([0,0,0,1])\n",
    "            cam_2_epipole = (cam_2_view_origin[0]/cam_2_view_origin[2], \n",
    "                             cam_2_view_origin[1]/cam_2_view_origin[2],\n",
    "                             cam_2_view_origin[2]/cam_2_view_origin[2], 1)\n",
    "            epipole_coords[1] = np.array([cam_2_epipole[0], cam_2_epipole[1]])\n",
    "            cam_2_epipole = K @ cam_2_epipole\n",
    "            ax.scatter(*cam_2_epipole[:3], color='black', marker='x')\n",
    "\n",
    "            # Adjust view\n",
    "            ax.view_init(elev=elev_angle, azim=azim_angle, roll=roll_angle)\n",
    "\n",
    "        #show view in camera 1    \n",
    "        cam_1_coord[i] = np.array([world_coord[i][0]/world_coord[i][2], world_coord[i][1]/world_coord[i][2]])\n",
    "\n",
    "\n",
    "        camera_coords[i][0] = cam_1_coord[i]\n",
    "        camera_coords[i][1] = cam_2_coord[i]\n",
    "\n",
    "    \n",
    "    \n",
    "    update_2d_plots(fig,gs, camera_coords, epipole_coords, ep)\n",
    "    \n",
    "    lambda1 = world_coord[0][2]#math.sqrt((world_coord[0]**2)+(world_coord[1]**2)+(world_coord[2]**2))\n",
    "    lambda2 = FL2*temp_world0[2]# math.sqrt((world_coord[0]-camera_2_center[0])**2+(world_coord[1]-camera_2_center[1])**2+(world_coord[2]-camera_2_center[2])**2)\n",
    "    print(f'lambda1:{lambda1}')\n",
    "    print(f'lambda2:{lambda2}')\n",
    "    \n",
    "    x0 = np.append(camera_coords[0][0], 1)\n",
    "    \n",
    "    x0p = np.append(camera_coords[0][1], 1)\n",
    "    print(f'x0:{x0}')\n",
    "    #np.append(cam_2_coord, 1)\n",
    "    print(f'x0\\':{x0p}')\n",
    "    Tx = np.array([[0, -tz, ty],\n",
    "                   [tz, 0, -tx],\n",
    "                   [-ty, tx, 0]])\n",
    "    \n",
    "    R = np.array(rot[:3,:3])\n",
    "    print(f'x0TxRx0\\':{ x0 @ Tx @ R @ x0p}')\n",
    "    print(f'lambda1*x1:{lambda1*x0}')\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    print(f'R(lambda1*x0)+T:{R_inv @ (lambda1*x0 -np.array([tx, ty,tz])) }' )\n",
    "    print(f'lambda2*x0\\':{lambda2*x0p}')\n",
    "    \n",
    "    E_mat= Tx @ R\n",
    "    \n",
    "    \n",
    "    print(f'Determinant of E=TxR: {np.linalg.det(E_mat)}')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "elev_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Elevation')\n",
    "azim_slider = widgets.IntSlider(min=-180, max=180, step=1, value=90, description='Azimuth')\n",
    "roll_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-90, description='Roll')\n",
    "\n",
    "\n",
    "\n",
    "FL_slider2 = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1.0, description='Cam 2 Focal')\n",
    "\n",
    "alpha_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Cam2 Alpha')\n",
    "beta_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-150, description='Cam2 Beta')\n",
    "gamma_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-70, description='Cam2 Gamma')\n",
    "\n",
    "\n",
    "tx_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Tx')\n",
    "ty_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Ty')\n",
    "tz_slider = widgets.FloatSlider(min=0.0, max=5.0, step=0.1, value=4, description='Tz')\n",
    "\n",
    "# Group sliders into two columns\n",
    "left_box = widgets.VBox([elev_slider, azim_slider, roll_slider, Xw_slider, Yw_slider, Zw_slider ])\n",
    "right_box = widgets.VBox([ FL_slider2, alpha_slider, beta_slider, gamma_slider, tx_slider, ty_slider, tz_slider])\n",
    "\n",
    "epipoles_checkbox = widgets.Checkbox(value=False, description='Show Epipoles in 2D',disabled=False)\n",
    "\n",
    "# Combine the two columns into a single horizontal layout\n",
    "ui = widgets.HBox([left_box,  right_box])\n",
    "\n",
    "\n",
    "# Interactive widget\n",
    "out = widgets.interactive_output(update_plot, {'elev_angle': elev_slider, 'azim_angle': azim_slider, \n",
    "                                               'roll_angle': roll_slider, \n",
    "                                                'FL2': FL_slider2, \n",
    "                                               'Alpha': alpha_slider, 'Beta': beta_slider, 'Gamma': gamma_slider,\n",
    "                                              'tx': tx_slider, 'ty': ty_slider, 'tz': tz_slider, 'ep': epipoles_checkbox})\n",
    "\n",
    "sliders_box = widgets.VBox([elev_slider, azim_slider, roll_slider, \n",
    "                            FL_slider2, alpha_slider, beta_slider, \n",
    "                            gamma_slider, tx_slider, ty_slider, tz_slider, epipoles_checkbox])\n",
    "ui = widgets.HBox([sliders_box, out])\n",
    "\n",
    "\n",
    "# Display the UI and the output widget\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "a8051ad0-0b1f-48aa-b4f9-37b3a1e2f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2, 2)\n",
      "[[1. 0. 0. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 0. 1. 4.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[-0.296 -0.814 -0.5    0.   ]\n",
      " [-0.94   0.342  0.     0.   ]\n",
      " [ 0.171  0.47  -0.866  0.   ]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "[[-0.296 -0.814 -0.5   -3.11 ]\n",
      " [-0.94   0.342  0.    -0.598]\n",
      " [ 0.171  0.47  -0.866 -2.823]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "[[-0.296 -0.94   0.171 -1.   ]\n",
      " [-0.814  0.342  0.47  -1.   ]\n",
      " [-0.5    0.    -0.866 -4.   ]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "[[-0.296 -0.94   0.171 -0.552]\n",
      " [-0.814  0.342  0.47   1.408]\n",
      " [-0.5    0.    -0.866 -3.964]\n",
      " [ 0.     0.     0.     1.   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'X = [1,1,1,1]\\nprint(rotTInv @ X)\\nprint(rotinvTminus @ X)\\nprint(rot)\\nprint(rot.T)'"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(camera_coords.shape)\n",
    "print(T)\n",
    "print(rot)\n",
    "print(rot @ T)\n",
    "rotTInv = np.linalg.inv(rot @ T)\n",
    "print(rotTInv)\n",
    "rotinvTminus = rot.T @ T\n",
    "print(rotinvTminus)\n",
    "\n",
    "'''X = [1,1,1,1]\n",
    "print(rotTInv @ X)\n",
    "print(rotinvTminus @ X)\n",
    "print(rot)\n",
    "print(rot.T)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a07fb2",
   "metadata": {},
   "source": [
    "## The Eight Point Algorithm\n",
    "\n",
    "So we start with the epipolar constraint.\n",
    "\\begin{equation}\n",
    "    x_2^{\\top}Ex_1=0\n",
    "\\end{equation}\n",
    "\n",
    "This should hold for any matching points $x_1$ and $x_2$ in two image views.\n",
    "\n",
    "If we have enough points, we will use eight, then we should be able to recover the unknown matrix $E$.\n",
    "\n",
    "Strictly speaking we can get away with seven points but eight will give us a unique solution (up to scale).\n",
    "\n",
    "This assumes the eight points meet certain criteria and have no noise. More on this later.\n",
    "\n",
    "\n",
    "\n",
    "$E$ is a $3\\times3$ matrix as follows.\n",
    "\\begin{equation}\n",
    "\tE= \\begin{bmatrix}\n",
    "e_{11} & e_{12} & e_{13}\\\\\n",
    "e_{21} & e_{22} & e_{23}\\\\\n",
    "e_{31} & e_{32} & e_{33}\\\\\n",
    " \\end{bmatrix}\n",
    "\\end{equation}\n",
    "    \n",
    "\n",
    "We can stack this matrix into a single vector $\\in \\mathbb{R}^9$\n",
    "\n",
    "which we will call $e_s$\n",
    "\n",
    "$$e_s= \\begin{bmatrix}\n",
    "e_{11}\\\\\n",
    "e_{21}\\\\\n",
    "e_{31}\\\\\n",
    "e_{12}\\\\\n",
    "e_{22}\\\\\n",
    "e_{32}\\\\\n",
    "e_{13}\\\\\n",
    "e_{23}\\\\\n",
    "e_{33}\n",
    "\\end{bmatrix} $$\n",
    " \n",
    "For each set of point correspondences in homogeneous coordinates we will get one linear equation in the unknown entries of $E$.\n",
    "\n",
    "For example if $x = (x,y,1)^{\\top}$ and $x' = (x',y',1)^{\\top}$ we have the linear equation\n",
    "\n",
    " \\begin{equation}\n",
    "\tx'xe_{11}+x'ye_{12}+x'e_{13}+y'xe_{21}+y'ye_{22}+y'e_{23}+xe_{31}+ye_{32}+e_{33} = 0\n",
    "\\end{equation}\n",
    "\n",
    "We can write this as $a^{\\top}e_s=0$ which is equivalent to the epipolar constraint.\n",
    "\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "x'x & x'y & x'& y'x&y'y&y'&x&y&1\n",
    " \\end{bmatrix} \\begin{bmatrix}\n",
    "e_{11}\\\\\n",
    "e_{21}\\\\\n",
    "e_{31}\\\\\n",
    "e_{12}\\\\\n",
    "e_{22}\\\\\n",
    "e_{32}\\\\\n",
    "e_{13}\\\\\n",
    "e_{23}\\\\\n",
    "e_{33}\n",
    "\\end{bmatrix}=0$$\n",
    "\n",
    " \n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "We can put each of the equations for the eight point correspondances into a separate row of a matrix called $A$\n",
    " \\begin{equation}\n",
    "\t\\begin{bmatrix}\n",
    "x_1'x_1 & x_1'y_1 & x_1'& y_1'x_1&y_1'y_1&y_1'&x_1&y_1&1\\\\\n",
    "x_2'x_2 & x_2'y_2 & x_2'& y_2'x_2&y_2'y_2&y_2'&x_2&y_2&1\\\\\n",
    "x_3'x_3 & x_3'y_3 & x_3'& y_3'x_3&y_3'y_3&y_3'&x_3&y_3&1\\\\\n",
    "x_4'x_4 & x_4'y_4 & x_4'& y_4'x_4&y_4'y_4&y_4'&x_4&y_4&1\\\\\n",
    "x_5'x_5 & x_5'y_5 & x_5'& y_5'x_5&y_5'y_5&y_5'&x_5&y_5&1\\\\\n",
    "x_6'x_6 & x_6'y_6 & x_6'& y_6'x_6&y_6'y_6&y_6'&x_6&y_6&1\\\\\n",
    "x_7'x_7 & x_7'y_7 & x_7'& y_7'x_7&y_7'y_7&y_7'&x_7&y_7&1\\\\\n",
    "x_8'x_8 & x_8'y_8 & x_8'& y_8'x_8&y_8'y_8&y_8'&x_8&y_8&1\\\\\n",
    " \\end{bmatrix} \\begin{bmatrix}\n",
    "e_{11}\\\\\n",
    "e_{21}\\\\\n",
    "e_{31}\\\\\n",
    "e_{12}\\\\\n",
    "e_{22}\\\\\n",
    "e_{32}\\\\\n",
    "e_{13}\\\\\n",
    "e_{23}\\\\\n",
    "e_{33} \n",
    " \\end{bmatrix} = 0\n",
    "\\end{equation}\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "f458341b-1e48-4da1-81c6-a97e9b593a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:[9.24  0.31  0.155 0.069 0.004 0.001 0.    0.    0.   ]\n",
      "Es:[ 7.86  -2.712 -1.287 -1.796 -7.45   2.312 -1.732 -2.268  1.   ]\n",
      "E:[[ 7.86  -2.712 -1.287]\n",
      " [-1.796 -7.45   2.312]\n",
      " [-1.732 -2.268  1.   ]]\n",
      "ATe:[-0. -0. -0.  0.  0. -0. -0.  0.]\n",
      "S:[8.485 8.485 0.   ]\n",
      "Negative Determinent\n",
      "T1: [ 1.104 -2.815  7.928]\n",
      "T2: [-1.104  2.815 -7.928]\n",
      "R1:[[ 0.235  0.878 -0.416]\n",
      " [ 0.97  -0.186  0.156]\n",
      " [ 0.06  -0.44  -0.896]]\n",
      "R2:[[-0.296 -0.94   0.171]\n",
      " [-0.814  0.342  0.47 ]\n",
      " [-0.5    0.    -0.866]]\n",
      "Actual Rotation: [[-0.296 -0.814 -0.5  ]\n",
      " [-0.94   0.342  0.   ]\n",
      " [ 0.171  0.47  -0.866]]\n",
      "determinant of U: 0.9999999999999998\n",
      "determinant of Vh: -1.0\n",
      "determinant of E: -6.451319239206104e-10\n",
      "determinant of S: 0.0\n",
      "determinant of Rz: 1.0\n",
      "determinant of Rzneg: 1.0\n",
      "determinant of R2: 0.9999999999999996\n",
      "determinant of R1: 0.9999999999999996\n",
      "determinant of actual rotation: 1.0\n",
      "[-0.5  0.5  1.3]\n",
      "[ 0.452 -0.219  3.088]\n",
      "[ 0.452 -0.219  3.088]\n",
      "[-0.5  0.5  1.3]\n",
      "[ 0.332 -1.783  2.55 ]\n",
      "[-0.651  2.596 -4.84 ]\n"
     ]
    }
   ],
   "source": [
    "c = camera_coords\n",
    "\n",
    "\n",
    "A = np.array([[c[0,1,0]*c[0,0,0], c[0,1,0]*c[0,0,1], c[0,1,0], c[0,1,1]*c[0,0,0], c[0,1,1]*c[0,0,1], c[0,1,1], c[0,0,0], c[0,0,1], 1 ],\n",
    "              [c[1,1,0]*c[1,0,0], c[1,1,0]*c[1,0,1], c[1,1,0], c[1,1,1]*c[1,0,0], c[1,1,1]*c[1,0,1], c[1,1,1], c[1,0,0], c[1,0,1], 1 ],\n",
    "              [c[2,1,0]*c[2,0,0], c[2,1,0]*c[2,0,1], c[2,1,0], c[2,1,1]*c[2,0,0], c[2,1,1]*c[2,0,1], c[2,1,1], c[2,0,0], c[2,0,1], 1 ],\n",
    "              [c[3,1,0]*c[3,0,0], c[3,1,0]*c[3,0,1], c[3,1,0], c[3,1,1]*c[3,0,0], c[3,1,1]*c[3,0,1], c[3,1,1], c[3,0,0], c[3,0,1], 1 ],\n",
    "              [c[4,1,0]*c[4,0,0], c[4,1,0]*c[4,0,1], c[4,1,0], c[4,1,1]*c[4,0,0], c[4,1,1]*c[4,0,1], c[4,1,1], c[4,0,0], c[4,0,1], 1 ],\n",
    "              [c[5,1,0]*c[5,0,0], c[5,1,0]*c[5,0,1], c[5,1,0], c[5,1,1]*c[5,0,0], c[5,1,1]*c[5,0,1], c[5,1,1], c[5,0,0], c[5,0,1], 1 ],\n",
    "              [c[6,1,0]*c[6,0,0], c[6,1,0]*c[6,0,1], c[6,1,0], c[6,1,1]*c[6,0,0], c[6,1,1]*c[6,0,1], c[6,1,1], c[6,0,0], c[6,0,1], 1 ],\n",
    "              [c[7,1,0]*c[7,0,0], c[7,1,0]*c[7,0,1], c[7,1,0], c[7,1,1]*c[7,0,0], c[7,1,1]*c[7,0,1], c[7,1,1], c[7,0,0], c[7,0,1], 1 ]])\n",
    "\n",
    "U, S, Vh = np.linalg.svd(A.T @ A)\n",
    "print(f'S:{S}')\n",
    "Es = Vh[8,:]\n",
    "Es = Es/Es[8]\n",
    "E = Es.reshape(3,3)\n",
    "#E = E.transpose()\n",
    "\n",
    "print(f'Es:{Es}')\n",
    "print(f'E:{E}')\n",
    "print(f'ATe:{A @ Es}')\n",
    "\n",
    "\n",
    "\n",
    "#In this code I am using the E matrix that I created from a known rotation and translation matrix\n",
    "# For the eight point algorithm we must determine the E matrix\n",
    "U, S, Vh = np.linalg.svd(E)\n",
    "theta = np.pi / 2  # 90 degrees in radians\n",
    "print(f'S:{S}')\n",
    "negDetFlag = 1\n",
    "if np.linalg.det(E) < 0.0:\n",
    "    print('Negative Determinent')\n",
    "    negDetFlag = -1\n",
    "\n",
    "S[2] = 0\n",
    "\n",
    "Rz = np.array([[np.cos(theta), -np.sin(theta),0],\n",
    "                [np.sin(theta), np.cos(theta),0],\n",
    "                [0, 0, 1]])\n",
    "Rzneg = np.array([[np.cos(-theta), -np.sin(-theta),0],\n",
    "                [np.sin(-theta), np.cos(-theta),0],\n",
    "                 [0, 0, 1]])\n",
    "\n",
    "Tx1 = U @ Rz @ np.diag(S) @ U.T\n",
    "Tx2 = U @ Rzneg @ np.diag(S) @ U.T\n",
    "T1 = np.array([Tx1[2, 1], Tx1[0, 2], Tx1[1, 0]])\n",
    "T2 = np.array([Tx2[2, 1], Tx2[0, 2], Tx2[1, 0]])\n",
    "\n",
    "print(f'T1: {T1}')\n",
    "print(f'T2: {T2}')\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "R1 = negDetFlag*(U @ Rz.T @ Vh)\n",
    "R2 = negDetFlag*(U @ Rzneg.T @ Vh)\n",
    "print(f'R1:{R1}')\n",
    "print(f'R2:{R2}')\n",
    "print(f'Actual Rotation: {rot[0:3,0:3]}')\n",
    "\n",
    "\n",
    "\n",
    "print(f'determinant of U: {np.linalg.det(U)}')\n",
    "print(f'determinant of Vh: {np.linalg.det(Vh)}')\n",
    "print(f'determinant of E: {np.linalg.det(E)}')\n",
    "print(f'determinant of S: {np.linalg.det(np.diag(S))}')\n",
    "print(f'determinant of Rz: {np.linalg.det(Rz)}')\n",
    "print(f'determinant of Rzneg: {np.linalg.det(Rzneg)}')\n",
    "print(f'determinant of R2: {np.linalg.det(R2)}')\n",
    "print(f'determinant of R1: {np.linalg.det(R1)}')\n",
    "print(f'determinant of actual rotation: {np.linalg.det(rot[0:3,0:3])}')\n",
    "X = 1.3*np.array([-0.3846, 0.3846, 1])\n",
    "Xp = 3.08826868*np.array([0.1465, -0.0709, 1])\n",
    "print(1.3*np.array([-0.3846, 0.3846, 1]))\n",
    "print(3.08826868*np.array([0.1465, -0.0709, 1]))\n",
    "print( rot[0:3,0:3].T @ (X - T[0:3,3]) ) \n",
    "print( rot[0:3,0:3] @ Xp + T[0:3,3] ) \n",
    "\n",
    "print( R1 @ X + T1/2)\n",
    "print( R2 @ X + T2/2)\n",
    "\n",
    "\n",
    "# How best to explain the recovered T. I guess simply that T it recovers the homogeneous coordinate T in camera one rather than the actual Translation.\n",
    "# I also need to figure out the difference between recovery to a scalar versus recorvery to a projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "c31d1d5c-a324-448f-af68-681807ed0f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.3846153846153846,0.3846153846153846\n",
      "(0.14649513239403944,-0.07088068323885628\n",
      "(8, 9)\n",
      "[3.039762948063 0.55649307714  0.393403515918 0.263331614303\n",
      " 0.060835445213 0.038258743933 0.020225585776 0.002310344643]\n",
      "[ 0.654963425801 -0.149705710485 -0.144337567297 -0.225967100428\n",
      " -0.620839505965 -0.188995766036 -0.107249081343  0.192636304113\n",
      "  0.083333333333]\n",
      "[ 7.859561109613 -1.796468525819 -1.732050807569 -2.711605205134\n",
      " -7.450074071581 -2.267949192431 -1.28698897612   2.31163564935\n",
      "  1.            ]\n",
      "Calculated E_Det: -3.4123543974788306e-13\n",
      "Calculated E: [[ 7.859561109613 -1.796468525819 -1.732050807569]\n",
      " [-2.711605205134 -7.450074071581 -2.267949192431]\n",
      " [-1.28698897612   2.31163564935   1.            ]]\n",
      "Synthetic E: [[ 7.859561109613 -1.796468525819 -1.732050807569]\n",
      " [-2.711605205134 -7.450074071581 -2.267949192431]\n",
      " [-1.28698897612   2.31163564935   1.            ]]\n",
      "Synthetic E_Det: 7.041659016127529e-15\n",
      " Dif synE-E:[[-0.  0.  0.]\n",
      " [ 0. -0.  0.]\n",
      " [-0.  0.  0.]]\n",
      "S:[8.485281374239 8.485281374239 0.            ]\n",
      "S[2]:7.632773557789898e-17\n",
      "Negative Determinent\n",
      "Tx1: [[ 0.  8. -2.]\n",
      " [-8.  0.  2.]\n",
      " [ 2. -2.  0.]]\n",
      "Tx2: [[ 0. -8.  2.]\n",
      " [ 8.  0. -2.]\n",
      " [-2.  2.  0.]]\n",
      "T1: [-2. -2. -8.]\n",
      "T2: [2. 2. 8.]\n",
      "R1:[[-0.234881414186 -0.970198537299 -0.059544264985]\n",
      " [-0.878375902246  0.185619287376  0.440455735015]\n",
      " [ 0.416276945823 -0.155757113406  0.895797536277]]\n",
      "R2:[[ 0.296198132726  0.813797681349  0.5           ]\n",
      " [ 0.939692620786 -0.342020143326  0.            ]\n",
      " [-0.171010071663 -0.469846310393  0.866025403784]]\n",
      "Actual Rotation: [[-0.296198132726 -0.813797681349 -0.5           ]\n",
      " [-0.939692620786  0.342020143326  0.            ]\n",
      " [ 0.171010071663  0.469846310393 -0.866025403784]]\n",
      "[8.485281374239 8.485281374239 0.            ]\n",
      "[2. 2. 8.]\n",
      "[[1. 0. 0. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 0. 1. 4.]\n",
      " [0. 0. 0. 1.]]\n",
      "determinant of U: -1.0000000000000002\n",
      "determinant of Vh: -1.0000000000000004\n",
      "determinant of E: -7.041659016127529e-15\n",
      "determinant of S: 3.316616660172877e-15\n",
      "determinant of Rz: 1.0\n",
      "determinant of Rzneg: 1.0\n",
      "determinant of R2: -1.0000000000000002\n",
      "determinant of R1: -1.0000000000000004\n",
      "determinant of actual rotation: 1.0\n",
      "[-0.49998  0.49998  1.3    ]\n",
      "[ 0.45243136162  -0.218958249412  3.08826868    ]\n",
      "[ 0.452429185882 -0.218921704056  3.088258590218]\n",
      "[-1.077723433356 -0.077802028314 -1.011095474801]\n",
      "[2.499955948815 1.500034543773 6.700025536635]\n",
      "[-1.445051399694  0.104568770427 -3.121468791774]\n",
      "[1.908789422321 0.359169252199 4.976420882279]\n"
     ]
    }
   ],
   "source": [
    "#playing around\n",
    "np.set_printoptions(precision=12, suppress=True)\n",
    "c = camera_coords\n",
    "\n",
    "print(f'({c[0,0,0]},{c[0,0,1]}')\n",
    "print(f'({c[0,1,0]},{c[0,1,1]}')\n",
    "A = np.array([[c[0,0,0]*c[0,1,0], c[0,0,0]*c[0,1,1], c[0,0,0], c[0,0,1]*c[0,1,0], c[0,0,1]*c[0,1,1], c[0,0,1], c[0,1,0], c[0,1,1], 1 ],\n",
    "              [c[1,0,0]*c[1,1,0], c[1,0,0]*c[1,1,1], c[1,0,0], c[1,0,1]*c[1,1,0], c[1,0,1]*c[1,1,1], c[1,0,1], c[1,1,0], c[1,1,1], 1 ],\n",
    "              [c[2,0,0]*c[2,1,0], c[2,0,0]*c[2,1,1], c[2,0,0], c[2,0,1]*c[2,1,0], c[2,0,1]*c[2,1,1], c[2,0,1], c[2,1,0], c[2,1,1], 1 ],\n",
    "              [c[3,0,0]*c[3,1,0], c[3,0,0]*c[3,1,1], c[3,0,0], c[3,0,1]*c[3,1,0], c[3,0,1]*c[3,1,1], c[3,0,1], c[3,1,0], c[3,1,1], 1 ],\n",
    "              [c[4,0,0]*c[4,1,0], c[4,0,0]*c[4,1,1], c[4,0,0], c[4,0,1]*c[4,1,0], c[4,0,1]*c[4,1,1], c[4,0,1], c[4,1,0], c[4,1,1], 1 ],\n",
    "              [c[5,0,0]*c[5,1,0], c[5,0,0]*c[5,1,1], c[5,0,0], c[5,0,1]*c[5,1,0], c[5,0,1]*c[5,1,1], c[5,0,1], c[5,1,0], c[5,1,1], 1 ],\n",
    "              [c[6,0,0]*c[6,1,0], c[6,0,0]*c[6,1,1], c[6,0,0], c[6,0,1]*c[6,1,0], c[6,0,1]*c[6,1,1], c[6,0,1], c[6,1,0], c[6,1,1], 1 ],\n",
    "              [c[7,0,0]*c[7,1,0], c[7,0,0]*c[7,1,1], c[7,0,0], c[7,0,1]*c[7,1,0], c[7,0,1]*c[7,1,1], c[7,0,1], c[7,1,0], c[7,1,1], 1 ]])\n",
    "\n",
    "print(A.shape)\n",
    "U, S, Vh = np.linalg.svd(A)\n",
    "#print(U)\n",
    "print(S)\n",
    "#print(Vh)\n",
    "#print(\"************\")\n",
    "#print(Vh[:,8])\n",
    "Es = Vh[8,:]\n",
    "print(Es)\n",
    "Es = Es/Es[8]\n",
    "E = Es.reshape(3,3)\n",
    "\n",
    "\n",
    "\n",
    "print(Es)\n",
    "print(f'Calculated E_Det: {np.linalg.det(E)}')\n",
    "print(f'Calculated E: {E}')\n",
    "\n",
    "\n",
    "\n",
    "#In this code I am using the E matrix that I created from a known rotation and translation matrix\n",
    "# For the eight point algorithm we must determine the E matrix\n",
    "\n",
    "Tx = skew(np.array([1,1,4]))\n",
    "#print(Tx)\n",
    "synE = Tx @ rot[0:3,0:3]\n",
    "synE = synE/synE[2,2]\n",
    "print(f'Synthetic E: {synE}')\n",
    "print(f'Synthetic E_Det: {np.linalg.det(synE)}')\n",
    "print(f' Dif synE-E:{synE-E}')\n",
    "U, S, Vh = np.linalg.svd(synE)\n",
    "\n",
    "theta = np.pi / 2  # 90 degrees in radians\n",
    "print(f'S:{S}')\n",
    "print(f'S[2]:{S[2]}')\n",
    "negDetFlag = 1\n",
    "if np.linalg.det(E) < 0.0:\n",
    "    print('Negative Determinent')\n",
    "    negDetFlag = -1\n",
    "S[2] = 0\n",
    "E = U @ np.diag(S) @ Vh\n",
    "U, S, Vh = np.linalg.svd(E)\n",
    "\n",
    "\n",
    "\n",
    "Rz = np.array([[np.cos(theta), -np.sin(theta),0],\n",
    "                [np.sin(theta), np.cos(theta),0],\n",
    "                [0, 0, 1]])\n",
    "Rzneg = np.array([[np.cos(-theta), -np.sin(-theta),0],\n",
    "                [np.sin(-theta), np.cos(-theta),0],\n",
    "                 [0, 0, 1]])\n",
    "Tx1 = U @ Rz @ np.diag(S) @ U.T\n",
    "Tx2 = U @ Rzneg @ np.diag(S) @ U.T\n",
    "T1 = np.array([Tx1[2, 1], Tx1[0, 2], Tx1[1, 0]])\n",
    "T2 = np.array([Tx2[2, 1], Tx2[0, 2], Tx2[1, 0]])\n",
    "print(f'Tx1: {Tx1}')\n",
    "print(f'Tx2: {Tx2}')\n",
    "print(f'T1: {T1}')\n",
    "print(f'T2: {T2}')\n",
    "\n",
    "\n",
    "\n",
    "R1 = negDetFlag*(U @ Rz.T @ Vh)\n",
    "R2 = negDetFlag*(U @ Rzneg.T @ Vh)\n",
    "print(f'R1:{R1}')\n",
    "print(f'R2:{R2}')\n",
    "print(f'Actual Rotation: {rot[0:3,0:3]}')\n",
    "#print(f'Actual Rotation inv: {rotInv}')\n",
    "print(S)\n",
    " \n",
    "print(T2)\n",
    "#T2 = 4.3*T2/0.701\n",
    "print(T)\n",
    "print(f'determinant of U: {np.linalg.det(U)}')\n",
    "print(f'determinant of Vh: {np.linalg.det(Vh)}')\n",
    "print(f'determinant of E: {np.linalg.det(E)}')\n",
    "print(f'determinant of S: {np.linalg.det(np.diag(S))}')\n",
    "print(f'determinant of Rz: {np.linalg.det(Rz)}')\n",
    "print(f'determinant of Rzneg: {np.linalg.det(Rzneg)}')\n",
    "print(f'determinant of R2: {np.linalg.det(R2)}')\n",
    "print(f'determinant of R1: {np.linalg.det(R1)}')\n",
    "print(f'determinant of actual rotation: {np.linalg.det(rot[0:3,0:3])}')\n",
    "\n",
    "X = 1.3*np.array([-0.3846, 0.3846, 1])\n",
    "Xp = 3.08826868*np.array([0.1465, -0.0709, 1])\n",
    "print(1.3*np.array([-0.3846, 0.3846, 1]))\n",
    "print(3.08826868*np.array([0.1465, -0.0709, 1]))\n",
    "print( rot[0:3,0:3].T @ (X - T[0:3,3]) ) \n",
    "\n",
    "print( R1 @ Xp + T1/2)\n",
    "print( R2 @ Xp + T2/2)\n",
    "print( R1 @ X + T1/2)\n",
    "print( R2 @ X + T2/2)\n",
    "# How best to explain the recovered T. I guess simply that T it recovers the homogeneous coordinate T in camera one rather than the actual Translation.\n",
    "# I also need to figure out the difference between recovery to a scalar versus recorvery to a projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1376716",
   "metadata": {},
   "source": [
    "## Why Eight?\n",
    "You will notice that there are nine unknowns in $E$ but as mentioned earlier we can only determine a unique solution up to a scale factor. So generally we set $e_{33}$ to 1 as we can set it to any value. But we must do this first before we start solving.\n",
    "\n",
    "For $E$ to have a solution, $A$ must be of rank at most 8. \n",
    "\n",
    "If it is of rank = 8 then we will have a unique solution. $Ae_s = 0$ says that the vector $e_s$ is in the null space of $A$. So if $A$ had rank greater than 8 then there would be no null space and no solution. \n",
    "\n",
    "For less than 8 e.g. 7 there is a whole 2D plane of solutions and there are methods to determine a solution on this plane with the best essential matrix in $\\mathcal{E}$ space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18586d30",
   "metadata": {},
   "source": [
    "## Noise\n",
    "**If the data (point correspondences) are not exact (it won't be exact in the real world), the rank of $A$ may be greater than 8.**\n",
    "\n",
    "9 is the full rank as there are 9 columns.\n",
    "\n",
    "In this case we can find the least squares solution. \n",
    "\n",
    "This is also the case if we use more than 8 point correspondences.\n",
    "\n",
    "Also note that even in the supposed full rank case we would need 9 correspondences to realise this. \n",
    "\n",
    "So in the case of noise and only 8 points, we will still only have rank 8, but our null space could be the wrong vector/line. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7705562a-c16a-480f-86e5-28393ee655b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can demonstrate that by adding noise I don't recover the Rotation and Translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b05048",
   "metadata": {},
   "source": [
    "## How do we find the Null space of A?\n",
    "How do we find $e_s$?\n",
    "\n",
    "Get the SVD of $A$.\n",
    "\\begin{equation}\n",
    "\tA = U\\Sigma V^{\\top}\n",
    "\\end{equation}\n",
    "\n",
    "The solution is the column vector of $V$ that corresponds to the smallest singular value of $\\Sigma$. \n",
    "\n",
    "Most programming software libraries (Matlab, Numpy) will order the singular values of $\\Sigma$ in descending order. \n",
    "\n",
    "In that case the solution $e_s$ will be the final column of $V^{\\top}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17da0a",
   "metadata": {},
   "source": [
    "## Projecting $E$ onto the essential space ($\\mathcal{E}$)\n",
    "\n",
    "As we mentioned, calculating $E$ by this manner is unlikely to get us a matrix that obeys all the constraints of the essential space.\n",
    "\n",
    "Instead we must project onto $\\mathcal{E}$.\n",
    "\n",
    "From Theorem: _Projection onto the essential space_ page 86 An invitation to 3D Vision by Ma, Kosecka, Soatto, Sastry.\n",
    "\n",
    "\n",
    "Let $E$ be the calculated matrix $\\in \\mathbb{R}^{3\\times3}$.\n",
    "\n",
    "Perform an SVD on E such that\n",
    "\\begin{equation}\n",
    "\tE = U \\begin{bmatrix}\n",
    "\\lambda_1 & 0 & 0\\\\\n",
    "0 & \\lambda_2 & 0\\\\\n",
    "0 & 0 &\\lambda_3\n",
    " \\end{bmatrix}V^{\\top}\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\lambda_1 \\geq \\lambda_2 \\geq \\lambda_3$, i.e. the singular values are in descending order.\n",
    "The closest essential matrix (we'll call it $E^*$) is given by \n",
    " \\begin{equation}\n",
    "\tE^* = U \\begin{bmatrix}\n",
    "\t\\sigma & 0 & 0\\\\\n",
    "0 & \\sigma & 0\\\\\n",
    "0 & 0 &0\n",
    " \\end{bmatrix}V^{\\top}, \\quad \\text{with } \\sigma = \\frac{\\lambda_1+\\lambda_2}{2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d3b83",
   "metadata": {},
   "source": [
    "## Two decompositions\n",
    "\n",
    "From the theorem _Pose recovery from the Essential Matrix_ - page 84 An invitation to 3D Vision by Ma, Kosecka, Soatto, Sastry.\n",
    "\n",
    "There are two relative poses $(R,T)$ with $R\\in SO(3)$ and $T\\in\\mathbb{R}^3$ corresponding to an essential matrix $E\\in\\mathcal{E}$\n",
    "\n",
    "\n",
    "For $E=U\\Sigma V^{\\top}$ we have:\n",
    "\\begin{equation}\n",
    "\t(T_{1\\times},R_1) = (UR_{Z(+\\frac{\\pi}{2})}\\Sigma U^{\\top}, UR^{\\top}_{Z(+\\frac{\\pi}{2})}V^{\\top})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t(T_{2\\times},R_2) = (UR_{Z(-\\frac{\\pi}{2})}\\Sigma U^{\\top}, UR^{\\top}_{Z(-\\frac{\\pi}{2})}V^{\\top})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fecacc",
   "metadata": {},
   "source": [
    "## Reconstruction\n",
    "\n",
    "So now we have determined $E$ we can get $R$ and $T$ (up to a scale factor). \n",
    "\n",
    "What next? How do we reconstruct the 3D points?\n",
    "\n",
    "Firstly we must take the scale factor into account.\n",
    "\n",
    "$||E||=||T||=\\gamma\\in \\mathbb{R}+$\n",
    "\n",
    "So a single point in 3D $X^j$ can be determined by \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\lambda_2^jx^j_2=\\lambda_1^jRx^j_1 + \\gamma T \n",
    "\\end{equation}\n",
    "\n",
    "The unknown scale parameters are $\\lambda^j_i$. We've seen previously how we can get rid of one of these. Multiply across by \n",
    "\n",
    "$x^j_{2\\times}$.\n",
    "\\begin{equation}\n",
    "\t\\lambda_2^jx^j_{2\\times}x^j_2=\\lambda_1^jx^j_{2\\times}Rx^j_1 + \\gamma x^j_{2\\times}T \n",
    "\\end{equation}\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "This gives us:\n",
    "\\begin{equation}\n",
    "\t\\lambda_1^jx^j_{2\\times}Rx^j_1 + \\gamma x^j_{2\\times}T = 0\n",
    "\\end{equation}\n",
    "\n",
    "Which we can show as a linear system of the following sort.\n",
    "\\begin{equation}\n",
    "\t\\begin{bmatrix}\n",
    "\tx^j_{2\\times}Rx^j_1 & x^j_{2\\times} T \\end{bmatrix} \n",
    "\t\\begin{bmatrix}\n",
    "\t\\lambda_1^j \\\\\n",
    "\t\\gamma \n",
    "\t\\end{bmatrix}= 0\n",
    "\\end{equation}\n",
    "\n",
    "So we can make a whole vector out of $$\n",
    "\t\\begin{bmatrix}\n",
    "\t\\lambda_1^j \\\\\n",
    "\t\\gamma \n",
    "\t\\end{bmatrix}$$ \n",
    "which we will call $\\vec{\\lambda}$.\n",
    "\t\n",
    "\\begin{equation}\n",
    "\t\\vec{\\lambda}=\n",
    "\t\\begin{bmatrix}\n",
    "\t\\lambda_1^1 \\\\\n",
    "\t\\lambda_1^2 \\\\\n",
    "\t.\\\\\n",
    "\t.\\\\\n",
    "\t.\\\\\n",
    "\t\\lambda_1^n \\\\\n",
    "\t\\gamma \n",
    "\t\\end{bmatrix} \\in \\mathbb{R}^{n+1}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "So we can solve the system $M\\vec{\\lambda}=0$\n",
    "where \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\tM \\equiv \n",
    "\t\\begin{bmatrix}\n",
    "\tx^1_{2\\times}Rx^1_1 & 0 & 0 & 0 & 0 & x^1_{2\\times}T\\\\\n",
    "    0 & x^2_{2\\times}Rx^2_1 &  0 & 0 & 0 & x^2_{2\\times}T\\\\\n",
    "\t0 & 0 & \\ddots & 0 & 0& \\vdots\\\\\n",
    "\t0 & 0 & 0 & x^{n-1}_{2\\times}Rx^{n-1}_1 &   0 & x^{n-1}_{2\\times}T\\\\\n",
    "\t0 & 0 & 0 & 0 & x^{n}_{2\\times}Rx^{n}_1 &    x^{n}_{2\\times}T\n",
    "\t\\end{bmatrix}\n",
    "\t\\end{equation}\n",
    "\n",
    "$3n \\times n+1$\n",
    "\t\n",
    "Once again, we are looking for a vector in the null space but in truth there is unlikely to be a perfect null space.\n",
    "\n",
    "Instead we can do an eigen vector decomposition of $M^{\\top}M$ and $\\vec{\\lambda}$ will be the vector associated with the smallest eigen value.\n",
    "\n",
    "Again this is only defined up to a global scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "2bacf211-81f2-4288-b7b1-f836097b81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  0.5  1.3]\n",
      "[-0.5 -1.5 -5.3]\n",
      "[ 0.452 -0.219  3.088]\n",
      "[ 0.452 -0.219  3.088]\n"
     ]
    }
   ],
   "source": [
    "def skew(vec):\n",
    "    return np.array([[0,-vec[2], vec[1]],\n",
    "                     [vec[2],0,-vec[0]],\n",
    "                     [-vec[1],vec[0],0]])\n",
    "x1 = np.array([-0.3846,0.3846,1])\n",
    "x2 = np.array([0.1465,-0.0709,1])\n",
    "lamb1 = 1.3\n",
    "lamb2 = 3.08826859\n",
    "\n",
    "#print((rot[0:3,0:3] @ x1))\n",
    "print(( (lamb1*x1)))\n",
    "print((R2 @ (lamb2*x2)) + T2)\n",
    "\n",
    "print(rot[0:3,0:3].T @ ((lamb1*x1) - T[0:3,3]))\n",
    "\n",
    "print(lamb2*x2)\n",
    "#print((lamb1*(rot[0:3,0:3] @ x1 - T[3,0:3])/(lamb2*x2))\n",
    "\n",
    "#print(rot @T)\n",
    "\n",
    "#print(np.linalg.inv(rot@T))\n",
    "\n",
    "\n",
    "#rotInv = rotTInv[0:3,0:3]    \n",
    "#print(np.linalg.det(rotInv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "956d9fe3-40c3-4c9a-a1d9-d1b8197c763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0883 2.049  2.9151 1.9856 1.8758 2.2187 1.7758 2.0722 1.    ]\n",
      "[1.3 2.5 1.5 2.4 2.7 1.9 2.7 2.3]\n",
      "[5.2725 0.9549 0.926  0.8539 0.8341 0.7339 0.7059 0.3753 0.    ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "\n",
    "\n",
    "def skew(vec):\n",
    "    return np.array([[0,-vec[2], vec[1]],\n",
    "                     [vec[2],0,-vec[0]],\n",
    "                     [-vec[1],vec[0],0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x2x = np.zeros((8,3,3))\n",
    "x1 = np.zeros((8,3,1))\n",
    "x2xT = np.zeros((3,1))\n",
    "\n",
    "#print(c)\n",
    "M = np.zeros((24,9))\n",
    "for i in range (0,8):\n",
    "    x2x[i] = skew(np.array([c[i,0,0],c[i,0,1],1]))\n",
    "    x1[i,:,:] = np.array([[c[i,1,0]],[c[i,1,1]],[1]])\n",
    "    #print(x2x[i])\n",
    "    M[3*i:(3*(i+1)), i:(i+1)] = x2x[i] @ rot[0:3,0:3] @ x1[i]    \n",
    "    x2xT[:,0] = x2x[i] @ T[0:3,3]\n",
    "    #print(x2xT)\n",
    "    M[3*i:3*(i+1), 8:9 ] = x2xT\n",
    "\n",
    "#print(M)\n",
    "MTM = M.transpose() @ M\n",
    "#print(f'rank of M: {np.linalg.matrix_rank(M)}')\n",
    "\n",
    "U, S, Vh = np.linalg.svd(M)\n",
    "\n",
    "\n",
    "lamb = Vh[8,:]\n",
    "#print(S)\n",
    "#print(f'T: is {T[0:3,3]}') \n",
    "#print(np.linalg.norm(T[0:3,3]))\n",
    "\n",
    "#print(Vh)\n",
    "\n",
    "#print(rot[0:3,0:3])b\n",
    "print(lamb/lamb[8])\n",
    "print(world_coord[:,2])\n",
    "print(S)\n",
    "\n",
    "#print(1.3*M[:,0]/M[:,8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "786edc76-3d7e-43a0-974e-690dfe872718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.6796  -0.0856  -1.7491  -1.3314   0.0866 -11.0633  -0.3054  -1.3013\n",
      "   1.    ]\n",
      "[1.3 2.5 1.5 2.4 2.7 1.9 2.7 2.3]\n",
      "[3.3247 0.9587 0.9488 0.8548 0.8393 0.7609 0.7063 0.6049 0.2893]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "\n",
    "\n",
    "def skew(vec):\n",
    "    return np.array([[0,-vec[2], vec[1]],\n",
    "                     [vec[2],0,-vec[0]],\n",
    "                     [-vec[1],vec[0],0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x2x = np.zeros((8,3,3))\n",
    "x1 = np.zeros((8,3,1))\n",
    "x2xT = np.zeros((3,1))\n",
    "\n",
    "#print(c)\n",
    "M = np.zeros((24,9))\n",
    "for i in range (0,8):\n",
    "    x2x[i] = skew(np.array([c[i,1,0],c[i,1,1],1]))\n",
    "    x1[i,:,:] = np.array([[c[i,0,0]],[c[i,0,1]],[1]])\n",
    "    #print(x2x[i])\n",
    "    M[3*i:(3*(i+1)), i:(i+1)] = x2x[i] @ rot[0:3,0:3].T @ x1[i]    \n",
    "    x2xT[:,0] = x2x[i] @ T[0:3,3]\n",
    "    #print(x2xT)\n",
    "    M[3*i:3*(i+1), 8:9 ] = x2xT\n",
    "\n",
    "#print(M)\n",
    "MTM = M.transpose() @ M\n",
    "#print(f'rank of M: {np.linalg.matrix_rank(M)}')\n",
    "\n",
    "U, S, Vh = np.linalg.svd(M)\n",
    "\n",
    "\n",
    "lamb = Vh[8,:]\n",
    "#print(S)\n",
    "#print(f'T: is {T[0:3,3]}') \n",
    "#print(np.linalg.norm(T[0:3,3]))\n",
    "\n",
    "#print(Vh)\n",
    "\n",
    "#print(rot[0:3,0:3])b\n",
    "print(lamb/lamb[8])\n",
    "print(world_coord[:,2])\n",
    "print(S)\n",
    "\n",
    "#print(1.3*M[:,0]/M[:,8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ed827-703a-416e-9bc9-f95064d59a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3110402c",
   "metadata": {},
   "source": [
    "## Defined up to scale\n",
    "\n",
    "\n",
    "What this means is that if the camera views are a known distance apart then we can calculate the scale of objects.\n",
    "\n",
    "But if they are not then we cannot tell if they are, for example 5cm apart and we are looking at minatures or 1m apart and we are looking at objects 20 times as large.\n",
    "\n",
    "\n",
    "\n",
    "![](images/smallFaraway.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9346908",
   "metadata": {},
   "source": [
    "## Let's take stock\n",
    "So if we get 8 _good_ correspondences, we can determine the Rotation of the camera. \n",
    "\n",
    "We can kind of determine the translation in that 3D points will be related to $T$ by some multiple.\n",
    "\n",
    "From there we can determine the 3D points themselves.\n",
    "\n",
    "We can do this with more than the 8 points. \n",
    "\n",
    "We can do it with any points we have correspondences for but obviously the reconstruction will only be as good as the quality of the correspondences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a86f0",
   "metadata": {},
   "source": [
    "## What should our concerns be?\n",
    "What if the correspondences are not good? \n",
    "\n",
    "- This can lead to degenerate configurations which we will talk about next.\n",
    "- The points may not be degenerate but have all sorts of noise and errors. There are therefore many algorithms for best minimising this. \n",
    "\n",
    "\n",
    "We assumed earlier that we knew the camera intrinsic parameters, what if we don't?  \n",
    "\n",
    "In most cases in the automotive sector you will know the intinisic parameters as you will have calibrated as a separate step. \n",
    "\n",
    "But in the case where you know nothing of the cameras there is an extension to the Essential matrix, called the Fundamental matrix. \n",
    "\n",
    "More later. There will even be a song about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25914b7b",
   "metadata": {},
   "source": [
    "## Sparse Reconstruction\n",
    "\n",
    "What can we tell about the world after it?\n",
    "\n",
    "Emmm, errr, wellll, not a lot really. \n",
    "\n",
    "Knowing a few points in the 3D world is not going to paint you a nice picture of the world.\n",
    "\n",
    "Even with one hundred points, what do we do? \n",
    "\n",
    "Join the dots? \n",
    "\n",
    "The dots aren't numbered, so it's not child's play."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5f9cb",
   "metadata": {},
   "source": [
    "## Degenerate Configurations\n",
    "\n",
    "So the eight point algorithm is often stated as providing a unique solution up to a scale factor for eight 3D points in general position.\n",
    "\n",
    "The _in general position_ can often be missed in amongst the other detail.\n",
    "\n",
    "In general position, means that the points must not lie on certain 2D surfaces, often called critical surfaces.\n",
    "\n",
    "When a configuration does not give us a unique solution for a particular class of transformations, we call this degenerate.\n",
    "\n",
    "Importantly, this refers to the configuration but also the transformations involved.\n",
    "\n",
    "So one transformation's degenerate configuration may be the ideal for another transformation.\n",
    "\n",
    "### Points on a plane in 2D\n",
    "\n",
    "Many of the degenerate configurations for the 8-point algorithm refer to surfaces that are described by quadratic equations. (Sometimes referred to as quadric surfaces).\n",
    "\n",
    "Most of them don't really show up in real world situations but one that definitely does is the situation that the 8-points lie in a 2D plane in the 3D world.\n",
    "\n",
    "For example if all of the 8-points are on the wall of a building for both views then the 8-point algorithm will fail.\n",
    "Line markings for a parking place all lie on a plane.\n",
    "\n",
    "Shortly we will see that if we know that all points fall on a plane then we can turn this degenerate configuration into an advantage, and get away with a 4-point algorithm.\n",
    "\n",
    "### No Translation\n",
    "This is the situation where the two camera views have the exact same camera center, i.e. the camera centers are said to be coincident.\n",
    "\n",
    "So either the camera hasn't moved or it has undergone a pure rotation.\n",
    "\n",
    "Either way, recovery of 3D geometry is not possible in this configuration.\n",
    "\n",
    "The images might be nice for generating a panorama though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732681b",
   "metadata": {},
   "source": [
    "## Planar Homographies\n",
    "\n",
    "Unlike the previous case where we want eight points in general position, here we want four points and they must lie on a plane in the 3D world.\n",
    "\n",
    "One of the ways to describe a plane is with a normal vector. \n",
    "\n",
    "This is a vector that is normal to the plane, i.e. at $90^o$ to the plane.\n",
    "\n",
    "Once again we are using the idea of a null space. \n",
    "\n",
    "In a 3D world a single vector makes up just one dimension. \n",
    "\n",
    "\n",
    "## Normal Vector\n",
    "\n",
    "The normal vector only meets the plane at the origin in the 3D coordinates. \n",
    "\n",
    "Therefore any 3D vector that is in the null space of the normal vector space is in the plane.\n",
    "\n",
    "You can think of this as describing the plane as everything that the normal vector is not. i.e. vectors that have absolutely nothing in common with the normal vector are in the plane. \n",
    "\n",
    "By _in common_ here we mean that if projected onto the normal vector it would result in some non-zero amount.\n",
    "\n",
    "But vectors in the plane, when projected onto the normal vector result in zero.\n",
    "\n",
    "\n",
    "## Plane not passing through origin\n",
    "\n",
    "So previously we assumed that the plane passes through the origin and then the normal vector meets the plane only at the origin.\n",
    "\n",
    "But this is a little restrictive as we want to discuss planes that do not pass through the origin.\n",
    "\n",
    "This is relatively straight forward, we simply move the plane along the normal vector some distance $d$. \n",
    "\n",
    "Now if we project any vector on the plane onto the normal vector, it will result in the scalar value $d$ rather than zero.\n",
    "\n",
    "So we can place the origin at one of the camera centers, which is useful.\n",
    "\n",
    "\n",
    "\n",
    "## Equation of a plane\n",
    "\n",
    "\\begin{equation}\n",
    "\tN^{\\top}\\mathbf{X}_1=d\n",
    "\\end{equation}\n",
    "\n",
    "or\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\frac{1}{d}N^{\\top}\\mathbf{X}_1=1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "This is w.r.t camera one.\n",
    "In terms of camera two's center this is \n",
    "\\begin{equation}\n",
    "\t\\mathbf{X}_2 = R\\mathbf{X}_1 + T\n",
    "\\end{equation}\n",
    "\n",
    "There is a clever trick we can use here. $T$ is the same as $1\\times T$ and we see from the second equation for a plane above  that we have something useful that is equal to 1, and we can substitute it in.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{X}_2 = R\\mathbf{X}_1 + T\\frac{1}{d}N^{\\top}\\mathbf{X}_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815447c",
   "metadata": {},
   "source": [
    "## Homography Matrix\n",
    "\n",
    "You need to be careful to consider the shapes of the vectors to know which side you can multiply to get the right behaviour.\n",
    "We now see that $\\mathbf{X}_1$ is common so we can take it out as a common factor.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{X}_2 = \\left(R + \\frac{1}{d}TN^{\\top}\\right)\\mathbf{X}_1 \\equiv H\\mathbf{X}_1\n",
    "\\end{equation}\n",
    "\n",
    "$H$ is a $3\\times3$ matrix called a homography matrix,\n",
    "and it relates the 3D points that lie on a 2D plane to eachother in terms of the two camera centers, i.e. The same point in two different coordinate frames.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{X}_2 = H\\mathbf{X}_1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## Homography Matrix for 2D\n",
    "Of course we don't usually know the 3D coordinates. We've been here before, we know the 2D so we can say\\\\\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\lambda_2\\mathbf{x}_2 = \\lambda_1H\\mathbf{x}_1\n",
    "\\end{equation}\n",
    "\n",
    "Again as the $\\lambda s$ show, the 2D coordinates are related up to scale by the homography matrix.\n",
    "\n",
    "The homography matrix encodes the camera extrinsic parameters and parameters describing the plane.\n",
    "\n",
    "Just like with the points in general position, we can get rid of $\\lambda s$ by multiplying across by $\\mathbf{x}_{2\\times}$\n",
    "\\begin{equation}\n",
    "\t\\mathbf{x}_{2\\times}H\\mathbf{x}_{1} = 0\n",
    "\\end{equation}\n",
    "\n",
    "This is called the planar epipolar constraint or planar homography constraint. \n",
    "Note the subtle difference, $\\mathbf{x}_{2\\times}$ instead of $\\mathbf{x}_{2}$\n",
    "\n",
    "We can use our stacking operators as before, to make a vector $h_s$\n",
    "\n",
    "$$h_s= \\begin{bmatrix}\n",
    "h_{11}\\\\\n",
    "h_{21}\\\\\n",
    "h_{31}\\\\\n",
    "h_{12}\\\\\n",
    "h_{22}\\\\\n",
    "h_{32}\\\\\n",
    "h_{13}\\\\\n",
    "h_{23}\\\\\n",
    "h_{33}\n",
    " \\end{bmatrix} $$\n",
    "\n",
    "\n",
    "\n",
    "But $\\mathbf{x}_{2\\times}$ is a $3\\times3$ skew symmetric matrix.\n",
    "\n",
    "So $\\mathbf{a}$ this time is a $9\\times3$ matrix instead of a vector.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{a}\\equiv \\mathbf{x}_1 \\otimes \\mathbf{x_{2\\times}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{a}^{\\top}h_s = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da930168",
   "metadata": {},
   "source": [
    "## The four point algorithm\n",
    "If we have $n$ pairs of 2D point correspondances where $n\\geq4$ then each point pair $\\mathbf{x}^j_1,\\mathbf{x}^j_2 $ can be represented by matrix $\\mathbf{a}^j$.\n",
    "\n",
    "These can be put together in a combined matrix $\\mathbf{A}$ as follows.\n",
    "\\begin{equation}\n",
    "\\mathbf{A}\\equiv (\\mathbf{a}^1,...,\\mathbf{a}^n)^{\\top}\n",
    "\\end{equation}\n",
    "\n",
    "Which is a $3n\\times9$ matrix.\n",
    "\n",
    "And this gives us a full system to solve.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{A}h_s=0\n",
    "\\end{equation}\n",
    "\n",
    "Just like with the essential matrix, the homography matrix can be estimated up to a scale factor.\n",
    "So the consise algorithm is\n",
    "\n",
    "1. Compute the matrix $\\mathbf{A}$ for the four points\n",
    "2. Compute a solution to $h_s$ for equation above using SVD and taking the column vector with the smallest singular value.\n",
    "3. Extract the motion parameters from the homography matrix $H=R+\\frac{1}{d}TN^{\\top}$.\n",
    "\n",
    "\n",
    "$H$ can be decomposed into $R, N$ and $\\frac{T}{d}$.\n",
    "[Inra, Ezio Malis, Manuel Vargas Page 8](https://hal.inria.fr/inria-00174036v3/document)\n",
    "\n",
    "Once again we see that we can reconstruct the translation up to a scale. \n",
    "In this case it is scaled by the distance to the plane.\n",
    "We can compute the 3D coordinates as we did for the 8-point algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc800c",
   "metadata": {},
   "source": [
    "##  Effect of the camera matrix $K$\n",
    "The essential matrix worked on the principle that we know the camera intrinsic paramters and further that we assume no skew and we give everything in units of focal length leading to the canonical camera matrix $K =I$ where $I$ is the $3\\times3$ identity matrix.\n",
    "\n",
    "It's reasonable to think of this as not so much knowing the camera matrix as pretending it doesn't exist.\n",
    "\n",
    "However the camera matrix, if it is not the identity, will have an effect on the projection of 3D coordinates.\n",
    "\n",
    "\n",
    "\n",
    "## If we know $K$\n",
    "If we have separately calculated the calibration matrix for the camera and therefore know $K$, all we need do is transform our pixel coordinates to normalised pixel coordinates using $K^{-1}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\mathbf{x}=K^{-1}\\mathbf{x}'\n",
    "\\end{equation}\n",
    "\n",
    "We can do this with  all point correspondences and then we are at our starting point for either our 4 or 8-point algorithm.\n",
    "\n",
    "This is the most likely scenario in the automotive setting. \n",
    "\n",
    "\n",
    "## The uncalibrated camera\n",
    "Imagine the situation where we have two views but no information about the camera.\n",
    "\n",
    "This might be the case with archive film.\n",
    "\n",
    "It is also the case where we take two images of a location from the internet from two different photographers.\n",
    "\n",
    "i.e. two views, two cameras, no information.\n",
    "\n",
    "This is attempting reconstruction from un-calibrated views.\n",
    "\n",
    "\n",
    "\n",
    "## The Fundamental Matrix\n",
    "\n",
    "Lets assume the same camera has taken both views, so just one camera matrix $K$.\n",
    "\n",
    "We can rework the epipolar constraint as follows.\n",
    "\n",
    "\\begin{equation}\n",
    "\tx_2^{\\top}T_{\\times}Rx_1=0 \\to x_2^{'}K^{-\\top}T_{\\times}RK^{-1}x'_1=0\n",
    "\\end{equation}\n",
    "\n",
    "This gives rise to the fundamental matrix $F$\n",
    "\n",
    "\\begin{equation}\n",
    "\tF = K^{-\\top}T_{\\times}RK^{-1} \\text{\\quad  or \\quad } F = K^{-\\top}EK^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t x_2^{'T}K^{-\\top}T_{\\times}RK^{-1}x'_1=0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "## SVD of the fundamental matrix $F$\n",
    "$K$ is invertible so $F$ will have the same rank as $E$.\n",
    "\n",
    "So we can use the exact same method of SVD of $F$ as for $E$, i.e.\n",
    "\\begin{equation}\n",
    "\t\\text{SVD } F = U\\Sigma V^{\\top}. \n",
    "\\end{equation}\n",
    "With \n",
    "\\begin{equation}\n",
    "\t\\Sigma = \\begin{bmatrix}\n",
    "\t\\sigma_1 & 0 & 0\\\\\n",
    "0 & \\sigma_2 & 0\\\\\n",
    "0 & 0 &0\n",
    " \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Many texts and courses start with the Fundamental matrix and break it down to the Camera matrix and Essential matrix.\n",
    "\n",
    "However chronologically the Essential matrix came first.\n",
    "\n",
    "Either way the method for solving them is the same.\n",
    "\n",
    "Now, about that song.\n",
    "[Fundamental Matrix Song](https://www.youtube.com/watch?v=DgGV3l82NTk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417caebd",
   "metadata": {},
   "source": [
    "## Some considerations on $F$\n",
    "Note that $\\sigma_1$ and $\\sigma_2$ are not necessarily the same size as in the Essential Matrix.\n",
    "\n",
    "Getting $F$ may be similar to getting $E$ but from there things get harder. The decomposition is not so easy, i.e. we cannot easily separate the intrinsic and extrinsic parameters.\n",
    "\n",
    "We can determine reconstructions up to a projective reconstruction.\n",
    "\n",
    "The take away is, **try to find the camera intrinsics separately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be85a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be4b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
