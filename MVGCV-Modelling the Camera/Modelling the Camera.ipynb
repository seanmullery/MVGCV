{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e9729f-b17c-404d-b8c1-21cee6139721",
   "metadata": {},
   "source": [
    "![\"HCI Banner Logos for ATU Sligo, the HCI Human capital initiative and Higher Education 4.0\"](images/HCIBanner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e190e22-7090-409d-9ea9-554da37de831",
   "metadata": {},
   "source": [
    "# Modelling the Camera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d39ed-d360-4ad2-bcc3-13f58eb1ebc9",
   "metadata": {},
   "source": [
    "## Orthographic}\n",
    "This is fairly simple. \n",
    "If your projection is from the origin of the world 3D coordinates then to find the 2D projection you just drop the third coordinate.\n",
    "\n",
    "This is of limited use as cameras don't really work this way (there are telecentric lenses that do), but it can be a good approximation if your camera position is very far away (theoretically it should be infinity).\n",
    "\n",
    "So it's a reasonable approximation for telephoto lenses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37139b2-1eb3-4d82-bc03-d0357a6fa6e6",
   "metadata": {},
   "source": [
    "## Perspective Projection -  Pinhole Camera Model\n",
    "\n",
    "The pinhole camera model (and similarly the thin lens model) work on the principle of _similar triangles_.\n",
    "\n",
    "See the diagram below.\n",
    "\n",
    "A world point $\\mathbf{X} \\in \\mathbb{R}^3$ is mapped to an image point $\\mathbf{x} \\in \\mathbb{R}^2$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](images/pinholeCamera.jpg)\n",
    "\n",
    "Now we have to decide where the origin is. \n",
    "\n",
    "We can decide this arbitrarily as long as we stick to it. \n",
    "\n",
    "If the origin is at the camera sensor we have the figure below \n",
    "\n",
    "\n",
    "![](images/OriginAtSensor.jpg)\n",
    "\n",
    "If the origin is at the pinhole we have the figure below. \n",
    " \n",
    "The formulae are different and as you can see the pinhole version is a little simpler so we will use that one.\n",
    "\n",
    "\n",
    "![](images/originAtPinhole.jpg)\n",
    "You will note that the image formed on the sensor is upside down. \n",
    "\n",
    "We don't show it, but it shouldn't take too much imagination to see that it will also be be flipped left for right. \n",
    "\n",
    "This is not a problem, as we can easily flip these in software or just read off the sensor data upside down and backwards. \n",
    "\n",
    "You may have noticed that the front camera on your mobile phone only flips the image vertically but not left for right. \n",
    "\n",
    "People are used to seeing themselves in a mirror so if taking a photo of themselves this is how they expect it to behave. \n",
    "\n",
    "Most people also prefer their image in a mirror to their actual image, so the readout of the selfie camera can be set to this too.\n",
    "\n",
    "It is worth noting that this also happens in the human eye and our brain does the flip or we believe it does.\n",
    "Interestingly, people have done experiments with headsets that flip the image upside down and it only takes a day or two for the brain to adjust to this new norm.\n",
    "\n",
    "\n",
    "[Clip from BBC documentary, cycling with the world upside down.](https://www.youtube.com/watch?v=-kohUpQwZt8)\n",
    " \n",
    "\n",
    "We can make our lives easier by pretending that the image plane is in front of the pinhole instead of behind. \n",
    "\n",
    "The maths still works accept the minus sign is removed. \n",
    "\n",
    "See below. This is the idea we will use from now on unless we have to make an exception.\n",
    "\n",
    "\n",
    "![](images/sensorInFront.jpg)\n",
    "\n",
    "Now this allows us to link to the idea we used for homogeneous coordinates. \n",
    "\n",
    "Our image plane is at $f$ (the focal length). \n",
    "\n",
    "The Homogeneous plane can be anywhere, but by convention we used $(Z=1)$. \n",
    "\n",
    "If we have a world point at $(X=4, Y=5, Z=3)$ and our focal length is $f=2$ (don't worry about units yet).\n",
    "\n",
    "Treat the world coordinate as a homogeneous 2D coordinate.\n",
    "\n",
    "So the 2D coordinates in the plane at ($Z=1$) would be $\\frac{4}{3}, \\frac{5}{3}$. \n",
    "\n",
    "If we project the image on the plane at $Z=1$ out to the focal length $(Z=f=2)$ then we get 2D coordinates  $(\\frac{2\\times4}{3}, \\frac{2\\times5}{3})$.\n",
    "\n",
    "I.e. in the general case we get 2D image coordinates $(\\frac{fX}{Z}, \\frac{fY}{Z})$.\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e16bfc-5cb7-4c45-80ca-641f5baf373d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03d920812d34d6da05769cb1f423ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='Elevation', max=90), IntSlider(value=180, description='â€¦"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Define a function to update the plot with both elevation and azimuth angles\n",
    "def update_plot(elev_angle, azim_angle, roll_angle,Xw, Yw, Zw, FL):\n",
    "    # Create a new matplotlib figure and axis\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Set axes labels and limits\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_xlim([-2, 2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_zlim([0, 5])\n",
    "\n",
    "    # Plotting the axes by creating lines for each axis\n",
    "    axes = [        \n",
    "        [(-1, 0, 0), (1, 0, 0)],   # x-axis\n",
    "        [(0, -1, 0), (0, 1, 0)],  # y-axis\n",
    "        [(0, 0, 0), (0, 0, 5)]  # z-axis\n",
    "    ]\n",
    "    colors = ['r', 'g', 'b']  # Colors for each axis\n",
    "    for ax_line, color in zip(axes, colors):\n",
    "        ax.plot(*zip(*ax_line), color=color)\n",
    "\n",
    "    # adding the world coordinate point\n",
    "    \n",
    "\n",
    "    world_coord = (Xw, Yw, Zw)\n",
    "\n",
    "    ax.scatter(*world_coord, color='magenta')\n",
    "    ax.text(Xw, Yw, Zw, \"World coordinate\", color='magenta')\n",
    "\n",
    "    # Drawing a line from the origin to the point\n",
    "    ax.plot([0, world_coord[0]], [0, world_coord[1]], [0, world_coord[2]], color='magenta')\n",
    "\n",
    "    # Creating a plane normal to the y-axis centered at (0, 1, 0)\n",
    "    x = np.linspace(-1, 1, 10)\n",
    "    y = np.linspace(-1, 1, 10)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = FL*np.ones_like(X)  # Plane centered at Z=focal length\n",
    "\n",
    "    # Adding the plane with transparency\n",
    "    ax.plot_surface(X, Y, Z, color='cyan', alpha=0.2)\n",
    "\n",
    "    # The intersection point where the magenta line intersects the plane Z = 1\n",
    "\n",
    "    intersection_point = (FL*Xw/Zw, FL*Yw/Zw, FL*Zw/Zw)\n",
    "    ax.scatter(*intersection_point, color='magenta')\n",
    "\n",
    "    # Adjust view\n",
    "    ax.view_init(elev=elev_angle, azim=azim_angle, roll=roll_angle)\n",
    "    \n",
    "    #ax.view_init(elev=30, azim=45, roll=15)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "elev_slider = widgets.IntSlider(min=0, max=90, step=1, value=10, description='Elevation')\n",
    "azim_slider = widgets.IntSlider(min=0, max=180, step=1, value=180, description='Azimuth')\n",
    "roll_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-90, description='Roll')\n",
    "\n",
    "# Sliders for world coordinates\n",
    "Xw_slider = widgets.FloatSlider(min=-2, max=2, step=0.1, value=0, description='Xw')\n",
    "Yw_slider = widgets.FloatSlider(min=-2, max=2, step=0.1, value=0.5, description='Yw')\n",
    "Zw_slider = widgets.FloatSlider(min=0, max=5, step=0.1, value=3, description='Zw')\n",
    "FL_slider = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1, description='Focal Length')\n",
    "# Interactive widget\n",
    "widgets.interactive(update_plot, elev_angle=elev_slider, azim_angle=azim_slider, roll_angle=roll_slider, Xw=Xw_slider, Yw=Yw_slider, Zw=Zw_slider, FL=FL_slider)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7363f0-ffa9-47a1-8e2d-cdc4e4d61911",
   "metadata": {},
   "source": [
    "## Camera Intrinsic and Extrinsic Parameters\n",
    "So here is what we have to do.\n",
    "We must go from\n",
    "\n",
    "World coords (3D) $\\to$ Camera coords (3D) $\\to$ Image coords (2D) $\\to$ Pixel coords (2D Discrete).\n",
    "\n",
    "So we start with a vector in 3D and we change this to homogeneous Coordinates in 4D. \n",
    "We will call this $\\textbf{X} = (X, Y, Z, 1)^{\\top}$. \n",
    "\n",
    "And this is relative to some world coordinate frame, it will be important to know or decide where the origin of the world coordinate frame is.\n",
    "\n",
    "Next we need to transform this vector to a coordinate relative to the camera origin, which we decided was either the pin hole or the center of the lens. \n",
    "This requires the vector to under go rigid body motion based on the **Extrinsic** parameters of the camera. So these include translation and rotation.\n",
    "\n",
    "So this has moved the vector from the world frame to the camera frame.\n",
    "\n",
    "In effect what we are doing is moving the 3D origin from the world to the pinhole of the camera and all the vectors must move relative to that. \n",
    "The rotation is because the axis of the origin at the camera may be different from the world frame because the camera is rotated in some way.\n",
    "\n",
    "Next we need to transform the 3D coordinate to a 2D image coordinate. \n",
    "\n",
    "This will require a change from 4D Homogeneous to 3D Homogeneous. \n",
    "\n",
    "We will simply drop one dimension and divide the first two coordinates by the third and multiply by the focal length. \n",
    "\n",
    "Warning: dividing across by the third coordinate is a non-linear operation. \n",
    "\n",
    "It's nothing we can't handle, but it makes a mess of our elegant linear algebra. \n",
    "\n",
    "For this reason we take it outside the equation and put it on the other side of the equals. It's denoted below as $\\lambda$. \n",
    "\n",
    "Note that it is not Z as that is the world coordinate that undergoes a lot of changes before it becomes the third coordinate of the final homogeneous image vector.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "The final thing we need to do is change the 2D coordinates to 2D discrete which means quantizing the space into pixels and usually means shifting the origin to one corner of the sensor. \n",
    "\n",
    "The most obvious choice being the top-left of the final image when it has righted itself but this is manufacturer dependent.\n",
    "\n",
    "The focal length, and the scale factors for the pixels in both x and y are referred to as the **Intrinsic** Camera parameters.\n",
    " \n",
    "\n",
    "Any distortions or differences from the pinhole model are also included under the heading of the camera Intrinsic parameters but may or may not be dealt with directly here and may be modified later in software.\n",
    "\n",
    "\n",
    "$$\\lambda \\begin{bmatrix}\n",
    "                x\\\\\n",
    "                y\\\\\n",
    "                1\n",
    "            \\end{bmatrix} = \\begin{bmatrix}\n",
    "                s_x    & 0 & O_x  \\\\\n",
    "                0     & s_y & O_y  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                f    & 0 & 0 \\\\\n",
    "                0     & f & 0  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                1    & 0 & 0 & 0 \\\\\n",
    "                0     & 1 & 0 & 0 \\\\\n",
    "                0     & 0 & 1 & 0 \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                r_{11}     & r_{12} & r_{13} & t_x \\\\\n",
    "                r_{21}     & r_{22} & r_{23} & t_y \\\\\n",
    "                r_{31}     & r_{32} & r_{33} & t_z \\\\\n",
    "                0 & 0 & 0 & 1\n",
    "            \\end{bmatrix} \n",
    "            \\begin{bmatrix}\n",
    "                X\\\\\n",
    "                Y\\\\\n",
    "                Z\\\\\n",
    "                1\n",
    "\\end{bmatrix} $$   \n",
    "\n",
    "The intrinsic parameters are often put together into one matrix which we will call K.\n",
    "\n",
    "$$K=\\begin{bmatrix}\n",
    "                fs_x    & 0 & O_x  \\\\\n",
    "                0     & fs_y & O_y  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}=\\begin{bmatrix}\n",
    "                s_x    & 0 & O_x  \\\\\n",
    "                0     & s_y & O_y  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                f    & 0 & 0 \\\\\n",
    "                0     & f & 0  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}$$\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "If we put all of these together into one matrix called M we get.\n",
    "\n",
    "$$ M = \\begin{bmatrix}\n",
    "                m_{11}     & m_{12} & m_{13} & m_{14} \\\\\n",
    "                m_{21}     & m_{22} & m_{23} & m_{24} \\\\\n",
    "                m_{31}     & m_{32} & m_{33} & m_{34} \n",
    "            \\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "                s_x    & 0 & O_x  \\\\\n",
    "                0     & s_y & O_y  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                f    & 0 & 0 \\\\\n",
    "                0     & f & 0  \\\\\n",
    "                0     & 0 & 1  \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                1    & 0 & 0 & 0 \\\\\n",
    "                0     & 1 & 0 & 0 \\\\\n",
    "                0     & 0 & 1 & 0 \n",
    "            \\end{bmatrix}\n",
    "                \\begin{bmatrix}\n",
    "                r_{11}     & r_{12} & r_{13} & t_x \\\\\n",
    "                r_{11}     & r_{12} & r_{13} & t_y \\\\\n",
    "                r_{11}     & r_{12} & r_{13} & t_z \\\\\n",
    "                0 & 0 & 0 & 1\n",
    "            \\end{bmatrix} $$\n",
    "\n",
    "$$\\lambda \\begin{bmatrix}\n",
    "                x\\\\\n",
    "                y\\\\\n",
    "                1\n",
    "            \\end{bmatrix} = M\\mathbf{X}$$\n",
    "\n",
    "To calculate the value (x,y) we use\n",
    "\n",
    "\n",
    "$x=\\frac{M_1^{\\top}\\mathbf{X}}{M_3^{\\top}\\mathbf{X}}$, $y=\\frac{M_2^{\\top}\\mathbf{X}}{M_3^{\\top}\\mathbf{X}} $, $z=1$\n",
    " \n",
    "\n",
    "Bear in mind that this transforms only one world point.\n",
    "And there are an infinite number of world coordinates.\n",
    "Also keep in mind that any 2D coordinate is the projection along the whole line in 3D ($\\lambda x, \\lambda y, \\lambda $) but only the closest object will appear in the image and it will occlude all points behind it.\n",
    "\n",
    "The previous detail is useful to aid our understanding of what happens and in particular to help us work back. \n",
    "\n",
    "It's actually the matrix M and it's decomposition that is of interest to us to try work our way back from image coordinates to 3D world coordinates.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f78fb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8086b0f266e48f78378e22606eb5280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='Elevation', max=180, min=-180), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "camera_coords = np.array(np.zeros([2,2]))\n",
    "epipole_coords = np.array(np.zeros([2,2]))\n",
    "lambda1 = 0\n",
    "lambda2 = 0\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "\n",
    "\n",
    "\n",
    "def update_2d_plots(fig,gs, camera_coords, epipole_coords, ep):\n",
    "    \n",
    "    #fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    #axs = [fig.add_subplot(1, 3, 2), fig.add_subplot(1, 3, 3)]\n",
    "    axs = [fig.add_subplot(gs[0,3]),fig.add_subplot(gs[1,3])]\n",
    "    # Clear existing plots\n",
    "    axs[0].cla()\n",
    "    axs[1].cla()\n",
    "\n",
    "    # Update and configure the first plot (Camera 1 View)\n",
    "    axs[0].set_title('Camera 1 View')\n",
    "    axs[0].set_xlim(-1, 1)\n",
    "    axs[0].set_ylim(-0.5, 0.5)\n",
    "    rect1 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(0, 1, 1, 0.2))  # Cyan color\n",
    "    axs[0].add_patch(rect1)\n",
    "    axs[0].scatter(camera_coords[0][0], camera_coords[0][1], color='magenta')\n",
    "    axs[0].text(camera_coords[0][0], camera_coords[0][1], \"x1\", color='black')\n",
    "    if ep:\n",
    "        axs[0].scatter(epipole_coords[0][0], epipole_coords[0][1], color='black', marker='x')\n",
    "        axs[0].plot([camera_coords[0][0], epipole_coords[0][0]], [camera_coords[0][1], epipole_coords[0][1]], color='magenta')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update and configure the second plot (Camera 2 View)\n",
    "    axs[1].set_title('Camera 2 View')\n",
    "    axs[1].set_xlim(-1, 1)\n",
    "    axs[1].set_ylim(-0.5, 0.5)\n",
    "    rect2 = patches.Rectangle((-0.6, -0.4), 1.2, 0.8, color=(1, 1, 0, 0.2))  # Yellow color\n",
    "    axs[1].add_patch(rect2)\n",
    "    axs[1].scatter(camera_coords[1][0], camera_coords[1][1], color='green')\n",
    "    axs[1].text(camera_coords[1][0], camera_coords[1][1], \"x2\", color='black')\n",
    "    if ep:\n",
    "        axs[1].scatter(epipole_coords[1][0], epipole_coords[1][1], color='black', marker='x')\n",
    "        axs[1].plot([camera_coords[1][0], epipole_coords[1][0]], [camera_coords[1][1], epipole_coords[1][1]], color='green')\n",
    "    # Redraw the plots\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "# Define a function to update the plot with both elevation and azimuth angles\n",
    "def update_plot(elev_angle, azim_angle, roll_angle,Xw, Yw, Zw, FL2, Alpha, Beta, Gamma, tx, ty, tz, ep):\n",
    "    # Create a new matplotlib figure and axis\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    gs = GridSpec(2, 4, figure=fig)\n",
    "    #fig = plt.figure(figsize=(30, 10))\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = fig.add_subplot(gs[0:4,:], projection='3d')\n",
    "    # Set axes labels and limits\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_xlim([-2, 2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_zlim([0, 4])\n",
    "    global E_mat\n",
    "    global rot\n",
    "\n",
    "\n",
    "    # Second camera array\n",
    "    K=np.array([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0,1,0],\n",
    "               [0,0,0,1]])\n",
    "    \n",
    "    T = np.array([[1,0,0,tx],\n",
    "                   [0,1,0,ty],\n",
    "                   [0,0,1,tz],\n",
    "                   [0,0,0,1]])\n",
    "    \n",
    "    # Individual Euler angle matrices\n",
    "    alphaRot = np.array([[1,0,0,0],\n",
    "       [0,math.cos(math.pi*Alpha/180),-math.sin(math.pi*Alpha/180),0],\n",
    "       [0,math.sin(math.pi*Alpha/180),math.cos(math.pi*Alpha/180),0],\n",
    "       [0,0,0,1]])\n",
    "    betaRot = np.array([[math.cos(math.pi*Beta/180),0,math.sin(math.pi*Beta/180),0],\n",
    "       [0,1,0,0],\n",
    "       [-math.sin(math.pi*Beta/180),0,math.cos(math.pi*Beta/180),0],\n",
    "       [0,0,0,1]])\n",
    "    gammaRot = np.array([\n",
    "       [math.cos(math.pi*Gamma/180),-math.sin(math.pi*Gamma/180),0,0],\n",
    "       [math.sin(math.pi*Gamma/180),math.cos(math.pi*Gamma/180),0,0],\n",
    "        [0,0,1,0],\n",
    "       [0,0,0,1]])\n",
    "    # Full rotation matrix but keep in mind that changing the order will change the rotation.\n",
    "    rot = alphaRot @ betaRot @ gammaRot\n",
    "    \n",
    "    # Camera two focal length only.\n",
    "    K_FL = ([[FL2,0,0,0],\n",
    "       [0,FL2,0,0],\n",
    "       [0,0,FL2,0],\n",
    "       [0,0,0,1]])\n",
    "    \n",
    "    '''Special matrix for the applying the focal length to the z-axis only \n",
    "    This is used to move the image sensor with the focal length but not resize the sensor\n",
    "    '''\n",
    "    K_plane = ([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0 ,FL2,0],\n",
    "               [0,0 ,0,1]])\n",
    "    \n",
    "    '''K_NF is the camera two matrix but without the focal length\n",
    "    This is to all the red, green and blue axes for camera two \n",
    "    to be the same size as for camera one. So this matrix is to help \n",
    "    with the visualisation only'''\n",
    "    K_NF = K @ T @ rot \n",
    "    \n",
    "    '''K_z is for the visualisation only. It allows the camera two frame to be shown in the correct\n",
    "    position without re-sizing the frame. Note, as we are only affecting the z-axis, ordering matters here.\n",
    "    You must do the rotation and translation first and only then extend the z-axis or otherwise you will rotate\n",
    "    and translate what you did to the z-axis and point it in another direction'''\n",
    "   \n",
    "    K_z = K @ T  @ rot @ K_plane \n",
    "   \n",
    "    '''This is the full camera two matrix (relative to camera one). The focal length is in multiples \n",
    "    of the first camera focal length. Hence the first camera focal lenght is fixed at 1 and therefore all \n",
    "    coordinates are in units of the focal length of camera one'''\n",
    "    \n",
    "    K = K  @ T  @  rot @  K_FL  \n",
    "    \n",
    "       \n",
    "    # Plotting the axes for the two cameras\n",
    "    axes = np.array([[[-.1, 0, 0],[.1, 0, 0]],\n",
    "            [[0, -.1, 0], [0, .1, 0]],\n",
    "            [[0, 0, 0], [0, 0, 0.5]]])\n",
    "               \n",
    "       \n",
    "    axes_cam_2 = axes.reshape(6,3)\n",
    "    axes_cam_2 = np.hstack([axes_cam_2, np.ones((6, 1))])\n",
    "    axes_cam_2 = K_NF @ axes_cam_2.transpose()\n",
    "    axes_cam_2 = axes_cam_2.transpose() \n",
    "    # Remove the last column\n",
    "    axes_cam_2 = axes_cam_2[:, :-1]\n",
    "    axes_cam_2 = axes_cam_2.reshape(3,2,3)\n",
    "    colors = ['r', 'g', 'b']  # Colors for each axis\n",
    "    for i in range(0, 3):\n",
    "        ax.plot([axes_cam_2[i][0][0], axes_cam_2[i][1][0]],  # X coordinates\n",
    "            [axes_cam_2[i][0][1], axes_cam_2[i][1][1]],  # Y coordinates\n",
    "            [axes_cam_2[i][0][2], axes_cam_2[i][1][2]],  # Z coordinates\n",
    "            color=colors[i]) \n",
    "        \n",
    "        ax.plot([axes[i][0][0], axes[i][1][0]],  # X coordinates\n",
    "            [axes[i][0][1], axes[i][1][1]],  # Y coordinates\n",
    "            [axes[i][0][2], axes[i][1][2]],  # Z coordinates\n",
    "            color=colors[i])   \n",
    "     \n",
    "    \n",
    "    \n",
    "    # adding the world coordinate point\n",
    "    world_coord = np.array([Xw, Yw, Zw])\n",
    "    ax.scatter(*world_coord, color='black')\n",
    "    ax.text(Xw, Yw, Zw, \"X\", color='black')\n",
    "\n",
    "    # Drawing a line from the origin to the  World coordinate point\n",
    "    ax.plot([0, world_coord[0]], [0, world_coord[1]], [0, world_coord[2]], color='magenta')\n",
    "    \n",
    "    # Creating a plane normal to the y-axis centered at (0, 1, 0)\n",
    "    x = np.linspace(-.6, .6, 10)\n",
    "    y = np.linspace(-.4, .4, 10)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.ones_like(X)  # Plane centered at Z=focal length\n",
    "    image_plane1 = np.array([X,Y,Z, np.ones_like(X)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    camera_2_center = K_NF @ np.array([0,0,0,1])\n",
    "    # Drawing a line from the camera 2 center to the point\n",
    "    ax.plot([camera_2_center[0], world_coord[0]], [camera_2_center[1], world_coord[1]], [camera_2_center[2], world_coord[2]], color='green')\n",
    "    \n",
    "    # Adding the plane with transparency\n",
    "    ax.plot_surface(image_plane1[0], image_plane1[1], image_plane1[2], color='cyan', alpha=0.2)\n",
    "    \n",
    "    # This reshapes image_plane1 for matrix multiplication by our camera 2 matrix\n",
    "    image_plane2 = K_z @ image_plane1.reshape(4,-1) \n",
    "    \n",
    "    # Reshaping back to original shape\n",
    "    image_plane2 = image_plane2.reshape(image_plane1.shape) \n",
    "    ax.plot_surface(image_plane2[0], image_plane2[1], image_plane2[2], color='yellow', alpha=0.2)\n",
    "    \n",
    "    # The intersection point where the magenta line intersects the image_plane1 Z = 1\n",
    "    intersection_point = (Xw/Zw, Yw/Zw, Zw/Zw)\n",
    "    cam_1_coord = np.array(intersection_point[:2])\n",
    "    \n",
    "    \n",
    "    ax.scatter(*intersection_point, color='magenta')\n",
    "    world_hom = np.array([Xw,Yw,Zw,1])\n",
    "    try:\n",
    "        K_inv = np.linalg.inv(K)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"The matrix is not invertible.\")\n",
    "        \n",
    "    temp_world = K_inv @ world_hom\n",
    "    \n",
    "    intersection_point_imageP2 = np.array([FL2*temp_world[0]/temp_world[2], \n",
    "                                  FL2*temp_world[1]/temp_world[2], \n",
    "                                  FL2*temp_world[2]/temp_world[2],1])\n",
    "    \n",
    "    x2 = intersection_point_imageP2[:3]\n",
    "    cam_2_coord = intersection_point_imageP2[:2]\n",
    "    \n",
    "    intersection_point_imageP2 = K_NF @ intersection_point_imageP2\n",
    "    pt = (intersection_point_imageP2[0],intersection_point_imageP2[1],intersection_point_imageP2[2])\n",
    "    ax.scatter(*pt, color='green')\n",
    "    \n",
    "    # draw line between camera centers\n",
    "    ax.plot([0, camera_2_center[0]], [0, camera_2_center[1]], [0, camera_2_center[2]], color='cyan')\n",
    "    \n",
    "    points = np.array([[0, 0, 0],  # Origin - camera 1 center\n",
    "                       [world_coord[0], world_coord[1], world_coord[2]],  # World coordinate\n",
    "                       [camera_2_center[0], camera_2_center[1], camera_2_center[2]]])  # Camera 2 center\n",
    "\n",
    "    # Shade in the Epipolar plane\n",
    "    epipoloar_plane = Poly3DCollection([points])\n",
    "    epipoloar_plane.set_color('grey')\n",
    "    epipoloar_plane.set_alpha(0.2)  # Adjust transparency here\n",
    "    ax.add_collection3d(epipoloar_plane)\n",
    "    \n",
    "    # Show the epipole for camera 1\n",
    "    cam_1_epipole = (camera_2_center[0]/camera_2_center[2], \n",
    "                     camera_2_center[1]/camera_2_center[2], \n",
    "                     camera_2_center[2]/camera_2_center[2])\n",
    "    ax.scatter(*cam_1_epipole, color='black', marker='x')\n",
    "    epipole_coords[0] = np.array([cam_1_epipole[0], cam_1_epipole[1]])\n",
    "    \n",
    "    # Show the epipole for camera 2\n",
    "    cam_2_view_origin = K_inv @ np.array([0,0,0,1])\n",
    "    cam_2_epipole = (cam_2_view_origin[0]/cam_2_view_origin[2], \n",
    "                     cam_2_view_origin[1]/cam_2_view_origin[2],\n",
    "                     cam_2_view_origin[2]/cam_2_view_origin[2], 1)\n",
    "    epipole_coords[1] = np.array([cam_2_epipole[0], cam_2_epipole[1]])\n",
    "    cam_2_epipole = K @ cam_2_epipole\n",
    "    ax.scatter(*cam_2_epipole[:3], color='black', marker='x')\n",
    "    \n",
    "    # Adjust view\n",
    "    ax.view_init(elev=elev_angle, azim=azim_angle, roll=roll_angle)\n",
    "    \n",
    "    #show view in camera 1    \n",
    "    cam_1_coord = np.array([world_coord[0]/world_coord[2], world_coord[1]/world_coord[2]])\n",
    "    \n",
    "    \n",
    "    camera_coords[0] = cam_1_coord\n",
    "    camera_coords[1] = cam_2_coord\n",
    "    \n",
    "    \n",
    "    \n",
    "    update_2d_plots(fig,gs, camera_coords, epipole_coords, ep)\n",
    "    \n",
    "    lambda1 = world_coord[2]#math.sqrt((world_coord[0]**2)+(world_coord[1]**2)+(world_coord[2]**2))\n",
    "    lambda2 = FL2*temp_world[2]# math.sqrt((world_coord[0]-camera_2_center[0])**2+(world_coord[1]-camera_2_center[1])**2+(world_coord[2]-camera_2_center[2])**2)\n",
    "    \n",
    "    \n",
    "    print(f'lambda1:{lambda1}')\n",
    "    print(f'lambda2:{lambda2}')\n",
    "    \n",
    "    \n",
    "    x1 = np.append(cam_1_coord, 1)\n",
    "    print(f'x1:{x1}')\n",
    "    #np.append(cam_2_coord, 1)\n",
    "    print(f'x2:{x2}')\n",
    "    Tx = np.array([[0, -tz, ty],\n",
    "                   [tz, 0, -tx],\n",
    "                   [-ty, tx, 0]])\n",
    "    \n",
    "    R = np.array(rot[:3,:3])\n",
    "    print(f'x1TxRx2:{ x1 @ Tx @ R @ x2}')\n",
    "    print(f'lambda1*x1:{lambda1*x1}')\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    print(f'R(lambda1*x1)+T:{R_inv @ (lambda1*x1 -np.array([tx, ty,tz])) }' )\n",
    "    print(f'lambda2*x2:{lambda2*x2}')\n",
    "    \n",
    "    E_mat= Tx @ R\n",
    "    \n",
    "    \n",
    "    print(f'Determinant of E=TxR: {np.linalg.det(E_mat)}')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "elev_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Elevation')\n",
    "azim_slider = widgets.IntSlider(min=-180, max=180, step=1, value=90, description='Azimuth')\n",
    "roll_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-90, description='Roll')\n",
    "\n",
    "# Sliders for world coordinates\n",
    "Xw_slider = widgets.FloatSlider(min=-2, max=2, step=0.1, value=0, description='Xw')\n",
    "Yw_slider = widgets.FloatSlider(min=-2, max=2, step=0.1, value=0.5, description='Yw')\n",
    "Zw_slider = widgets.FloatSlider(min=0, max=5, step=0.1, value=3, description='Zw')\n",
    "\n",
    "FL_slider2 = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1.0, description='Cam 2 Focal')\n",
    "\n",
    "alpha_slider = widgets.IntSlider(min=-180, max=180, step=1, value=0, description='Cam2 Alpha')\n",
    "beta_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-150, description='Cam2 Beta')\n",
    "gamma_slider = widgets.IntSlider(min=-180, max=180, step=1, value=-70, description='Cam2 Gamma')\n",
    "\n",
    "\n",
    "tx_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Tx')\n",
    "ty_slider = widgets.FloatSlider(min=-2.0, max=2.0, step=0.1, value=1, description='Ty')\n",
    "tz_slider = widgets.FloatSlider(min=0.0, max=5.0, step=0.1, value=4, description='Tz')\n",
    "\n",
    "# Group sliders into two columns\n",
    "left_box = widgets.VBox([elev_slider, azim_slider, roll_slider, Xw_slider, Yw_slider, Zw_slider ])\n",
    "right_box = widgets.VBox([ FL_slider2, alpha_slider, beta_slider, gamma_slider, tx_slider, ty_slider, tz_slider])\n",
    "\n",
    "epipoles_checkbox = widgets.Checkbox(value=False, description='Show Epipoles in 2D',disabled=False)\n",
    "\n",
    "# Combine the two columns into a single horizontal layout\n",
    "ui = widgets.HBox([left_box,  right_box])\n",
    "\n",
    "\n",
    "# Interactive widget\n",
    "out = widgets.interactive_output(update_plot, {'elev_angle': elev_slider, 'azim_angle': azim_slider, \n",
    "                                               'roll_angle': roll_slider, 'Xw': Xw_slider, \n",
    "                                               'Yw': Yw_slider, 'Zw': Zw_slider, 'FL2': FL_slider2, \n",
    "                                               'Alpha': alpha_slider, 'Beta': beta_slider, 'Gamma': gamma_slider,\n",
    "                                              'tx': tx_slider, 'ty': ty_slider, 'tz': tz_slider, 'ep': epipoles_checkbox})\n",
    "\n",
    "sliders_box = widgets.VBox([elev_slider, azim_slider, roll_slider, \n",
    "                            Xw_slider, Yw_slider, Zw_slider,\n",
    "                            FL_slider2, alpha_slider, beta_slider, \n",
    "                            gamma_slider, tx_slider, ty_slider, tz_slider, epipoles_checkbox])\n",
    "ui = widgets.HBox([sliders_box, out])\n",
    "\n",
    "\n",
    "# Display the UI and the output widget\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735ea51-0619-4ac0-9181-f157f493b326",
   "metadata": {},
   "source": [
    "## Distortions\n",
    "\n",
    "The pin hole camera model is certainly a very good approximation but as we know most cameras use lenses to gather more light. \n",
    "How much do these differ from the pinhole model?\n",
    "Well firstly, with a lens, not everything is in focus.\n",
    "Secondly there are all sorts of distortions which can affect the image.\n",
    "\n",
    "I'll mention radial distortions here but I recommend  to anyone that is interested in lens distortions to look up [Marc Levoy's Stanford slides](http://graphics.stanford.edu/courses/cs478/lectures/01112012_optics.pdf)\n",
    "on the limitations of lenses or to read [Eugene Hecht's book on Optics](https://www.amazon.co.uk/Optics-Global-Eugene-Hecht/dp/1292096934/ref=sr_1_1?ie=UTF8&qid=1550318092&sr=8-1&keywords=hecht+optics)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "## Radial Distortion\n",
    "I mention this here as this has a large effect on image coordinates. \n",
    "\n",
    "Radial distortion is distortion that has an effect that is related to the distance from the center of the lens. \n",
    "\n",
    "This is most likely in lenses with a wide field of view i.e. a very short focal length. \n",
    "\n",
    "Fish-eye lenses are an extreme version of this.\n",
    "\n",
    "The basic problem is that the rules of projective geometry are broken i.e. straightness of lines are not preserved. \n",
    "\n",
    "\n",
    "## Radial Distortion\n",
    "The examples below show a (synthetic) radial distortion in order to drive home the point. \n",
    "\n",
    "What we notice is that the straight lines in the real world are curved in the image and this curving becomes more pronounced the further we get from the center.\n",
    "\n",
    "\n",
    "![](images/DCURadialDistortion.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70adc97-1bb3-4337-8e3a-0bb39e3ae903",
   "metadata": {},
   "source": [
    "![\"HigherEd 4.0 is funded by the Human Capital Initiative Pillar 3. HCI Pillar 3 supports projects to enhance the innovation and agility in response to future skills needs\"](images/HCIFunding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc944a1-05b3-4df4-b2d0-0faeba96ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
